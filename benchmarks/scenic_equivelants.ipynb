{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongming/workspace/research/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the .apperception_cache if it exists, as to avoid DB conflict errors\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(),\"apperception\"))\n",
    "\n",
    "dirpath = os.path.join('.apperception_cache')\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "dirpath = os.path.join('output')\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "os.mkdir(dirpath)\n",
    "\n",
    "# This piece of code is unsafe, and should not be run if not needed. \n",
    "# It serves for test purposes when one recieves a \"dead kernel\" error.\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongming/workspace/research/apperception\n"
     ]
    }
   ],
   "source": [
    "##### NUSCENES DATA #####\n",
    "from new_world import empty_world, World\n",
    "from scenic_util import transformation\n",
    "from camera import Camera\n",
    "import pandas as pd\n",
    "import pickle\n",
    "print(os. getcwd())\n",
    "World.db.reset()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "units = 'metrics'      # world units\n",
    "user_data_dir = os.path.join(\"v1.0-mini\")\n",
    "\n",
    "\n",
    "with open('./benchmarks/df_sample_data.pickle', \"rb\") as f:\n",
    "    df_sample_data = pickle.loads(f.read())\n",
    "with open('./benchmarks/df_annotation.pickle', \"rb\") as f:\n",
    "    df_annotation = pickle.loads(f.read())\n",
    "\n",
    "\n",
    "world = empty_world(name=name)\n",
    "\n",
    "from camera_config import fetch_camera_config\n",
    "# scenes = [\"scene-0061\", \"scene-0103\",\"scene-0553\", \"scene-0655\", \"scene-0757\", \"scene-0796\", \"scene-0916\", \"scene-1077\", \"scene-1094\", \"scene-1100\"]\n",
    "scenes = [\"scene-0061\"]\n",
    "for scene in scenes:\n",
    "    config = fetch_camera_config(scene, df_sample_data)\n",
    "    camera = Camera(config=config, id=scene)\n",
    "    world = world.add_camera(camera)\n",
    "    df_config = df_sample_data[df_sample_data['scene_name'] == scene][['sample_token']]\n",
    "    df_ann = df_annotation.join(df_config.set_index('sample_token'), on='sample_token', how='inner')\n",
    "    world = world.recognize(camera, df_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: insert_cam\n",
      "New camera inserted successfully.........\n",
      "execute: retrieve_cam\n",
      "execute: insert_bbox_traj\n",
      "Recognization done, saving to database......\n",
      "execute: get_cam\n",
      "done execute node\n"
     ]
    }
   ],
   "source": [
    "cams = world.get_camera()\n",
    "# ids = world.get_id()\n",
    "# print(\"cameras are\", cams[:2])\n",
    "# print(\"ids are\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_sample_data[\"heading\"].unique()\n",
    "x.sort()\n",
    "x[x.shape[0] // 2 + 330:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.road_direction(400, 1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40))\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "\n",
    "filtered_world = filtered_world.filter_relative_to_type(lambda obj: (cam.x - 10) <= obj.x <= (cam.x + 10) \n",
    "                                                                          and (cam.y - 10) <= obj.y <= (cam.y + 0)\n",
    "                                                                          and (cam.heading + 5) <= filtered_world.roadDirection(cam.x, cam.y) <= (cam.heading - 5))\n",
    "### when using predicate\n",
    "predicate(lambda obj, cam: any(obj.convert_to_cam) >= (-10, -10) \n",
    "              and any(obj.convert_to_cam) <= (10, 10)).get_camtimestamp()\n",
    "'''\n",
    "To realize this:\n",
    " 1. def convert_to_camera(): return 'ConvertCamera(obj_table.traj, obj_table.cameraId)'\n",
    " 2. any\n",
    " 3. <= , >= will be convert to where clause\n",
    "'''\n",
    "\n",
    "Select * from item_general_trajectory as traj, cameras join on cameraId where any(convertCamera(traj.trajCentroid, cameras.ego_config)) >= (-10,-10)\n",
    "                                                and any(convertCamera(traj.trajCentroid, traj.cameraId)) <= (10,10))\n",
    "\n",
    "# filtered_world = filtered_world.filter_pred_relative_to_type(pred = lambda obj: -10 <= (obj.x - cam.x) <= 10\n",
    "#                                                                             and 20 <= (obj.y - cam.y) <= 40\n",
    "#                                                                             and obj.heading == cam.heading)\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Total execution time is: %s seconds\" % (time.time() - start_time))\n",
    "# print(\"Device Details: \\n Processor: AMD Ryzen 7 5800H \\n RAM Size: 16GB \\n Graphics Card: NVIDIA GeForce RTX 3060 Laptop\")\n",
    "print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "traj = filtered_world.get_traj()\n",
    "for i, id in enumerate(filtered_ids):\n",
    "    print(id)\n",
    "    filtered_world.overlay_trajectory(scenes[0], traj[i], id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# offset = Uniform(-1, 1) * Range(90, 180) deg\n",
    "\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing offset relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# otherCar = Car on visible road,\n",
    "#             facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# require (distance from ego to otherCar) < 10\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "filtered_world = filtered_world.predicate(lambda obj: -67.5 <= (obj.heading - cam.heading) <= 67.5\n",
    "                                                    and -180 <= (filtered_world.roadDirection(cam.x, cam.y) - cam.heading) <= -90\n",
    "                                                    and 90 <= (filtered_world.roadDirection(cam.x, cam.y) - cam.heading) <= 180\n",
    "                                                    and -15 <= (filtered_world.roadDirection(obj.x, obj.y) - obj.heading) <= 15)\n",
    "                                                             \n",
    "filtered_world = filtered_world.filter_distance_to_type(distance=10, type=\"camera\")\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40)), \n",
    "# \tfacing Range(-5, 5) deg\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "filtered_world = filtered_world.filter_camera(pred = lambda cam: filtered_world.roadDirection(cam.x, cam.y) == cam.heading)\n",
    "\n",
    "filtered_world = filtered_world.filter_pred_relative_to_type(pred = lambda obj: -10 <= (obj.x - cam.x) <= 10\n",
    "                                                                            and 20 <= (obj.y - cam.y) <= 40,\n",
    "                                                             type=\"camera\")\n",
    "                                                             \n",
    "filtered_world = filtered_world.filter_traj(pred = lambda obj: -5 <= obj.heading <= 5)\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40)), \n",
    "# \tfacing Range(-5, 5) deg relative to ego\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "filtered_world = filtered_world.filter_camera(pred = lambda cam: filtered_world.roadDirection(cam.x, cam.y) == cam.heading)\n",
    "\n",
    "filtered_world = filtered_world.filter_pred_relative_to_type(pred = lambda obj: -10 <= (obj.x - cam.x) <= 10\n",
    "                                                                            and 20 <= (obj.y - cam.y) <= 40\n",
    "                                                                            and -5 <= (obj.heading - cam.heading) <= 5,\n",
    "                                                             type=\"camera\")\n",
    "                                                             \n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40)), \n",
    "# \tfacing Range(-5, 5) deg relative to roadDirection\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "filtered_world = filtered_world.filter_camera(pred = lambda cam: filtered_world.roadDirection(cam.x, cam.y) == cam.heading)\n",
    "\n",
    "filtered_world = filtered_world.filter_pred_relative_to_type(pred = lambda obj: -10 <= (obj.x - cam.x) <= 10\n",
    "                                                                            and 20 <= (obj.y - cam.y) <= 40,\n",
    "                                                             type=\"camera\")\n",
    "\n",
    "filtered_world = filtered_world.filter_traj(pred = lambda obj: -5 <= (obj.heading - filtered_world.roadDirection(obj.x, obj.y)) <= 5)\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = car on road\n",
    "# otherCar = Car ahead of ego by Range(4, 19)\n",
    "# require not (otherCar in intersection)\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "filtered_world = filtered_world.filter_camera(pred = lambda cam: filtered_world.roadDirection(cam.x, cam.y) == cam.heading \n",
    "                                                             and filtered_world.roadType(cam.x, cam.y) != None)\n",
    "\n",
    "filtered_world = filtered_world.filter_pred_relative_to_type(pred = lambda obj: 4 <= (obj.y - cam.y) <= 19,\n",
    "                                                             type=\"camera\")\n",
    "\n",
    "filtered_world = filtered_world.filter_traj(pred = lambda obj: roadType(obj.x, obj.y) != RoadType.Intersection)\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = car in intersection\n",
    "# otherCar = Car ahead of ego by Range(4, 19)\n",
    "# require otherCar in rightLane\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = world.filter_traj_type(\"vehicle.car\")\n",
    "\n",
    "filtered_world = filtered_world.filter_camera(pred = lambda cam:  filtered_world.roadDirection(cam.x, cam.y) == cam.heading \n",
    "                                                              and filtered_world.roadType(cam.x, cam.y) == RoadType.Intersection)\n",
    "\n",
    "filtered_world = filtered_world.filter_pred_relative_to_type(pred = lambda obj: 4 <= (obj.y - cam.y) <= 19,\n",
    "                                                             type=\"camera\")\n",
    "\n",
    "filtered_world = filtered_world.filter_traj(pred = lambda obj: roadType(obj.x, obj.y) == RoadType.RightLane)\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# def placeObjs(car, numCars):\n",
    "#     for i in range(numCars):\n",
    "#         car = Car ahead of car by Range(4, 5)\n",
    "#         leftCar = Car left of car by Normal(2, 0.1), facing roadDirection\n",
    "#         rightCar = Car right of car by Normal(3, 0.1), facing Range(0, 10) deg relative to ego.heading\n",
    "#     return leftCar, rightCar\n",
    "\n",
    "# spawn_point = 207.26 @ 8.72\n",
    "# ego = Car at spawn_point, with visible_distance 200\n",
    "\n",
    "# leftCar, rightCar = placeObjs(ego, 2)\n",
    "# require (distance to leftCar) < 200\n",
    "# require (distance to rightCar) < 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# def placeObjs(numPeds):\n",
    "#     for i in range(numPeds):\n",
    "#         Pedestrian offset by Range(-5, 5) @ Range(0, 200),\n",
    "#             facing Range(-120, 120) deg relative to ego.heading\n",
    "\n",
    "# spawn_point = 207.26 @ 8.72\n",
    "# ego = Car at spawn_point,\n",
    "#         with visibleDistance 200\n",
    "\n",
    "# placeObjs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50, \n",
    "#         with viewAngle 135 deg\n",
    "# ped = Pedestrian on roadsOrIntersections,\n",
    "#         with regionContainedIn roadRegion,\n",
    "#         facing Range(-180, 180) deg\n",
    "\n",
    "# require abs(relative heading of ped from ego) > 70 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# other1 = Car on intersection,\n",
    "#             facing -1 * Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# other2 = Car on intersection,\n",
    "#             facing -1 * Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# require abs(relative heading of other1 from other2) > 100 deg\n",
    "# require (distance from ego to intersectionRegion) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# offset = Uniform(-1, 1) * Range(90, 180) deg\n",
    "\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing offset relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# otherCar = Car on visible road,\n",
    "#             facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# require (distance from ego to otherCar) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# point1 = OrientedPoint ahead of ego by Range(0, 40)\n",
    "# Car at (point1 offset by Range(-1, 1) & 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# oppositeCar = Car offset by (Range(-10, -1), Range(0, 50)),\n",
    "#     facing Range(140, 180) deg relative to ego.heading\n",
    "\n",
    "# point2 = OrientedPoint ahead of oppositeCar by Range(0, 40)\n",
    "# Car at (point2 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# lanesWithRightLane = filter(lambda i: i._laneToRight, network.laneSections)\n",
    "# egoLane = Uniform(*lanesWithRightLane)\n",
    "\n",
    "# ego = Car on egoLane,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection\n",
    "# cutInCar = Car offset by Range(0, 4) @ Range(0, 5),\n",
    "#             facing -1*Range(15, 30) deg relative to roadDirection"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36b9f45d2c0c5940d48526f9dac9a46c8afda5d718c8f108cd3f22cd85be16c2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
