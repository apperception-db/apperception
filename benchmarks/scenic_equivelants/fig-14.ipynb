{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2a4075-d7d2-47b4-ba3e-e38942f27acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chanwutk/Documents/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "# %pip install .\n",
    "import time\n",
    "from os import environ\n",
    "# offset = Uniform(-1, 1) * Range(90, 180) deg\n",
    "\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing offset relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# otherCar = Car on visible road,\n",
    "#             facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# require (distance from ego to otherCar) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97df501",
   "metadata": {},
   "outputs": [],
   "source": [
    "if environ[\"AP_PORT\"] is None:\n",
    "    environ[\"AP_PORT\"] = str(input('port'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563f35bd-868e-4f01-87d5-37eb00adc206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith (\\n  select *\\n  from item_traj\\n  where item_traj.object_type = \\'car\\'\\n) as cars\\n\\nselect *\\nfrom cars as otherCar\\njoin Cameras as cam on t1.cameraId = Cameras.id\\nwhere\\n  TODO: ego facing relative to road direction????\\n  DISTANCE(cam.egoTranslation, otherCar.trajCentroids, cam.timestamp) < 50 AND\\n  viewAngle(otherCar.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\\n  contained(otherCar.traj, road_segment_type(\"visibleRoad\"), cam.timestamp) and\\n  facingRelative(otherCar.heading, road_direction(valueAtTimestamp(otherCar.trajCentroids, cam.timestamp)), cam.timestamp) >= -15 AND\\n  facingRelative(otherCar.heading, road_direction(valueAtTimestamp(otherCar.trajCentroids, cam.timestamp)), cam.timestamp) < 15 AND\\n  DISTANCE(cam.egoTranslation, otherCar.centroid, cam.timestamp) < 10 AND\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'car'\n",
    ") as cars\n",
    "\n",
    "select *\n",
    "from cars as otherCar\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  TODO: ego facing relative to road direction????\n",
    "  DISTANCE(cam.egoTranslation, otherCar.trajCentroids, cam.timestamp) < 50 AND\n",
    "  viewAngle(otherCar.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  contained(otherCar.traj, road_segment_type(\"visibleRoad\"), cam.timestamp) and\n",
    "  facingRelative(otherCar.heading, road_direction(valueAtTimestamp(otherCar.trajCentroids, cam.timestamp)), cam.timestamp) >= -15 AND\n",
    "  facingRelative(otherCar.heading, road_direction(valueAtTimestamp(otherCar.trajCentroids, cam.timestamp)), cam.timestamp) < 15 AND\n",
    "  DISTANCE(cam.egoTranslation, otherCar.centroid, cam.timestamp) < 10 AND\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d969ea-e93e-4e94-8844-5073af38c8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apperception.database.Database at 0x7f0ebf52d480>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.database import database\n",
    "from apperception.predicate import camera, objects\n",
    "import numpy as np\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c4ff55-c1d8-4963-a199-f182444a4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010508298873901367\n"
     ]
    }
   ],
   "source": [
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "# world = world.filter(\"lambda obj1, cam: \" + \n",
    "#         \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
    "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "#         \"F.view_angle(obj1, cam.ego, cam.timestamp) < 70 / 2 and \" +\n",
    "#         \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -180, -90) and \" +\n",
    "#         \"F.contained(cam.ego, F.road_segment('road')) and \" +\n",
    "#         \"F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) and \" +\n",
    "#         \"F.angle_between(F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 10\"\n",
    "# )\n",
    "\n",
    "obj1 = objects[0]\n",
    "cam = camera\n",
    "world = world.filter(\n",
    "    F.like(obj1.type, 'vehicle%') &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.timestamp) < 50) &\n",
    "    (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2) &\n",
    "    F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -180, -90) &\n",
    "    F.contained(cam.ego, F.road_segment('road')) &\n",
    "    F.contained(obj1.trans@cam.time, F.road_segment('road')) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, F.road_direction(obj1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.time) < 10)\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(num_joined_tables=1)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cccd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename:\n",
    "    itemId, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages[filename] = (itemId, timestamp, camId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c356d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from show_images import show_images\n",
    "%matplotlib inline\n",
    "\n",
    "# data_dir =  \"data/nuscenes/experiment_data\"\n",
    "data_dir = '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data'\n",
    "# data_dir = '/Users/chanwutk/Documents/experiment_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5128938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 6000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(data_dir, list(resultImages.keys()), sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78112ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m expected_imgs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492112404.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mshow_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/apperception/benchmarks/scenic_equivelants/show_images.py:29\u001b[0m, in \u001b[0;36mshow_images\u001b[0;34m(base_dir, images, sample, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m images[_image]:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(ii)\n\u001b[0;32m---> 29\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mmpimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;28mlen\u001b[39m(_images) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m columns \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, columns, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/mambaforge/envs/apperception/lib/python3.10/site-packages/matplotlib/image.py:1563\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         )\n\u001b[0;32m-> 1563\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1565\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/.local/share/mambaforge/envs/apperception/lib/python3.10/site-packages/PIL/Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3236\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3237\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 6000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expected_imgs = [\n",
    "    \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg\",\n",
    "    \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492112404.jpg\"\n",
    "]\n",
    "show_images(data_dir, expected_imgs, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting info about the expected images\n",
    "from apperception.database import database\n",
    "for img in expected_imgs:\n",
    "    prefix = \"samples/CAM_FRONT/\"\n",
    "    query = f\"\"\"SELECT Distinct \\'Cameras: \\', Cameras.filename, roadDirection(Cameras.egoTranslation, Cameras.timestamp, Cameras.egoHeading), \n",
    "    Cameras.egoHeading, facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp, Cameras.egoHeading), Cameras.timestamp),\n",
    "     ST_X(Cameras.egoTranslation), ST_Y(Cameras.egoTranslation), ST_Z(Cameras.egoTranslation),\n",
    "    \\'Cars: \\', table_0.itemId, getX(table_0.trajCentroids, Cameras.timestamp), getY(table_0.trajCentroids, Cameras.timestamp), \n",
    "    ST_Z(valueAtTimestamp(table_0.trajCentroids, Cameras.timestamp)), \n",
    "    \\'Distance: \\', distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp),\n",
    "    \\'CarHeading:\\', valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp),\n",
    "    \\'RoadDirection for car:\\', roadDirection(table_0.trajCentroids, Cameras.timestamp, valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp)::real),\n",
    "    \\'facingRelative:\\', facingRelative(table_0.itemHeadings, roadDirection(table_0.trajCentroids, Cameras.timestamp, valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp)::real), Cameras.timestamp) \n",
    "    FROM Item_General_Trajectory AS table_0, Cameras\n",
    "                WHERE Cameras.filename = \\'{prefix + img}\\' AND table_0.cameraId = Cameras.cameraId AND table_0.objectType LIKE 'vehicle%'\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "query = f\"\"\"SELECT elementId FROM SegmentPolygon WHERE contained(st_point(1269.1763045216746, 911.0066718975124), elementPolygon)\n",
    "            AND (SELECT id FROM Road WHERE id = elementId) IS NOT NULL;\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046aa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "query = f\"\"\"SELECT ST_Distance(st_point(1269.1763045216746, 911.0066718975124), st_point(1248.3893859608852, 947.7008533706982));\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "122.09787+48.640766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "360-(122.09787+48.640766)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73afa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d10f8d-c118-4328-859c-21934622ff73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7450ef5-dcef-4837-bd26-5c134cd051d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
