{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da2a4075-d7d2-47b4-ba3e-e38942f27acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongming/workspace/research\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "# %pip install .\n",
    "import time\n",
    "from os import environ\n",
    "# offset = Uniform(-1, 1) * Range(90, 180) deg\n",
    "\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing offset relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# otherCar = Car on visible road,\n",
    "#             facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# require (distance from ego to otherCar) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97df501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "port25432\n"
     ]
    }
   ],
   "source": [
    "environ['AP_PORT'] = str(input('port')) # README command uses port=25432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f35bd-868e-4f01-87d5-37eb00adc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'car'\n",
    ") as cars\n",
    "\n",
    "select *\n",
    "from cars as otherCar\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  TODO: ego facing relative to road direction????\n",
    "  DISTANCE(cam.egoTranslation, otherCar.trajCentroids, cam.timestamp) < 50 AND\n",
    "  viewAngle(otherCar.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  contained(otherCar.traj, road_segment_type(\"visibleRoad\"), cam.timestamp) and\n",
    "  facingRelative(otherCar.heading, road_direction(valueAtTimestamp(otherCar.trajCentroids, cam.timestamp)), cam.timestamp) >= -15 AND\n",
    "  facingRelative(otherCar.heading, road_direction(valueAtTimestamp(otherCar.trajCentroids, cam.timestamp)), cam.timestamp) < 15 AND\n",
    "  DISTANCE(cam.egoTranslation, otherCar.centroid, cam.timestamp) < 10 AND\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c4ff55-c1d8-4963-a199-f182444a4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: get_id_time_camId_filename\n",
      "get_id_time_camId_filename \n",
      "        SELECT table_0.itemId, cameras.timestamp, cameras.cameraId, cameras.filename\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        JOIN Cameras USING (cameraId)\n",
      "        WHERE ((table_0.objectType LIKE 'vehicle%') AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<67.5) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp, Cameras.egoHeading), Cameras.timestamp)>(-180)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp, Cameras.egoHeading), Cameras.timestamp)<(-90)) AND contained(Cameras.egoTranslation, roadSegment('road')) AND contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) AND (facingRelative(table_0.itemHeadings, roadDirection(table_0.trajCentroids, Cameras.timestamp, Cameras.egoHeading), Cameras.timestamp)>=(-15)) AND (facingRelative(table_0.itemHeadings, roadDirection(table_0.trajCentroids, Cameras.timestamp, Cameras.egoHeading), Cameras.timestamp)<15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<10))\n",
      "        \n",
      "done execute node\n",
      "[('9e02e0dcb5f04d01a4b8f0559d0e7d95', datetime.datetime(2018, 8, 30, 12, 31, 31, 612404, tzinfo=datetime.timezone.utc), 'scene-0769', 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg'), ('9e02e0dcb5f04d01a4b8f0559d0e7d95', datetime.datetime(2018, 8, 30, 12, 31, 32, 112404, tzinfo=datetime.timezone.utc), 'scene-0769', 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492112404.jpg')]\n",
      "12.29552936553955\n"
     ]
    }
   ],
   "source": [
    "### Prepare the world for queries ###\n",
    "from apperception.world import empty_world\n",
    "import numpy as np\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.database import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "# world = world.filter(lambda obj: obj.object_type == 'vehicle.car')\n",
    "random_sample = np.random.choice([-1,1],1)[0]\n",
    "facing_range = (random_sample*90, random_sample*180)\n",
    "def pred(otherCar, cam):\n",
    "    return (\n",
    "        # TODO: ego facing `offset` relative to road direction??\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 50 and \n",
    "        F.view_angle(obj1, cam.ego, cam.timestamp) < 67.5 and \n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp) > {min(facing_range)} and \n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp) < {max(facing_range)} and \n",
    "        F.contained(cam.ego, F.road_segment('road')) and \n",
    "        F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) and \n",
    "        F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) >= -15 and \n",
    "        F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) < 15 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 10\n",
    "    )\n",
    "world = world.filter(\"lambda obj1, cam: \" + \n",
    "        \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "        \"F.view_angle(obj1, cam.ego, cam.timestamp) < 67.5 and \" +\n",
    "        f\"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp) > -180 and \" +\n",
    "        f\"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp) < -90 and \" +\n",
    "        \"F.contained(cam.ego, F.road_segment('road')) and \" +\n",
    "        \"F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) and \" +\n",
    "        \"F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) >= -15 and \" +\n",
    "        \"F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) < 15 and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 10\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(num_joined_tables=1)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cccd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename:\n",
    "    itemId, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages[filename] = (itemId, timestamp, camId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c356d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "\n",
    "experiment_data_dir =  \"data/nuscenes/experiment_data\"\n",
    "# experiment_data_dir = '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data'\n",
    "def show_images(images, sample=None):\n",
    "    if sample is not None:\n",
    "        images = [i for i in images]\n",
    "        random.shuffle(images)\n",
    "        images = images[:sample]\n",
    "    \n",
    "    plt.figure(figsize=(60,30))\n",
    "    columns = 3\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        print(\"image\", image)\n",
    "        img = mpimg.imread(os.path.join(experiment_data_dir, image))\n",
    "        print(\"loaded\")\n",
    "        plt.subplot(len(images) // columns + 1, columns, i + 1)\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5128938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/nuscenes/experiment_data/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshow_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresultImages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mshow_images\u001b[0;34m(images, sample)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m---> 20\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mmpimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m columns \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, columns, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.3/lib/python3.8/site-packages/matplotlib/image.py:1560\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1558\u001b[0m                 response \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   1559\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m imread(response, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mext)\n\u001b[0;32m-> 1560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1562\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.3/lib/python3.8/site-packages/PIL/Image.py:3068\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3065\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3068\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3069\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3071\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/nuscenes/experiment_data/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4320x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(list(resultImages.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78112ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_imgs = [\"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492112404.jpg\"]\n",
    "show_images(expected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21586ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Getting info about the expected images\n",
    "from apperception.database import database\n",
    "for img in expected_imgs:\n",
    "    prefix = \"samples/CAM_FRONT/\"\n",
    "    query = f\"\"\"SELECT Distinct \\'Cameras: \\', Cameras.filename, roadDirection(Cameras.egoTranslation, Cameras.timestamp, Cameras.egoHeading), \n",
    "    Cameras.egoHeading, facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp, Cameras.egoHeading), Cameras.timestamp),\n",
    "     ST_X(Cameras.egoTranslation), ST_Y(Cameras.egoTranslation), ST_Z(Cameras.egoTranslation),\n",
    "    \\'Cars: \\', table_0.itemId, getX(table_0.trajCentroids, Cameras.timestamp), getY(table_0.trajCentroids, Cameras.timestamp), \n",
    "    ST_Z(valueAtTimestamp(table_0.trajCentroids, Cameras.timestamp)), \n",
    "    \\'Distance: \\', distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp),\n",
    "    \\'CarHeading:\\', valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp),\n",
    "    \\'RoadDirection for car:\\', roadDirection(table_0.trajCentroids, Cameras.timestamp, valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp)::real),\n",
    "    \\'facingRelative:\\', facingRelative(table_0.itemHeadings, roadDirection(table_0.trajCentroids, Cameras.timestamp, valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp)::real), Cameras.timestamp) \n",
    "    FROM Item_General_Trajectory AS table_0, Cameras\n",
    "                WHERE Cameras.filename = \\'{prefix + img}\\' AND table_0.cameraId = Cameras.cameraId AND table_0.objectType LIKE 'vehicle%'\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "query = f\"\"\"SELECT elementId FROM SegmentPolygon WHERE contained(st_point(1269.1763045216746, 911.0066718975124), elementPolygon)\n",
    "            AND (SELECT id FROM Road WHERE id = elementId) IS NOT NULL;\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046aa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "query = f\"\"\"SELECT ST_Distance(st_point(1269.1763045216746, 911.0066718975124), st_point(1248.3893859608852, 947.7008533706982));\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "122.09787+48.640766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "360-(122.09787+48.640766)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73afa44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
