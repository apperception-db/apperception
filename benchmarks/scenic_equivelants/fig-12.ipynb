{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e564f2b-e214-4d07-bade-bf55c8190b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\youse\\Desktop\\Research\\Apperception\\apperception\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "# %pip install .\n",
    "import time\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50, \n",
    "#         with viewAngle 135 deg\n",
    "# ped = Pedestrian on roadsOrIntersections,\n",
    "#         with regionContainedIn roadRegion,\n",
    "#         facing Range(-180, 180) deg\n",
    "\n",
    "# require abs(relative heading of ped from ego) > 70 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efbe6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith (\\n  select *\\n  from item_traj\\n  where item_traj.object_type = \\'pedestrian\\'\\n) as pedestrians\\n\\nselect *\\nfrom pedestrians as t1\\njoin Cameras as cam on t1.cameraId = Cameras.id\\nwhere\\n  t1.heading < 180 and t1.heading > -180 and\\n  (contained(t1.traj, road_segment(\"roads\"), cam.timestamp) or\\n   contained(t1.traj, road_segment(\"Intersections\"), cam.timestamp)) and\\n  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -70 OR\\n  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > 70) AND\\n  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\\n  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\\n  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\\n  viewAngle(t1.traj, cam.egoHeading, cam.ego_translation, cam.timestamp) < 135\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'pedestrian'\n",
    ") as pedestrians\n",
    "\n",
    "select *\n",
    "from pedestrians as t1\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  t1.heading < 180 and t1.heading > -180 and\n",
    "  (contained(t1.traj, road_segment(\"roads\"), cam.timestamp) or\n",
    "   contained(t1.traj, road_segment(\"Intersections\"), cam.timestamp)) and\n",
    "  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -70 OR\n",
    "  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > 70) AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\n",
    "  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t1.traj, cam.egoHeading, cam.ego_translation, cam.timestamp) < 135\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b38598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj_key\n",
      "get_traj_key \n",
      "        SELECT itemId FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "0.6405878067016602\n"
     ]
    }
   ],
   "source": [
    "### Prepare the world for queries ###\n",
    "from apperception.new_world import *\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.new_db import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "world = world.filter(lambda obj: obj.object_type == 'human.pedestrian.adult' or\n",
    "                                 obj.object_type == 'human.pedestrian.wheelchair' or\n",
    "                                 obj.object_type == 'human.pedestrian.personal_mobility' or\n",
    "                                 obj.object_type == 'human.pedestrian.construction_worker' or\n",
    "                                 obj.object_type == 'human.pedestrian.police_officer' or\n",
    "                                 obj.object_type == 'human.pedestrian.child' or\n",
    "                                 obj.object_type == 'human.pedestrian.stroller')\n",
    "def pred(obj1, cam):\n",
    "    return (\n",
    "        obj1.heading < 180 and obj1.heading > -180 and\n",
    "        (F.contained(obj1.traj, F.road_segment(\"road\"), cam.timestamp) or\n",
    "            F.contained(obj1.traj, F.road_segment(\"intersection\"))) and\n",
    "        (F.facing_relative(obj1, cam.ego, cam.timestamp) < -70 or\n",
    "            F.facing_relative(obj1, cam.ego, cam.timestamp) >= 70) and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj1, cam.ego, cam.timestamp) < 135\n",
    "    )\n",
    "\n",
    "# With road direction\n",
    "world = world.filter(\"lambda obj1, cam: \" +\n",
    "        \"(F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) or \" + \n",
    "            \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp)) and \" +\n",
    "        \"(F.facing_relative(obj1, cam.ego, cam.timestamp) < -70 or \" + \n",
    "            \"F.facing_relative(obj1, cam.ego, cam.timestamp) >= 70) and \" + \n",
    "        \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and \" +\n",
    "        \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "        \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135\")\n",
    "\n",
    "# Without road direction\n",
    "# world = world.filter(\"lambda obj1, cam: \" +\n",
    "#         \"(F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) or \" + \n",
    "#             \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp)) and \" +\n",
    "#         \"(F.facing_relative(obj1, cam.ego, cam.timestamp) < -70 or \" + \n",
    "#             \"F.facing_relative(obj1, cam.ego, cam.timestamp) >= 70) and \"\n",
    "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "#         \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135\")\n",
    "start = time.time()\n",
    "\n",
    "key = world.get_traj_key()\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a9c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj_key\n",
      "get_traj_key \n",
      "        SELECT itemId FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj\n",
      "get_traj \n",
      "        SELECT asMFJSON(trajCentroids)::json->'sequences'\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj_attr\n",
      "get_traj_attr: cameraId \n",
      "        SELECT cameraId FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "[('69c08f8de9eb4af1ade1a6f85f9421fd',), ('8ddf99e397a048e0ae26767155a0ccdd',), ('c1585912b1b54727be81c39e5309e3c0',), ('c24e096fcf4c4e55b74892bddc982eaa',)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "keys = world.get_traj_key()\n",
    "trajs = world.get_traj()\n",
    "scene_names = world.get_traj_attr(\"cameraId\")\n",
    "print(keys)\n",
    "images = []\n",
    "for i in range(len(keys)):\n",
    "    key = keys[i][0]\n",
    "    traj = trajs[i][0]\n",
    "    scene_name = scene_names[i][0]\n",
    "    current_images = world.get_trajectory_images(scene_name, traj)\n",
    "    for image in current_images:\n",
    "        images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0badbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_flat = np.array(images, dtype='object').flatten()\n",
    "no_prefix_imgs = []\n",
    "for image in images_flat:\n",
    "    no_prefix_imgs.append(image.split(\"/\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e03f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_imgs = ['n008-2018-05-21-11-06-59-0400__CAM_FRONT__1526915471412465.jpg', 'n008-2018-07-27-12-07-38-0400__CAM_FRONT__1532707917112404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153162404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153662404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385154162404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385154662404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385155162404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385158662404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159162404.jpg', 'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159662404.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656805162404.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656805662415.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656806162404.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656806612404.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656807162404.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656807662404.jpg', 'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656808162404.jpg', 'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659404362404.jpg', 'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659404762404.jpg', 'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659405262404.jpg', 'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659405762404.jpg', 'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659406262404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535728830362404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326412404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326912404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729327412404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729327912404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729328412404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729328912404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729329412404.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729329912795.jpg', 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729330362404.jpg', 'n008-2018-08-31-11-37-23-0400__CAM_FRONT__1535730293412404.jpg', 'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731236162404.jpg', 'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731236662404.jpg', 'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731237112404.jpg', 'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731237612404.jpg', 'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293291162404.jpg', 'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293291662404.jpg', 'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293292162404.jpg', 'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293292662404.jpg', 'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293293162404.jpg', 'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293293662404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299143862404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299144362404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299144862404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299145362404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299145862404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299146362404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299146862404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299147362404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299147862404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299148362404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299148862404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299149412404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299229362404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299239112404.jpg', 'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299240112404.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee5fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of expected results missing from query:  86.20689655172414 %\n",
      "Percentage of images in query but not in expected results:  58.97435897435897 %\n"
     ]
    }
   ],
   "source": [
    "missing = 0\n",
    "for expected_img in expected_imgs:\n",
    "    if expected_img not in no_prefix_imgs:\n",
    "        missing += 1\n",
    "print(\"Percentage of expected results missing from query: \", 100 * missing / len(expected_imgs), \"%\")\n",
    "\n",
    "extra = 0\n",
    "for img in no_prefix_imgs:\n",
    "    if img not in expected_imgs:\n",
    "        extra += 1\n",
    "print(\"Percentage of images in query but not in expected results: \", 100 * extra / len(no_prefix_imgs), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb14000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c9f2372a2bfaf539cf701a38e7f23ab828911ee177c2e7bc9c32aa1f4b546df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
