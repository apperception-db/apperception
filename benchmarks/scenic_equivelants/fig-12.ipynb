{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e564f2b-e214-4d07-bade-bf55c8190b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\youse\\Desktop\\Research\\Apperception\\apperception\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "# %pip install .\n",
    "import time\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50, \n",
    "#         with viewAngle 135 deg\n",
    "# ped = Pedestrian on roadsOrIntersections,\n",
    "#         with regionContainedIn roadRegion,\n",
    "#         facing Range(-180, 180) deg\n",
    "\n",
    "# require abs(relative heading of ped from ego) > 70 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efbe6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith (\\n  select *\\n  from item_traj\\n  where item_traj.object_type = \\'pedestrian\\'\\n) as pedestrians\\n\\nselect *\\nfrom pedestrians as t1\\njoin Cameras as cam on t1.cameraId = Cameras.id\\nwhere\\n  t1.heading < 180 and t1.heading > -180 and\\n  (contained(t1.traj, road_segment(\"roads\"), cam.timestamp) or\\n   contained(t1.traj, road_segment(\"Intersections\"), cam.timestamp)) and\\n  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -70 OR\\n  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > 70) AND\\n  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\\n  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\\n  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\\n  viewAngle(t1.traj, cam.egoHeading, cam.ego_translation, cam.timestamp) < 135\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'pedestrian'\n",
    ") as pedestrians\n",
    "\n",
    "select *\n",
    "from pedestrians as t1\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  t1.heading < 180 and t1.heading > -180 and\n",
    "  (contained(t1.traj, road_segment(\"roads\"), cam.timestamp) or\n",
    "   contained(t1.traj, road_segment(\"Intersections\"), cam.timestamp)) and\n",
    "  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -70 OR\n",
    "  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > 70) AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\n",
    "  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t1.traj, cam.egoHeading, cam.ego_translation, cam.timestamp) < 135\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b38598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj_key\n",
      "get_traj_key \n",
      "        SELECT itemId FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)<180) AND (facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)>(-180)) AND (contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "0.21906495094299316\n"
     ]
    }
   ],
   "source": [
    "### Prepare the world for queries ###\n",
    "from apperception.new_world import *\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.new_db import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "world = world.filter(lambda obj: obj.object_type == 'human.pedestrian.adult' or\n",
    "                                 obj.object_type == 'human.pedestrian.wheelchair' or\n",
    "                                 obj.object_type == 'human.pedestrian.personal_mobility' or\n",
    "                                 obj.object_type == 'human.pedestrian.construction_worker' or\n",
    "                                 obj.object_type == 'human.pedestrian.police_officer' or\n",
    "                                 obj.object_type == 'human.pedestrian.child' or\n",
    "                                 obj.object_type == 'human.pedestrian.stroller')\n",
    "def pred(obj1, cam):\n",
    "    return (\n",
    "        obj1.heading < 180 and obj1.heading > -180 and\n",
    "        (F.contained(obj1.traj, F.road_segment(\"road\"), cam.timestamp) or\n",
    "            F.contained(obj1.traj, F.road_segment(\"intersection\"))) and\n",
    "        (F.facing_relative(obj1, cam.ego, cam.timestamp) < -70 or\n",
    "            F.facing_relative(obj1, cam.ego, cam.timestamp) >= 70) and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj1, cam.ego, cam.timestamp) < 135\n",
    "    )\n",
    "world = world.filter(\"lambda obj1, cam: F.facing_relative(obj1, 0, cam.timestamp) < 180 and \" + \n",
    "                     \"F.facing_relative(obj1, 0, cam.timestamp) > -180 and \" +\n",
    "        \"(F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) or \" + \n",
    "            \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp)) and \" +\n",
    "        \"(F.facing_relative(obj1, cam.ego, cam.timestamp) < -70 or \" + \n",
    "            \"F.facing_relative(obj1, cam.ego, cam.timestamp) >= 70) and \" + \n",
    "        \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and \" +\n",
    "        \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "        \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "key = world.get_traj_key()\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a9c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj_key\n",
      "get_traj_key \n",
      "        SELECT itemId FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)<180) AND (facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)>(-180)) AND (contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj\n",
      "get_traj \n",
      "        SELECT asMFJSON(trajCentroids)::json->'sequences'\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)<180) AND (facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)>(-180)) AND (contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "execute: filter\n",
      "execute: filter\n",
      "execute: get_traj_attr\n",
      "get_traj_attr: cameraId \n",
      "        SELECT cameraId FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (\n",
      "        SELECT DISTINCT table_0.*\n",
      "        FROM (SELECT * FROM item_general_trajectory) as table_0\n",
      "        \n",
      "        \n",
      "        WHERE ((table_0.objectType='human.pedestrian.adult') OR (table_0.objectType='human.pedestrian.wheelchair') OR (table_0.objectType='human.pedestrian.personal_mobility') OR (table_0.objectType='human.pedestrian.construction_worker') OR (table_0.objectType='human.pedestrian.police_officer') OR (table_0.objectType='human.pedestrian.child') OR (table_0.objectType='human.pedestrian.stroller'))\n",
      "        ) as table_0\n",
      "        \n",
      "        JOIN Cameras ON Cameras.cameraId = table_0.cameraId\n",
      "        WHERE ((facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)<180) AND (facingRelative(table_0.itemHeadings, 0, Cameras.timestamp)>(-180)) AND (contained(table_0.trajCentroids, roadSegment('road'), Cameras.timestamp) OR contained(table_0.trajCentroids, roadSegment('intersection'), Cameras.timestamp)) AND ((facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)<(-70)) OR (facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp)>=70)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)>=(-15)) AND (facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp), Cameras.timestamp)<=15) AND (distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp)<50) AND (viewAngle(table_0.trajCentroids, Cameras.egoHeading, Cameras.egoTranslation, Cameras.timestamp)<135))\n",
      "        ) as final\n",
      "        \n",
      "done execute node\n",
      "[('c1585912b1b54727be81c39e5309e3c0',)]\n",
      "[['samples/CAM_FRONT/n008-2018-09-18-12-53-31-0400__CAM_FRONT__1537290188512404.jpg'], ['samples/CAM_FRONT/n008-2018-09-18-12-53-31-0400__CAM_FRONT__1537290189012404.jpg'], ['samples/CAM_FRONT/n008-2018-09-18-12-53-31-0400__CAM_FRONT__1537290189512404.jpg'], ['samples/CAM_FRONT/n008-2018-09-18-12-53-31-0400__CAM_FRONT__1537290190012404.jpg'], ['samples/CAM_FRONT/n008-2018-09-18-12-53-31-0400__CAM_FRONT__1537290199912404.jpg'], ['samples/CAM_FRONT/n008-2018-09-18-12-53-31-0400__CAM_FRONT__1537290201412404.jpg']]\n"
     ]
    }
   ],
   "source": [
    "keys = world.get_traj_key()\n",
    "trajs = world.get_traj()\n",
    "scene_names = world.get_traj_attr(\"cameraId\")\n",
    "print(keys)\n",
    "for i in range(len(keys)):\n",
    "    key = keys[i][0]\n",
    "    traj = trajs[i][0]\n",
    "    scene_name = scene_names[i][0]\n",
    "    print(world.get_trajectory_images(scene_name, traj))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c9f2372a2bfaf539cf701a38e7f23ab828911ee177c2e7bc9c32aa1f4b546df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
