{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fce500-7081-4f17-b607-e0ef1638c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "import time\n",
    "from os import environ\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# other1 = Car on intersection,\n",
    "#             facing Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# other2 = Car on intersection,\n",
    "#             facing -1 * Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# require abs(relative heading of other1 from other2) > 100 deg\n",
    "# require (distance from ego to intersectionRegion) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3978070-58ee-4b43-802d-4843a3470ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"AP_PORT\" not in environ:\n",
    "    environ[\"AP_PORT\"] = \"25432\" #str(input('port'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a55f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'car'\n",
    ") as cars\n",
    "\n",
    "select *\n",
    "from cars as t1\n",
    "join cars as t2 on t1.cameraId = t2.cameraId\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\n",
    "  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t1.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  DISTANCE(cam.egoTranslation, t2.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t2.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  contained(t1.traj, road_segment_type(\"intersection\"), cam.timestamp) and\n",
    "  contained(t2.traj, road_segment_type(\"intersection\"), cam.timestamp) and\n",
    "  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -50 ANd\n",
    "  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > -135) AND\n",
    "  (facingRelative(t2.heading, cam.egoHeading, cam.timestamp) < -50 AND\n",
    "  facingRelative(t2.heading, cam.egoHeading, cam.timestamp) > -135) AND\n",
    "  DISTANCE(cam.egoTranslation, roadSection(\"intersection\"), cam.timestamp) < 10 AND\n",
    "  (facingRelative(t1.heading, t2.heading, cam.timestamp) > 100 OR\n",
    "  facingRelative(t1.heading, t2.heading, cam.timestmap) < -100)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646aa68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Prepare the world for queries ###\n",
    "from apperception.world import empty_world\n",
    "from apperception.database import database\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.new_db import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "\n",
    "\n",
    "def pred(obj1, obj2, cam):\n",
    "    return (\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj1, cam.ego, cam.timestamp) < (70 / 2) and\n",
    "        F.distance(cam.ego, obj2, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj2, cam.ego, cam.timestamp) < (70 / 2) and\n",
    "        F.contained(obj1.traj, F.road_segment(\"intersection\"), cam.timestamp) and\n",
    "        F.contained(obj2.traj, F.road_segment(\"intersection\"), cam.timestamp) and\n",
    "        (F.facing_relative(obj1, cam.ego, cam.timestamp) < -50 or\n",
    "            F.facing_relative(obj1, cam.ego, cam.timestamp) > -135) and\n",
    "        (F.facing_relative(obj2, cam.ego, cam.timestamp) < -50 or\n",
    "            F.facing_relative(obj2, cam.ego, cam.timestamp) > -135) and\n",
    "        F.distance(cam.ego, roadSection(obj1.traj, cam.timestamp)) < 10 and\n",
    "        (F.facing_relative(obj1, obj2, cam.timestamp) > 100 or\n",
    "            F.facing_relative(obj1, obj2, cam.timestamp) < -100)\n",
    "    )\n",
    "world = world.filter(\"lambda obj1, obj2, cam: \" +\n",
    "    \"obj1.object_id != obj2.object_id and \" +\n",
    "    \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
    "    \"F.like(obj2.object_type, 'vehicle%') and \" +\n",
    "    \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) and \" +\n",
    "    \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "    \"F.view_angle(obj1, cam.ego, cam.timestamp) < 70 / 2.0 and \" +\n",
    "    \"F.distance(cam.ego, obj2, cam.timestamp) < 50 and \" +\n",
    "    \"F.view_angle(obj2, cam.ego, cam.timestamp) < 70 / 2.0 and \" +\n",
    "    \"F.contains_all('intersection', [obj1.traj, obj2.traj]@cam.timestamp) and \"\n",
    "    \"F.angle_between(F.facing_relative(obj1, cam.ego, cam.timestamp), 50, 135) and \" +\n",
    "    \"F.angle_between(F.facing_relative(obj2, cam.ego, cam.timestamp), -135, -50) and \" +\n",
    "    \"F.minDistance(cam.egoTranslation, F.road_segment('intersection')) < 10 and \" +\n",
    "    \"F.angle_between(F.facing_relative(obj1, obj2, cam.timestamp), 100, -100) and \" +\n",
    "    # \"F.like(cam.filename, '%n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656773912404.jpg') and \" +\n",
    "    \"1 == 1;\"\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(2)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17bd0d-d751-4c05-829b-01668d4d5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.utils import overlay_trajectory\n",
    "from apperception.database import database\n",
    "\n",
    "data_dir =  \"data/nuscenes/experiment_data\"\n",
    "\n",
    "overlay_trajectory(world=world, database=database, images_data_path=data_dir, is_overlay_headings=True, is_overlay_objects=True, is_overlay_road=True, is_keep_whole_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.data_types import QueryType, Trajectory\n",
    "import datetime\n",
    "query = f\"\"\"\n",
    "        SELECT asMFJSON(trajCentroids)::json->'sequences'\n",
    "        FROM Item_General_Trajectory as final\n",
    "        WHERE itemId = '9d03c6edb6eb4d49acccb245bdd0c652'\n",
    "        \"\"\"\n",
    "\n",
    "t = database._execute_query(query)[0][0][0]\n",
    "coordinates = t[\"coordinates\"]\n",
    "datetimes = t[\"datetimes\"]\n",
    "result = {}\n",
    "for coord, time in zip(coordinates, datetimes):\n",
    "    dt_time = datetime.datetime.strptime(time, \"%Y-%m-%dT%H:%M:%S.%f+00\").replace(tzinfo=datetime.timezone.utc)\n",
    "    result[dt_time] = coord\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512ae83-94bd-435f-bd57-3eb6d28a20d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in id_time_camId_filename:\n",
    "#     print(k[-2], str(k[-3]), k[-1])\n",
    "#     print(\"                                           \", *k[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6aee0-b1e0-4275-b6df-739824f10187",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename:\n",
    "    itemId1, itemId2, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    if filename not in resultImages:\n",
    "        resultImages[filename] = []\n",
    "    resultImages[filename].append((itemId1, itemId2, timestamp, camId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9434da-39cc-4396-8954-aae3a5ac79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from show_images import show_images\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir =  \"data/nuscenes/experiment_data\"\n",
    "# data_dir = '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data'\n",
    "# data_dir = '/Users/chanwutk/Documents/experiment_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1c992-fe0c-48b1-96a1-f1f9aa5dddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(data_dir, resultImages, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION ST_XYZ (g geometry) RETURNS real[] AS $$\n",
    "    BEGIN\n",
    "        RETURN ARRAY[ST_X(g), ST_Y(g), ST_Z(g)];\n",
    "    END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "SELECT\n",
    "    cameraId,\n",
    "    ST_XYZ(egoTranslation),\n",
    "    egoRotation,\n",
    "    ST_XYZ(cameraTranslation),\n",
    "    ST_XYZ(cameraTranslationAbs),\n",
    "    cameraRotation,\n",
    "    cameraIntrinsic,\n",
    "    frameNum,\n",
    "    fileName,\n",
    "    cameraHeading,\n",
    "    egoHeading\n",
    "FROM Cameras\n",
    "WHERE\n",
    "    fileName = 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg'\n",
    "ORDER BY cameraId ASC, frameNum ASC;\n",
    "\"\"\"\n",
    "# print(query)\n",
    "result = database._execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f4279-2b32-4f70-9742-dadc12e7cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_imgs = [\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657119112404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127612404.jpg',\n",
    "    'n008-2018-09-18-12-07-26-0400__CAM_FRONT__1537287358412404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118612404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127112404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657128112404.jpg',\n",
    "]\n",
    "show_images(data_dir, expected_imgs, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5837a-34e2-4e52-b680-15cd81f05f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = 0\n",
    "missing_images = []\n",
    "for expected_img in expected_imgs:\n",
    "    if expected_img not in resultImages.keys():\n",
    "        missing += 1\n",
    "        missing_images.append(expected_img)\n",
    "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
    "show_images(data_dir, missing_images, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515c5a1-97bc-466b-8509-61af53eef2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = 0\n",
    "extra_images = {}\n",
    "for img in resultImages.keys():\n",
    "    if img not in expected_imgs:\n",
    "        extra += 1\n",
    "        extra_images[img] = resultImages[img]\n",
    "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(resultImages.keys()), \"=\", 100 * extra / len(resultImages.keys()), \"%\")\n",
    "show_images(data_dir, extra_images, sample=10, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35518f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c9f2372a2bfaf539cf701a38e7f23ab828911ee177c2e7bc9c32aa1f4b546df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
