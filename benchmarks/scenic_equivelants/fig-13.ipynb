{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fce500-7081-4f17-b607-e0ef1638c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "import time\n",
    "from os import environ\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# other1 = Car on intersection,\n",
    "#             facing Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# other2 = Car on intersection,\n",
    "#             facing -1 * Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# require abs(relative heading of other1 from other2) > 100 deg\n",
    "# require (distance from ego to intersectionRegion) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3978070-58ee-4b43-802d-4843a3470ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if environ[\"AP_PORT\"] is None:\n",
    "    environ[\"AP_PORT\"] = str(input('port'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a55f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'car'\n",
    ") as cars\n",
    "\n",
    "select *\n",
    "from cars as t1\n",
    "join cars as t2 on t1.cameraId = t2.cameraId\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\n",
    "  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t1.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  DISTANCE(cam.egoTranslation, t2.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t2.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  contained(t1.traj, road_segment_type(\"intersection\"), cam.timestamp) and\n",
    "  contained(t2.traj, road_segment_type(\"intersection\"), cam.timestamp) and\n",
    "  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -50 ANd\n",
    "  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > -135) AND\n",
    "  (facingRelative(t2.heading, cam.egoHeading, cam.timestamp) < -50 AND\n",
    "  facingRelative(t2.heading, cam.egoHeading, cam.timestamp) > -135) AND\n",
    "  DISTANCE(cam.egoTranslation, roadSection(\"intersection\"), cam.timestamp) < 10 AND\n",
    "  (facingRelative(t1.heading, t2.heading, cam.timestamp) > 100 OR\n",
    "  facingRelative(t1.heading, t2.heading, cam.timestmap) < -100)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646aa68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Prepare the world for queries ###\n",
    "from apperception.world import empty_world\n",
    "from apperception.database import database\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.new_db import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "\n",
    "\n",
    "def pred(obj1, obj2, cam):\n",
    "    return (\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj1, cam.ego, cam.timestamp) < 135 and\n",
    "        F.distance(cam.ego, obj2, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj2, cam.ego, cam.timestamp) < 135 and\n",
    "        F.contained(obj1.traj, F.road_segment(\"intersection\"), cam.timestamp) and\n",
    "        F.contained(obj2.traj, F.road_segment(\"intersection\"), cam.timestamp) and\n",
    "        (F.facing_relative(obj1, cam.ego, cam.timestamp) < -50 or\n",
    "            F.facing_relative(obj1, cam.ego, cam.timestamp) > -135) and\n",
    "        (F.facing_relative(obj2, cam.ego, cam.timestamp) < -50 or\n",
    "            F.facing_relative(obj2, cam.ego, cam.timestamp) > -135) and\n",
    "        F.distance(cam.ego, roadSection(obj1.traj, cam.timestamp)) < 10 and\n",
    "        (F.facing_relative(obj1, obj2, cam.timestamp) > 100 or\n",
    "            F.facing_relative(obj1, obj2, cam.timestamp) < -100)\n",
    "    )\n",
    "world = world.filter(\"lambda obj1, obj2, cam: \" +\n",
    "    \"obj1.object_id != obj2.object_id and \" +\n",
    "    \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
    "    \"F.like(obj2.object_type, 'vehicle%') and \" +\n",
    "    \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) and \" +\n",
    "    \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "    \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135 / 2.0 and \" +\n",
    "    \"F.distance(cam.ego, obj2, cam.timestamp) < 50 and \" +\n",
    "    \"F.view_angle(obj2, cam.ego, cam.timestamp) < 135 / 2.0 and \" +\n",
    "    \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp) and \" +\n",
    "    \"F.contained(obj2.traj, F.road_segment('intersection'), cam.timestamp) and \" +\n",
    "    \"F.angle_between(F.facing_relative(obj1, cam.ego, cam.timestamp), 50, 135) and \" +\n",
    "    \"F.angle_between(F.facing_relative(obj2, cam.ego, cam.timestamp), -135, -50) and \" +\n",
    "                     \n",
    "    # TODO: distance for intersecting region\n",
    "    # \"F.distance(cam.ego, obj1, cam.timestamp) < 10 and \" +\n",
    "    # \"F.distance(cam.ego, obj2, cam.timestamp) < 10 and \" +\n",
    "    \"F.minDistance(cam.egoTranslation, F.road_segment('intersection')) < 10 and \" +\n",
    "    \"F.angle_between(F.facing_relative(obj1, obj2, cam.timestamp), 100, -100) and \" +\n",
    "    # \"F.like(cam.filename, '%n008-2018-09-18-12-07-26-0400__CAM_FRONT__1537287358412404.jpg') and \" +\n",
    "    \"1 == 1;\"\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(2)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17bd0d-d751-4c05-829b-01668d4d5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.sql(\"\"\"\n",
    "SELECT \n",
    "  table_0.itemId, \n",
    "  table_1.itemId, \n",
    "  cameras.timestamp, \n",
    "  cameras.cameraId, \n",
    "  cameras.filename,\n",
    "  minDistance(\n",
    "        Cameras.egoTranslation, \n",
    "        roadSegment('intersection')\n",
    "      )\n",
    "FROM \n",
    "  (\n",
    "    SELECT \n",
    "      * \n",
    "    FROM \n",
    "      item_general_trajectory\n",
    "  ) as table_0 \n",
    "  JOIN (\n",
    "    SELECT \n",
    "      * \n",
    "    FROM \n",
    "      item_general_trajectory\n",
    "  ) as table_1 USING (cameraId) \n",
    "  JOIN Cameras USING (cameraId) \n",
    "WHERE \n",
    "  (\n",
    "    (table_0.itemId <> table_1.itemId) \n",
    "    AND (\n",
    "      table_0.objectType LIKE 'vehicle%'\n",
    "    ) \n",
    "    AND (\n",
    "      table_1.objectType LIKE 'vehicle%'\n",
    "    ) \n",
    "    AND angleBetween(\n",
    "      facingRelative(\n",
    "        Cameras.egoHeading, \n",
    "        roadDirection(\n",
    "          Cameras.egoTranslation, Cameras.egoHeading\n",
    "        )\n",
    "      ), \n",
    "      (-15), \n",
    "      15\n",
    "    ) \n",
    "    AND (\n",
    "      distance(\n",
    "        Cameras.egoTranslation, table_0.trajCentroids, \n",
    "        Cameras.timestamp\n",
    "      )< 50\n",
    "    ) \n",
    "    AND (\n",
    "      viewAngle(\n",
    "        table_0.trajCentroids, Cameras.egoHeading, \n",
    "        Cameras.egoTranslation, Cameras.timestamp\n",
    "      )< 135\n",
    "    ) \n",
    "    AND (\n",
    "      distance(\n",
    "        Cameras.egoTranslation, table_1.trajCentroids, \n",
    "        Cameras.timestamp\n",
    "      )< 50\n",
    "    ) \n",
    "    AND (\n",
    "      viewAngle(\n",
    "        table_1.trajCentroids, Cameras.egoHeading, \n",
    "        Cameras.egoTranslation, Cameras.timestamp\n",
    "      )< 135\n",
    "    ) \n",
    "    AND contained(\n",
    "      table_0.trajCentroids, \n",
    "      roadSegment('intersection'), \n",
    "      Cameras.timestamp\n",
    "    ) \n",
    "    AND contained(\n",
    "      table_1.trajCentroids, \n",
    "      roadSegment('intersection'), \n",
    "      Cameras.timestamp\n",
    "    ) \n",
    "    AND angleBetween(\n",
    "      facingRelative(\n",
    "        table_0.itemHeadings, Cameras.egoHeading, \n",
    "        Cameras.timestamp\n",
    "      ), \n",
    "      50, \n",
    "      135\n",
    "    ) \n",
    "    AND angleBetween(\n",
    "      facingRelative(\n",
    "        table_1.itemHeadings, Cameras.egoHeading, \n",
    "        Cameras.timestamp\n",
    "      ), \n",
    "      (-135), \n",
    "      (-50)\n",
    "    ) \n",
    "    AND (\n",
    "      minDistance(\n",
    "        Cameras.egoTranslation, \n",
    "        roadSegment('intersection')\n",
    "      )< 10\n",
    "    ) \n",
    "    AND angleBetween(\n",
    "      facingRelative(\n",
    "        table_0.itemHeadings, table_1.itemHeadings, \n",
    "        Cameras.timestamp\n",
    "      ), \n",
    "      100, \n",
    "      (-100)\n",
    "    ) \n",
    "    AND (1 = 1)\n",
    "  )\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512ae83-94bd-435f-bd57-3eb6d28a20d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in id_time_camId_filename:\n",
    "#     print(k[-2], str(k[-3]), k[-1])\n",
    "#     print(\"                                           \", *k[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6aee0-b1e0-4275-b6df-739824f10187",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename:\n",
    "    itemId1, itemId2, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    if filename not in resultImages:\n",
    "        resultImages[filename] = []\n",
    "    resultImages[filename].append((itemId1, itemId2, timestamp, camId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9434da-39cc-4396-8954-aae3a5ac79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from show_images import show_images\n",
    "%matplotlib inline\n",
    "\n",
    "# data_dir =  \"data/nuscenes/experiment_data\"\n",
    "data_dir = '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1c992-fe0c-48b1-96a1-f1f9aa5dddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(data_dir, list(resultImages.keys()), sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f4279-2b32-4f70-9742-dadc12e7cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_imgs = [\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657119112404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127612404.jpg',\n",
    "    'n008-2018-09-18-12-07-26-0400__CAM_FRONT__1537287358412404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118612404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127112404.jpg',\n",
    "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657128112404.jpg',\n",
    "]\n",
    "show_images(data_dir, expected_imgs, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5837a-34e2-4e52-b680-15cd81f05f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = 0\n",
    "missing_images = []\n",
    "for expected_img in expected_imgs:\n",
    "    if expected_img not in resultImages.keys():\n",
    "        missing += 1\n",
    "        missing_images.append(expected_img)\n",
    "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
    "show_images(data_dir, missing_images, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515c5a1-97bc-466b-8509-61af53eef2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = 0\n",
    "extra_images = {}\n",
    "for img in resultImages.keys():\n",
    "    if img not in expected_imgs:\n",
    "        extra += 1\n",
    "        extra_images[img] = resultImages[img]\n",
    "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(resultImages.keys()), \"=\", 100 * extra / len(resultImages.keys()), \"%\")\n",
    "show_images(data_dir, extra_images.keys(), sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da270b3-cf20-4c86-b37d-50671a925c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18513f3-1318-4902-bbcd-ca66c72e4709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc462d8-243a-44b5-bf75-b3ef6ee2322e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc08285-1129-4291-8d2f-43d45af28b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
