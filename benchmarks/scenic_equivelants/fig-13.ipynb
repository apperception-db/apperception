{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fce500-7081-4f17-b607-e0ef1638c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%pip install .\n",
    "import time\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# other1 = Car on intersection,\n",
    "#             facing Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# other2 = Car on intersection,\n",
    "#             facing -1 * Range(50, 135) deg relative to ego.heading\n",
    "\n",
    "# require abs(relative heading of other1 from other2) > 100 deg\n",
    "# require (distance from ego to intersectionRegion) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a55f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with (\n",
    "  select *\n",
    "  from item_traj\n",
    "  where item_traj.object_type = 'car'\n",
    ") as cars\n",
    "\n",
    "select *\n",
    "from cars as t1\n",
    "join cars as t2 on t1.cameraId = t2.cameraId\n",
    "join Cameras as cam on t1.cameraId = Cameras.id\n",
    "where\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) >= -15 AND\n",
    "  facingRelative(cam.egoHeading, road_direction(cam.ego_translation), cam.timestamp) <= 15 AND\n",
    "  DISTANCE(cam.egoTranslation, t1.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t1.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  DISTANCE(cam.egoTranslation, t2.centroid, cam.timestamp) < 50 AND\n",
    "  viewAngle(t2.traj, cam.egoHeading, cam.ego_Translation, cam.timestamp) < 135 AND\n",
    "  contained(t1.traj, road_segment_type(\"intersection\"), cam.timestamp) and\n",
    "  contained(t2.traj, road_segment_type(\"intersection\"), cam.timestamp) and\n",
    "  (facingRelative(t1.heading, cam.egoHeading, cam.timestamp) < -50 ANd\n",
    "  facingRelative(t1.heading, cam.egoHeading, cam.timestamp) > -135) AND\n",
    "  (facingRelative(t2.heading, cam.egoHeading, cam.timestamp) < -50 AND\n",
    "  facingRelative(t2.heading, cam.egoHeading, cam.timestamp) > -135) AND\n",
    "  DISTANCE(cam.egoTranslation, roadSection(\"intersection\"), cam.timestamp) < 10 AND\n",
    "  (facingRelative(t1.heading, t2.heading, cam.timestamp) > 100 OR\n",
    "  facingRelative(t1.heading, t2.heading, cam.timestmap) < -100)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def show_filenames(w, key_and_timestamps):\n",
    "    itemids = []\n",
    "    ts = []\n",
    "    for i in range(len(key_and_timestamps)):\n",
    "        itemids.append(key_and_timestamps[i][0])\n",
    "        ts.append(key_and_timestamps[i][-1])\n",
    "    # clean up the filenames\n",
    "    fnames = set(w.get_filenames_by_itemids_and_timestamps(itemids, ts))\n",
    "    fnames = [fname.split(\"/\")[-1] for fname in fnames]\n",
    "    return fnames\n",
    "\n",
    "def show_images_by_filenames(filenames):\n",
    "    folder = \"./data/experiment_data/\"\n",
    "    for name in filenames:\n",
    "        fname = folder + name\n",
    "        print(fname)\n",
    "        plt.figure()\n",
    "        plt.imshow(mpimg.imread(fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare the world for queries ###\n",
    "from apperception.new_world import *\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.new_db import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "world = world.filter(lambda obj: obj.object_type == 'vehicle.car')\n",
    "def pred(obj1, obj2, cam):\n",
    "    return (\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj1, cam.ego, cam.timestamp) < 135 and\n",
    "        F.distance(cam.ego, obj2, cam.timestamp) < 50 and\n",
    "        F.viewAngle(obj2, cam.ego, cam.timestamp) < 135 and\n",
    "        F.contained(obj1.traj, F.road_segment(\"intersection\"), cam.timestamp) and\n",
    "        F.contained(obj2.traj, F.road_segment(\"intersection\"), cam.timestamp) and\n",
    "        (F.facing_relative(obj1, cam.ego, cam.timestamp) >= 50 or\n",
    "            F.facing_relative(obj1, cam.ego, cam.timestamp) <= 135) and\n",
    "        (F.facing_relative(obj2, cam.ego, cam.timestamp) < -50 or\n",
    "            F.facing_relative(obj2, cam.ego, cam.timestamp) > -135) and\n",
    "        F.distance(cam.ego, roadSection(obj1.traj, cam.timestamp)) < 10 and\n",
    "        (F.facing_relative(obj1, obj2, cam.timestamp) > 100 or\n",
    "            F.facing_relative(obj1, obj2, cam.timestamp) < -100)\n",
    "    )\n",
    "world2 = world.filter(\"lambda obj1, obj2, cam: F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and \" + \n",
    "        \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and \" + \n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "        \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135 and \" +\n",
    "        \"F.distance(cam.ego, obj2, cam.timestamp) < 50 and \" +\n",
    "        \"F.view_angle(obj2, cam.ego, cam.timestamp) < 135 and \" +\n",
    "        \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp) and \" +\n",
    "        \"F.contained(obj2.traj, F.road_segment('intersection'), cam.timestamp) and \" +\n",
    "        \"(F.facing_relative(obj1, cam.ego, cam.timestamp) >= 50 or \" +\n",
    "            \"F.facing_relative(obj1, cam.ego, cam.timestamp) <= 135) and \" +\n",
    "        \"(F.facing_relative(obj2, cam.ego, cam.timestamp) < -50 or \" +\n",
    "            \"F.facing_relative(obj2, cam.ego, cam.timestamp) > -135) and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 10 and \" +\n",
    "        \"F.distance(cam.ego, obj2, cam.timestamp) < 10 and \" +\n",
    "        \"(F.facing_relative(obj1, obj2, cam.timestamp) > 100 or \" +\n",
    "            \"F.facing_relative(obj1, obj2, cam.timestamp) < -100)\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# key = world2.get_id_and_time(num_joined_tables=2)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d382ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*] The answer filename is in the result\n",
    "\n",
    "world2 = world.filter(\"lambda obj1, obj2, cam: \"+ # F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and \" + \n",
    "#         \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and \" + \n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "#         \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135 and \" +\n",
    "        \"F.distance(cam.ego, obj2, cam.timestamp) < 50 and \" +\n",
    "#         \"F.view_angle(obj2, cam.ego, cam.timestamp) < 135 and \" +\n",
    "        \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp) and \" +\n",
    "        \"F.contained(obj2.traj, F.road_segment('intersection'), cam.timestamp)\"\n",
    "#         \"(F.facing_relative(obj1, cam.ego, cam.timestamp) < -50 or \" +\n",
    "#             \"F.facing_relative(obj1, cam.ego, cam.timestamp) > -135) and \" +\n",
    "#         \"(F.facing_relative(obj2, cam.ego, cam.timestamp) < -50 or \" +\n",
    "#             \"F.facing_relative(obj2, cam.ego, cam.timestamp) > -135) and \" +\n",
    "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 10 and \" +\n",
    "#         \"F.distance(cam.ego, obj2, cam.timestamp) < 10 and \" +\n",
    "#         \"(F.facing_relative(obj1, obj2, cam.timestamp) > 100 or \" +\n",
    "#             \"F.facing_relative(obj1, obj2, cam.timestamp) < -100)\"\n",
    "        )\n",
    "\n",
    "key = world2.get_id_and_time(num_joined_tables=2)\n",
    "\"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg\" in show_filenames(world, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*] The answer filename is NOT in the result\n",
    "\n",
    "world2 = world.filter(\"lambda obj1, obj2, cam: F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) >= -15 and \" + \n",
    "        \"F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) <= 15 and \" + \n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
    "#         \"F.view_angle(obj1, cam.ego, cam.timestamp) < 135 and \" +\n",
    "        \"F.distance(cam.ego, obj2, cam.timestamp) < 50 and \" +\n",
    "#         \"F.view_angle(obj2, cam.ego, cam.timestamp) < 135 and \" +\n",
    "        \"F.contained(obj1.traj, F.road_segment('intersection'), cam.timestamp) and \" +\n",
    "        \"F.contained(obj2.traj, F.road_segment('intersection'), cam.timestamp)\"\n",
    "#         \"(F.facing_relative(obj1, cam.ego, cam.timestamp) < -50 or \" +\n",
    "#             \"F.facing_relative(obj1, cam.ego, cam.timestamp) > -135) and \" +\n",
    "#         \"(F.facing_relative(obj2, cam.ego, cam.timestamp) < -50 or \" +\n",
    "#             \"F.facing_relative(obj2, cam.ego, cam.timestamp) > -135) and \" +\n",
    "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 10 and \" +\n",
    "#         \"F.distance(cam.ego, obj2, cam.timestamp) < 10 and \" +\n",
    "#         \"(F.facing_relative(obj1, obj2, cam.timestamp) > 100 or \" +\n",
    "#             \"F.facing_relative(obj1, obj2, cam.timestamp) < -100)\"\n",
    "        )\n",
    "\n",
    "key = world2.get_id_and_time(num_joined_tables=2)\n",
    "\"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg\" in show_filenames(world, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ad8d9",
   "metadata": {},
   "source": [
    "# Database debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.new_db import database\n",
    "# database.reset()\n",
    "from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.cursor.execute(\n",
    "\"\"\"\n",
    "select * from cameras where  position('n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg' in filename) > 0 limit 5;\n",
    "\"\"\")\n",
    "database.cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ed698",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.cursor.execute(\n",
    "\"\"\"\n",
    "select roadDirection(Cameras.egoTranslation, Cameras.timestamp) from cameras where cameras.cameraid = 'scene-0757' AND cameras.timestamp = '2018-08-30 12:25:18.112404+00';\n",
    "\"\"\")\n",
    "database.cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a95c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.cursor.execute(\n",
    "\"\"\"\n",
    "select Cameras.egoHeading from cameras where cameras.cameraid = 'scene-0757' AND cameras.timestamp = '2018-08-30 12:25:18.112404+00';\n",
    "\"\"\"\n",
    ")\n",
    "database.cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.cursor.execute(\n",
    "\"\"\"\n",
    "select facingRelative(Cameras.egoHeading, roadDirection(Cameras.egoTranslation, Cameras.timestamp)) from cameras where cameras.cameraid = 'scene-0757' AND cameras.timestamp = '2018-08-30 12:25:18.112404+00';\n",
    "\"\"\")\n",
    "database.cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e8f20",
   "metadata": {},
   "source": [
    "# Find camera segment_id and heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f70905",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg\"\n",
    "\n",
    "def find_segmentid_and_heading_from_image(filename):\n",
    "    database.cursor.execute(\n",
    "    f\"\"\"\n",
    "    select * from cameras where  position('{filename}' in filename) > 0 limit 5;\n",
    "    \"\"\")\n",
    "    camera_id = database.cursor.fetchall()[0][0]\n",
    "    # print(camera_id)\n",
    "    database.cursor.execute(\n",
    "    f\"\"\"\n",
    "    select ST_asText(egoTranslation) from cameras where cameras.cameraid = '{camera_id}' limit 1;\n",
    "    \"\"\")\n",
    "    \n",
    "    ego_translation = database.cursor.fetchall()[0][0]\n",
    "    # print(ego_translation)\n",
    "    database.cursor.execute(\n",
    "    f\"\"\"\n",
    "    select segmentid, DEGREES(heading) from segment, ST_GeomFromText('{ego_translation}') as point order by ST_distance(segmentLine, point) asc limit 1;\n",
    "    \"\"\")\n",
    "    \n",
    "    out = database.cursor.fetchall()\n",
    "    \n",
    "    segment_id = out[0][0]\n",
    "    heading = out[0][1]\n",
    "    return segment_id, heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"n008-2018-09-18-12-07-26-0400__CAM_FRONT__1537287358412404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118612404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127612404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657128112404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127112404.jpg\", \"n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657119112404.jpg\"]\n",
    "df_dict = {\"filename\": [], \"segment_id\": [], \"heading\": []}\n",
    "for filename in filenames:\n",
    "    segment_id, heading = find_segmentid_and_heading_from_image(filename)\n",
    "    df_dict[\"filename\"].append(filename)\n",
    "    df_dict[\"segment_id\"].append(segment_id)\n",
    "    df_dict[\"heading\"].append(heading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd444af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(df_dict)\n",
    "display(df)\n",
    "df.to_csv(\"fig-13.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7906de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
