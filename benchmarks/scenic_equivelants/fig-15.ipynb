{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc36cc-806f-47fd-b0d5-5d18c40b2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "# %pip install .\n",
    "import time\n",
    "from os import environ\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# point1 = OrientedPoint ahead of ego by Range(0, 40)\n",
    "# Car at (point1 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa15bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['AP_PORT'] = str(input('port')) # README command uses port=25432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "\n",
    "experiment_data_dir =  \"data/nuscenes/experiment_data\"\n",
    "# experiment_data_dir = '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data'\n",
    "def show_images(images, sample=None):\n",
    "    if sample is not None:\n",
    "        images = [i for i in images]\n",
    "        random.shuffle(images)\n",
    "        images = images[:sample]\n",
    "    \n",
    "    plt.figure(figsize=(60,30))\n",
    "    columns = 3\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        print(\"image\", image)\n",
    "        img = mpimg.imread(os.path.join(experiment_data_dir, image))\n",
    "        print(\"loaded\")\n",
    "        plt.subplot(len(images) // columns + 1, columns, i + 1)\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First part of the query ####\n",
    "from apperception.world import empty_world\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.database import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "# world = world.predicate(lambda obj: obj.object_type == 'vehicle')\n",
    "def pred(obj1, cam):\n",
    "    return (\n",
    "        F.like(obj1.object_type, 'vehicle%') and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) > -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) < 15 and\n",
    "        F.view_angle(obj1, cam.ego, cam.timestamp) < 67.5 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 40 and\n",
    "        F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) > -15 and \n",
    "        F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) < 15 and\n",
    "        F.ahead(obj1, cam.ego, cam.timestamp)\n",
    "    )\n",
    "world = world.filter(\"lambda obj1, cam: \" +\n",
    "        \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.view_angle(obj1, cam.ego, cam.timestamp) < 67.5 and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(obj1, cam.ego, cam.timestamp)\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename_1 = world.get_id_time_camId_filename(num_joined_tables=1)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72918d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages_1 = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename_1:\n",
    "    itemId, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages_1[filename] = (itemId, timestamp, camId)\n",
    "    if filename == 'n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg':\n",
    "        print(\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f533502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# oppositeCar = Car offset by (Range(-10, -1), Range(0, 50)),\n",
    "#     facing Range(140, 180) deg relative to ego.heading\n",
    "\n",
    "# point2 = OrientedPoint ahead of oppositeCar by Range(0, 40)\n",
    "# Car at (point2 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3237c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second part of the query ###\n",
    "from apperception.world import empty_world\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "\n",
    "world = world.filter(\"lambda opposite_car, car2, cam: \" +\n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) > [-10, 0] and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) < [-1, 50] and \" +\n",
    "        \"F.angle_between(F.facing_relative(opposite_car, cam.ego, cam.timestamp), 140, 180) and \" +\n",
    "        \"F.like(car2.object_type, 'vehicle%') and F.like(opposite_car.object_type, 'vehicle%') and \" +\n",
    "        \"opposite_car.itemId != car2.itemId and \" +\n",
    "        \"F.distance(opposite_car, car2, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(car2, F.road_direction(car2.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(car2, opposite_car, cam.timestamp)\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename_2 = world.get_id_time_camId_filename(num_joined_tables=2)\n",
    "# print([e[4] for e in id_time_camId_filename_2])\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages_2 = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename_2:\n",
    "    itemId_1, itemId_2, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages_2[filename] = [(itemId_1, itemId_2, timestamp, camId)] if filename not in resultImages_2 else resultImages_2[filename]+[(itemId_1, itemId_2, timestamp, camId)]\n",
    "print(resultImages_2['n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(list(resultImages_2.keys()), sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_imgs = [\"n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg\", \"n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920662404.jpg\"]\n",
    "show_images(expected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8cff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting info about the expected images\n",
    "from apperception.database import database\n",
    "for img in expected_imgs:\n",
    "    prefix = \"samples/CAM_FRONT/\"\n",
    "    query = f\"\"\"SELECT \n",
    "    \\'Camera: \\', Cameras.egoHeading, ST_X(Cameras.egoTranslation), ST_Y(Cameras.egoTranslation), ST_Z(Cameras.egoTranslation),\n",
    "    \\'Cars: \\', table_0.itemId, getX(table_0.trajCentroids, Cameras.timestamp), getY(table_0.trajCentroids, Cameras.timestamp), \n",
    "    ST_Z(valueAtTimestamp(table_0.trajCentroids, Cameras.timestamp)), \n",
    "    \\'Distance: \\', distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp),\n",
    "    \\'CarHeading:\\', valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp),\n",
    "    \\'RoadDirection for car:\\', roadDirection(table_0.trajCentroids, Cameras.timestamp, valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp)::real),\n",
    "    \\'Ahead: \\', ahead(table_0.trajCentroids, Cameras.egoTranslation, Cameras.egoHeading, Cameras.timestamp),\n",
    "    \\'Angle to ego: \\', facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp) \n",
    "    FROM Item_General_Trajectory AS table_0, Cameras\n",
    "                WHERE Cameras.filename = \\'{prefix + img}\\' AND table_0.cameraId = Cameras.cameraId \n",
    "                AND table_0.objectType LIKE 'vehicle%' \n",
    "                AND getX(table_0.trajCentroids, Cameras.timestamp) IS NOT NULL\n",
    "\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b424020",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test ahead#\n",
    "from apperception.database import database\n",
    "from datetime import datetime\n",
    "for pair in resultImages_2['n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg']:\n",
    "    itemId_1, itemId_2, timestamp, camId = pair\n",
    "    query = f\"\"\"SELECT ahead(t2.trajCentroids,  t1.trajCentroids, t1.itemHeadings, cameras.timestamp),\n",
    "                ST_AsText(valueAtTimestamp(t2.trajCentroids, cameras.timestamp)), \n",
    "                ST_AsText(valueAtTimestamp(t1.trajCentroids, cameras.timestamp)), \n",
    "                valueAtTimestamp(t1.itemHeadings, cameras.timestamp) \n",
    "            FROM Item_General_Trajectory AS t1, Item_General_Trajectory AS t2, Cameras\n",
    "            WHERE t1.itemId = \\'{itemId_1}\\' AND t2.itemID = \\'{itemId_2}\\' AND Cameras.timestamp = \\'{timestamp}\\';\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test ahead#\n",
    "from apperception.database import database\n",
    "\n",
    "query = f\"\"\"SELECT (1893.895627360433 - 1927.3625156512157) * COS(PI() * (59.95824 + 90) / 180) + (1071.884001618687 - 1053.3215015295318) * SIN(PI() * (59.95824 + 90) / 180),\n",
    "         ST_AsText(convertCamera(st_point(1893.895627360433, 1071.884001618687), st_point(1927.3625156512157, 1053.3215015295318), 59.95824));\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96410c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### But for Scenic, all three cars should be in the scene ####\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# point1 = OrientedPoint ahead of ego by Range(0, 40)\n",
    "# Car at (point1 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# oppositeCar = Car offset by (Range(-10, -1), Range(0, 50)),\n",
    "#     facing Range(140, 180) deg relative to ego.heading\n",
    "\n",
    "# point2 = OrientedPoint ahead of oppositeCar by Range(0, 40)\n",
    "# Car at (point2 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "from apperception.world import empty_world\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "world = world.filter(\"lambda car1, opposite_car, car2, cam: \" +\n",
    "        \"F.like(car1.object_type, 'vehicle%') and \" +\n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.view_angle(car1, cam.ego, cam.timestamp) < 67.5 and \" +\n",
    "        \"F.distance(cam.ego, car1, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(car1, F.road_direction(car1.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(car1, cam.ego, cam.timestamp) and \" + \n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) > [-10, 0] and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) < [-1, 50] and \" +\n",
    "        \"F.angle_between(F.facing_relative(opposite_car, cam.ego, cam.timestamp), 140, 180) and \" +\n",
    "        \"F.like(car2.object_type, 'vehicle%') and F.like(opposite_car.object_type, 'vehicle%') and \" +\n",
    "        \"opposite_car.itemId != car2.itemId and car1.itemId != car2.itemId and car1.itemId != opposite_car.itemId and \" +\n",
    "        \"F.distance(opposite_car, car2, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(car2, F.road_direction(car2.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(car2, opposite_car, cam.timestamp)\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename_2 = world.get_id_time_camId_filename(num_joined_tables=2)\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc0ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
