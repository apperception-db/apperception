{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc36cc-806f-47fd-b0d5-5d18c40b2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "# %pip install .\n",
    "import time\n",
    "from os import environ\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# point1 = OrientedPoint ahead of ego by Range(0, 40)\n",
    "# Car at (point1 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa15bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if environ[\"AP_PORT\"] is None:\n",
    "    environ[\"AP_PORT\"] = str(input('port'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from show_images import show_images\n",
    "%matplotlib inline\n",
    "\n",
    "# data_dir =  \"data/nuscenes/experiment_data\"\n",
    "# data_dir = '/work/apperception/data/nuScenes/full-dataset-v1.0/Trainval/experiment_data'\n",
    "data_dir = '/Users/chanwutk/Documents/experiment_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First part of the query ####\n",
    "from apperception.world import empty_world\n",
    "# directly ingest the mini dataset and boston roadnetwork if needed\n",
    "# from apperception.database import database\n",
    "# database.reset()\n",
    "# from benchmarks.ingest_scenic_data import ingest_data\n",
    "# ingest_data()\n",
    "\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "# world = world.predicate(lambda obj: obj.object_type == 'vehicle')\n",
    "def pred(obj1, cam):\n",
    "    return (\n",
    "        F.like(obj1.object_type, 'vehicle%') and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) > -15 and\n",
    "        F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp), cam.timestamp) < 15 and\n",
    "        F.view_angle(obj1, cam.ego, cam.timestamp) < 67.5 and\n",
    "        F.distance(cam.ego, obj1, cam.timestamp) < 40 and\n",
    "        F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) > -15 and \n",
    "        F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp) < 15 and\n",
    "        F.ahead(obj1, cam.ego, cam.timestamp)\n",
    "    )\n",
    "world = world.filter(\"lambda obj1, cam: \" +\n",
    "        \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.view_angle(obj1, cam.ego, cam.timestamp) < 70 / 2 and \" +\n",
    "        \"F.distance(cam.ego, obj1, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(obj1, cam.ego, cam.timestamp)\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename_1 = world.get_id_time_camId_filename(num_joined_tables=1)\n",
    "\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72918d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages_1 = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename_1:\n",
    "    itemId, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages_1[filename] = (itemId, timestamp, camId)\n",
    "    if filename == 'n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg':\n",
    "        print(\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f533502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# oppositeCar = Car offset by (Range(-10, -1), Range(0, 50)),\n",
    "#     facing Range(140, 180) deg relative to ego.heading\n",
    "\n",
    "# point2 = OrientedPoint ahead of oppositeCar by Range(0, 40)\n",
    "# Car at (point2 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3237c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second part of the query ###\n",
    "from apperception.world import empty_world\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "\n",
    "world = world.filter(\"lambda opposite_car, car2, cam: \" +\n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) > [-10, 0] and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) < [-1, 50] and \" +\n",
    "        \"F.angle_between(F.facing_relative(opposite_car, cam.ego, cam.timestamp), 140, 180) and \" +\n",
    "        \"F.like(car2.object_type, 'vehicle%') and F.like(opposite_car.object_type, 'vehicle%') and \" +\n",
    "        \"opposite_car.itemId != car2.itemId and \" +\n",
    "        \"F.distance(opposite_car, car2, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(car2, F.road_direction(car2.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(car2, opposite_car, cam.timestamp)\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename_2 = world.get_id_time_camId_filename(num_joined_tables=2)\n",
    "# print([e[4] for e in id_time_camId_filename_2])\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages_2 = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename_2:\n",
    "    itemId_1, itemId_2, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages_2[filename] = [(itemId_1, itemId_2, timestamp, camId)] if filename not in resultImages_2 else resultImages_2[filename]+[(itemId_1, itemId_2, timestamp, camId)]\n",
    "print(resultImages_2['n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resultImages_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(data_dir, list(resultImages_2.keys()), sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_imgs = [\"n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg\", \"n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920662404.jpg\"]\n",
    "show_images(data_dir, expected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8cff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting info about the expected images\n",
    "from apperception.database import database\n",
    "for img in expected_imgs:\n",
    "    prefix = \"samples/CAM_FRONT/\"\n",
    "    query = f\"\"\"SELECT \n",
    "    \\'Camera: \\', Cameras.egoHeading, ST_X(Cameras.egoTranslation), ST_Y(Cameras.egoTranslation), ST_Z(Cameras.egoTranslation),\n",
    "    \\'Cars: \\', table_0.itemId, getX(table_0.trajCentroids, Cameras.timestamp), getY(table_0.trajCentroids, Cameras.timestamp), \n",
    "    ST_Z(valueAtTimestamp(table_0.trajCentroids, Cameras.timestamp)), \n",
    "    \\'Distance: \\', distance(Cameras.egoTranslation, table_0.trajCentroids, Cameras.timestamp),\n",
    "    \\'CarHeading:\\', valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp),\n",
    "    \\'RoadDirection for car:\\', roadDirection(table_0.trajCentroids, Cameras.timestamp, valueAtTimestamp(table_0.itemHeadings, Cameras.timestamp)::real),\n",
    "    \\'Ahead: \\', ahead(table_0.trajCentroids, Cameras.egoTranslation, Cameras.egoHeading, Cameras.timestamp),\n",
    "    \\'Angle to ego: \\', facingRelative(table_0.itemHeadings, Cameras.egoHeading, Cameras.timestamp) \n",
    "    FROM Item_General_Trajectory AS table_0, Cameras\n",
    "                WHERE Cameras.filename = \\'{prefix + img}\\' AND table_0.cameraId = Cameras.cameraId \n",
    "                AND table_0.objectType LIKE 'vehicle%' \n",
    "                AND getX(table_0.trajCentroids, Cameras.timestamp) IS NOT NULL \n",
    "                AND ahead(table_0.trajCentroids, Cameras.egoTranslation, Cameras.egoHeading, Cameras.timestamp)\n",
    "\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b424020",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test ahead#\n",
    "from apperception.database import database\n",
    "from datetime import datetime\n",
    "for pair in resultImages_2['n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg']:\n",
    "    itemId_1, itemId_2, timestamp, camId = pair\n",
    "    query = f\"\"\"SELECT ahead(t2.trajCentroids,  t1.trajCentroids, t1.itemHeadings, cameras.timestamp),\n",
    "                ST_AsText(valueAtTimestamp(t2.trajCentroids, cameras.timestamp)), \n",
    "                ST_AsText(valueAtTimestamp(t1.trajCentroids, cameras.timestamp)), \n",
    "                valueAtTimestamp(t1.itemHeadings, cameras.timestamp) \n",
    "            FROM Item_General_Trajectory AS t1, Item_General_Trajectory AS t2, Cameras\n",
    "            WHERE t1.itemId = \\'{itemId_1}\\' AND t2.itemID = \\'{itemId_2}\\' AND Cameras.timestamp = \\'{timestamp}\\';\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test ahead#\n",
    "from apperception.database import database\n",
    "\n",
    "query = f\"\"\"SELECT (1893.895627360433 - 1892.33194497499) * COS(PI() * (-120.12033333353695 + 90) / 180) + (1071.884001618687 - 1069.61352152532) * SIN(PI() * (-120.12033333353695 + 90) / 180),\n",
    "         ABS(ST_X(convertCamera(st_point(1893.895627360433, 1071.884001618687), st_point(1892.33194497499, 1069.61352152532), -120.12033333353695)));\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96410c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### But for Scenic, all three cars should be in the scene ####\n",
    "# ego = Car on drivableRoad,\n",
    "#         facing Range(-15, 15) deg relative to roadDirection,\n",
    "#         with visibleDistance 50,\n",
    "#         with viewAngle 135 deg\n",
    "\n",
    "# point1 = OrientedPoint ahead of ego by Range(0, 40)\n",
    "# Car at (point1 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "# oppositeCar = Car offset by (Range(-10, -1), Range(0, 50)),\n",
    "#     facing Range(140, 180) deg relative to ego.heading\n",
    "\n",
    "# point2 = OrientedPoint ahead of oppositeCar by Range(0, 40)\n",
    "# Car at (point2 offset by Range(-1, 1) @ 0),\n",
    "#     facing Range(-15, 15) deg relative to roadDirection\n",
    "\n",
    "from apperception.world import empty_world\n",
    "\n",
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)\n",
    "\n",
    "### Query ###\n",
    "from apperception.utils import F\n",
    "world = world.filter(\"lambda car1, opposite_car, car2, cam: \" +\n",
    "        \"F.like(car1.object_type, 'vehicle%') and \" +\n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.view_angle(car1, cam.ego, cam.timestamp) < 70 / 2 and \" +\n",
    "        \"F.distance(cam.ego, car1, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(car1, cam.ego, cam.timestamp), -15, 15) and \" +\n",
    "        \"F.angle_between(F.facing_relative(car1, F.road_direction(car1.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(car1, cam.ego, cam.timestamp) and \" + \n",
    "        \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) > [-10, 0] and \" +\n",
    "        \"F.convert_camera(opposite_car, cam.ego, cam.timestamp) < [-1, 50] and \" +\n",
    "        \"F.angle_between(F.facing_relative(opposite_car, cam.ego, cam.timestamp), 140, 180) and \" +\n",
    "        \"F.like(car2.object_type, 'vehicle%') and F.like(opposite_car.object_type, 'vehicle%') and \" +\n",
    "        \"opposite_car.itemId != car2.itemId and car1.itemId != car2.itemId and car1.itemId != opposite_car.itemId and \" +\n",
    "        \"F.distance(opposite_car, car2, cam.timestamp) < 40 and \" +\n",
    "        \"F.angle_between(F.facing_relative(car2, F.road_direction(car2.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
    "        \"F.ahead(car2, opposite_car, cam.timestamp)\")\n",
    "\n",
    "start = time.time()\n",
    "# keys = world.get_traj_key()\n",
    "id_time_camId_filename_final = world.get_id_time_camId_filename(num_joined_tables=3)\n",
    "end = time.time()\n",
    "print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages_final = dict() # maping from image -> (itemId, timestamp, camId) that it was found at\n",
    "for result in id_time_camId_filename_final:\n",
    "    car_1, oppositecar, car_2, timestamp, camId, filename = result\n",
    "    filename = filename.split(\"/\")[-1] # use split so that prefix path is not included in filename\n",
    "    resultImages_final[filename] = [(car_1, oppositecar, car_2, timestamp, camId)] if filename not in resultImages_final else resultImages_final[filename]+[(itemId_1, itemId_2, timestamp, camId)]\n",
    "print(resultImages_final['n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resultImages_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(data_dir, list(resultImages_final.keys()), sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979e08c-2061-4bbf-8fd4-60bdcdab91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = 0\n",
    "missing_images = []\n",
    "for expected_img in expected_imgs:\n",
    "    if expected_img not in resultImages_final.keys():\n",
    "        missing += 1\n",
    "        missing_images.append(expected_img)\n",
    "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
    "show_images(data_dir, missing_images, sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149284f4-c9c9-4eb0-8560-bb016ab454a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = 0\n",
    "extra_images = {}\n",
    "for img in resultImages_final.keys():\n",
    "    if img not in expected_imgs:\n",
    "        extra += 1\n",
    "        extra_images[img] = resultImages_final[img]\n",
    "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(resultImages_final.keys()), \"=\", 100 * extra / len(resultImages_final.keys()), \"%\")\n",
    "show_images(data_dir, extra_images, sample=10, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "from datetime import datetime\n",
    "for pair in resultImages_final['n008-2018-08-21-11-53-44-0400__CAM_FRONT__1534867377412404.jpg']:\n",
    "    car_1, oppositecar, car_2, timestamp, camId = pair\n",
    "    query = f\"\"\"SELECT \n",
    "                distance(Cameras.egoTranslation, t1.trajCentroids, Cameras.timestamp),\n",
    "                ahead(t2.trajCentroids,  t1.trajCentroids, t1.itemHeadings, cameras.timestamp),\n",
    "                ST_AsText(valueAtTimestamp(t2.trajCentroids, cameras.timestamp)), \n",
    "                ST_AsText(valueAtTimestamp(t1.trajCentroids, cameras.timestamp)), \n",
    "                valueAtTimestamp(t1.itemHeadings, cameras.timestamp) \n",
    "            FROM Item_General_Trajectory AS t1, Item_General_Trajectory AS t2, Item_General_Trajectory AS t3, Cameras\n",
    "            WHERE t1.itemId = \\'{car_1}\\' AND t2.itemID = \\'{oppositecar}\\' AND t3.itemId = \\'{car_2}\\'\n",
    "            AND Cameras.timestamp = \\'{timestamp}\\';\"\"\"\n",
    "    database.cursor.execute(query)\n",
    "    result = database.cursor.fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0045e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "\n",
    "query = f\"\"\"SELECT (1893.895627360433 - 1927.3625156512157) * COS(PI() * (59.95824 + 90) / 180) + (1071.884001618687 - 1053.3215015295318) * SIN(PI() * (59.95824 + 90) / 180),\n",
    "         ST_AsText(convertCamera(st_point(1893.895627360433, 1071.884001618687), st_point(1927.3625156512157, 1053.3215015295318), 59.95824));\"\"\"\n",
    "database.cursor.execute(query)\n",
    "result = database.cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136aca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImages_final['n008-2018-08-21-11-53-44-0400__CAM_FRONT__1534867377412404.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad98882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d1682-6a66-4020-841f-a825635de579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
