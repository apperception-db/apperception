{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the .apperception_cache if it exists, as to avoid DB conflict errors\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "dirpath = os.path.join('.apperception_cache')\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "# This piece of code is unsafe, and should not be run if not needed. \n",
    "# It serves for test purposes when one recieves a \"dead kernel\" error.\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"apperception\"))\n",
    "\n",
    "### IMPORTS\n",
    "import lens\n",
    "import point\n",
    "from new_world import empty_world\n",
    "\n",
    "# Let's define some attribute for constructing the world first\n",
    "name = \"trafficScene\"  # world name\n",
    "units = \"metrics\"  # world units\n",
    "video_file = \"amber_videos/traffic-scene-shorter.mp4\"  # example video file\n",
    "lens_attrs = {\"fov\": 120, \"cam_origin\": (0, 0, 0), \"skew_factor\": 0}\n",
    "point_attrs = {\"p_id\": \"p1\", \"cam_id\": \"cam1\", \"x\": 0, \"y\": 0, \"z\": 0, \"time\": None, \"type\": \"pos\"}\n",
    "camera_attrs = {\"ratio\": 0.5}\n",
    "fps = 30\n",
    "\n",
    "# 1. define a world\n",
    "traffic_world = empty_world(name)\n",
    "\n",
    "# 2. construct a camera\n",
    "fov, res, cam_origin, skew_factor = (\n",
    "    lens_attrs[\"fov\"],\n",
    "    [1280, 720],\n",
    "    lens_attrs[\"cam_origin\"],\n",
    "    lens_attrs[\"skew_factor\"],\n",
    ")\n",
    "cam_lens = lens.PinholeLens(res, cam_origin, fov, skew_factor)\n",
    "\n",
    "pt_id, cam_id, x, y, z, time, pt_type = (\n",
    "    point_attrs[\"p_id\"],\n",
    "    point_attrs[\"cam_id\"],\n",
    "    point_attrs[\"x\"],\n",
    "    point_attrs[\"y\"],\n",
    "    point_attrs[\"z\"],\n",
    "    point_attrs[\"time\"],\n",
    "    point_attrs[\"type\"],\n",
    ")\n",
    "location = point.Point(pt_id, cam_id, (x, y, z), time, pt_type)\n",
    "\n",
    "ratio = camera_attrs[\"ratio\"]\n",
    "\n",
    "# ingest the camera into the world\n",
    "traffic_world = traffic_world.add_camera(\n",
    "    cam_id=cam_id,\n",
    "    location=location,\n",
    "    ratio=ratio,\n",
    "    video_file=video_file,\n",
    "    metadata_identifier=name + \"_\" + cam_id,\n",
    "    lens=cam_lens,\n",
    ")\n",
    "\n",
    "# Call execute on the world to run the detection algorithm and save the real data to the database\n",
    "recognized_world = traffic_world.recognize(cam_id)\n",
    "\n",
    "volume = traffic_world.select_intersection_of_interest_or_use_default(cam_id=cam_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = traffic_world.get_camera()\n",
    "lens = traffic_world.get_len()\n",
    "# ids = traffic_world.get_id()\n",
    "print(\"cameras are\", cams)\n",
    "print(\"lens are\", lens)\n",
    "# print(\"ids are\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Query\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\").filter_traj_volume(volume).interval(0, fps * 3)\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\").interval(0, fps * 3)\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40))\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\")\n",
    "\n",
    "## OPTION 1 ###\n",
    "filtered_world = filtered_world.filter_relative_to_type(relative=lambda obj, camera: -10 <= (camera.x - obj.x) <= 10 \\\n",
    "                                                                                  and 20 <= (camera.y - obj.y) <= 40,\n",
    "                                                        type=\"camera\")\n",
    "# The idea is that the user passes in a lambda function, that specifies the relationship that must be met between the queried\n",
    "# object, and some object of the type passed to the function. In this case, the lambda function filters such that the offset \n",
    "# is between -10 and 10 in the x direction, and between 20 and 40 in the y direction, relative to some camera.\n",
    "\n",
    "### OPTION 2 ###\n",
    "filtered_world = filtered_world.filter_relative_to_type(offset=((-10, 10), (20, 40), None), heading=None, type=\"camera\")\n",
    "# The idea is that filter_offset_type() takes in two arguments: the offset in terms of coordinates, a relative heading \n",
    "# as well as the type of object to be offset from. In this case, we want it to be somehwere between -10 and 10 units\n",
    "# offset relative to a camera's x position, somehwere between 20 and 40 units offset relative to some camera's y position, \n",
    "# and we dont care about the offset relative to the camera's z position. We also dont care about the relative heading difference.\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40)), \n",
    "# \tfacing Range(-5, 5) deg\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\")\n",
    "\n",
    "## OPTION 1 ###\n",
    "filtered_world = filtered_world.filter_relative_to_type(relative=lambda obj, camera: -10 <= (camera.x - obj.x) <= 10 \\\n",
    "                                                                                  and 20 <= (camera.y - obj.y) <= 40,\n",
    "                                                        type=\"camera\")\n",
    "\n",
    "### OPTION 2 ###\n",
    "filtered_world = filtered_world.filter_relative_to_type(offset=((-10, 10), (20, 40), None), heading=None, type=\"camera\")\n",
    "\n",
    "filtered_world = filtered_world.filter_heading(-5, 5)\n",
    "# Filters for objects that have heading between -5 and 5 degrees\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car offset by (Range(-10, 10), Range(20, 40)), \n",
    "# \tfacing Range(-5, 5) deg relative to ego\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\")\n",
    "\n",
    "## OPTION 1 ###\n",
    "filtered_world = filtered_world.filter_relative_to_type(relative=lambda obj, camera: -10 <= (camera.x - obj.x) <= 10 \\\n",
    "                                                                                  and 20 <= (camera.y - obj.y) <= 40 \\\n",
    "                                                                                  and -5 <= (camera.heading - obj.heading) <= 5,\n",
    "                                                        type=\"camera\")\n",
    "# Now filtering for a relative heading between -5 and 5 degrees\n",
    "\n",
    "### OPTION 2 ###\n",
    "filtered_world = filtered_world.filter_relative_to_type(offset=((-10, 10), (20, 40), None), heading=(-5, 5), type=\"camera\")\n",
    "# Now filtering for a relative heading between -5 and 5 degrees\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car left of ego by 0.25 \n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\")\n",
    "\n",
    "## OPTION 1 ###\n",
    "def left_of(obj, camera):\n",
    "    expec_x = obj.x + 0.25 * np.cos(camera.heading)\n",
    "    expec_y = obj.y - 0.25 * np.sin(camera.heading)\n",
    "    # Should also allow some sort of variation, to account for noise (and since exact equality is unlikley)\n",
    "    return (expec_x == camera.x) and (expec_y == camera.y)\n",
    "\n",
    "filtered_world = filtered_world.filter_relative_to_type(relative=left_of, type=\"camera\")\n",
    "# Now filtering such that the car is left of ego by 0.25 units\n",
    "\n",
    "### OPTION 2 ##\n",
    "# Not possible\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# badAngle = Range(10, 20) deg\n",
    "# Car left of ego by 0.25,\n",
    "# \tfacing badAngle relative to ego\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\")\n",
    "\n",
    "## OPTION 1 ###\n",
    "def filter(obj, camera):\n",
    "    expec_x = obj.x + 0.25 * np.cos(camera.heading)\n",
    "    expec_y = obj.y - 0.25 * np.sin(camera.heading)\n",
    "    # Should also allow some sort of variation, to account for noise (and since exact equality is unlikley)\n",
    "    return (expec_x == camera.x) and (expec_y == camera.y) and 10 <= (camera.heading - obj.heading) <= 20\n",
    "\n",
    "filtered_world = filtered_world.filter_relative_to_type(relative=filter, type=\"camera\")\n",
    "# Now filtering such that the car is left of ego by 0.25 units\n",
    "\n",
    "### OPTION 2 ##\n",
    "# Not possible\n",
    "\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36b9f45d2c0c5940d48526f9dac9a46c8afda5d718c8f108cd3f22cd85be16c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
