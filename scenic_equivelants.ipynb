{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the .apperception_cache if it exists, as to avoid DB conflict errors\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "dirpath = os.path.join('.apperception_cache')\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "# This piece of code is unsafe, and should not be run if not needed. \n",
    "# It serves for test purposes when one recieves a \"dead kernel\" error.\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get backend Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"apperception\"))\n",
    "\n",
    "### IMPORTS\n",
    "import lens\n",
    "import point\n",
    "from new_world import empty_world\n",
    "\n",
    "# Let's define some attribute for constructing the world first\n",
    "name = \"trafficScene\"  # world name\n",
    "units = \"metrics\"  # world units\n",
    "video_file = \"amber_videos/traffic-scene-shorter.mp4\"  # example video file\n",
    "lens_attrs = {\"fov\": 120, \"cam_origin\": (0, 0, 0), \"skew_factor\": 0}\n",
    "point_attrs = {\"p_id\": \"p1\", \"cam_id\": \"cam1\", \"x\": 0, \"y\": 0, \"z\": 0, \"time\": None, \"type\": \"pos\"}\n",
    "camera_attrs = {\"ratio\": 0.5}\n",
    "fps = 30\n",
    "\n",
    "# 1. define a world\n",
    "traffic_world = empty_world(name)\n",
    "\n",
    "# 2. construct a camera\n",
    "fov, res, cam_origin, skew_factor = (\n",
    "    lens_attrs[\"fov\"],\n",
    "    [1280, 720],\n",
    "    lens_attrs[\"cam_origin\"],\n",
    "    lens_attrs[\"skew_factor\"],\n",
    ")\n",
    "cam_lens = lens.PinholeLens(res, cam_origin, fov, skew_factor)\n",
    "\n",
    "pt_id, cam_id, x, y, z, time, pt_type = (\n",
    "    point_attrs[\"p_id\"],\n",
    "    point_attrs[\"cam_id\"],\n",
    "    point_attrs[\"x\"],\n",
    "    point_attrs[\"y\"],\n",
    "    point_attrs[\"z\"],\n",
    "    point_attrs[\"time\"],\n",
    "    point_attrs[\"type\"],\n",
    ")\n",
    "location = point.Point(pt_id, cam_id, (x, y, z), time, pt_type)\n",
    "\n",
    "ratio = camera_attrs[\"ratio\"]\n",
    "\n",
    "# ingest the camera into the world\n",
    "traffic_world = traffic_world.add_camera(\n",
    "    cam_id=cam_id,\n",
    "    location=location,\n",
    "    ratio=ratio,\n",
    "    video_file=video_file,\n",
    "    metadata_identifier=name + \"_\" + cam_id,\n",
    "    lens=cam_lens,\n",
    ")\n",
    "\n",
    "# Call execute on the world to run the detection algorithm and save the real data to the database\n",
    "recognized_world = traffic_world.recognize(cam_id)\n",
    "\n",
    "volume = traffic_world.select_intersection_of_interest_or_use_default(cam_id=cam_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cameras are [('cam1', 0.5, 0.0, 0.0, 0.0, 369.5041722813606, 207.84609690826534, 120, 0.0)]\n",
      "lens are [(0.5, 0.0, 0.0, 0.0, 120, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "cams = traffic_world.get_camera()\n",
    "lens = traffic_world.get_len()\n",
    "# ids = traffic_world.get_id()\n",
    "print(\"cameras are\", cams)\n",
    "print(\"lens are\", lens)\n",
    "# print(\"ids are\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights from C:\\Users\\youse\\Desktop\\Research\\Apperception\\apperception\\apperception\\../yolov5-deepsort/deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7... Done!\n",
      "YOLOv5  v6.0-159-gdb6ec66 torch 1.10.2+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car-1 saved successfully\n",
      "person-2 saved successfully\n",
      "traffic light-3 saved successfully\n",
      "car-4 saved successfully\n",
      "car-6 saved successfully\n",
      "person-7 saved successfully\n",
      "traffic light-8 saved successfully\n",
      "person-9 saved successfully\n",
      "person-10 saved successfully\n",
      "traffic light-12 saved successfully\n",
      "person-12 saved successfully\n",
      "person-13 saved successfully\n",
      "car-14 saved successfully\n",
      "person-16 saved successfully\n",
      "bus-14 saved successfully\n",
      "car-19 saved successfully\n",
      "traffic light-10 saved successfully\n",
      "traffic light-13 saved successfully\n",
      "person-20 saved successfully\n",
      "car-21 saved successfully\n",
      "truck-21 saved successfully\n",
      "bus-21 saved successfully\n",
      "person-25 saved successfully\n",
      "person-26 saved successfully\n",
      "traffic light-26 saved successfully\n",
      "traffic light-9 saved successfully\n",
      "get_traj_key SELECT sq2.itemid FROM (SELECT * FROM (SELECT * FROM (SELECT * FROM item_general_trajectory WHERE worldId='5f8caac8-eb3d-4029-95b3-0433798957d3') sq0 WHERE sq0.objecttype='car') sq1 WHERE overlap(sq1.largestBbox,'STBOX Z((0.01082532, 2.59647246, 0),(3.01034039, 3.35985782, 2))')) sq2\n",
      "filtered_ids are [('car-1-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-4-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-14-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-21-5f8caac8-eb3d-4029-95b3-0433798957d3',)]\n"
     ]
    }
   ],
   "source": [
    "# Example Query\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\").filter_traj_volume(volume).interval(0, fps * 3)\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_traj_key SELECT sq1.itemid FROM (SELECT * FROM (SELECT * FROM item_general_trajectory WHERE worldId='5f8caac8-eb3d-4029-95b3-0433798957d3') sq0 WHERE sq0.objecttype='car') sq1\n",
      "filtered_ids are [('car-1-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-4-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-6-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-14-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-19-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-21-5f8caac8-eb3d-4029-95b3-0433798957d3',)]\n"
     ]
    }
   ],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\").interval(0, fps * 3)\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_traj_key SELECT sq1.itemid FROM (SELECT * FROM (SELECT * FROM item_general_trajectory WHERE worldId='5f8caac8-eb3d-4029-95b3-0433798957d3') sq0 WHERE sq0.objecttype='car') sq1\n",
      "filtered_ids are [('car-1-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-4-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-6-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-14-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-19-5f8caac8-eb3d-4029-95b3-0433798957d3',), ('car-21-5f8caac8-eb3d-4029-95b3-0433798957d3',)]\n"
     ]
    }
   ],
   "source": [
    "### Scenic Code ###\n",
    "# ego = Car\n",
    "# Car\n",
    "\n",
    "### Apperception Query ###\n",
    "filtered_world = recognized_world.filter_traj_type(\"car\").interval(0, fps * 3)\n",
    "filtered_ids = filtered_world.get_traj_key()\n",
    "print(\"filtered_ids are\", filtered_ids)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36b9f45d2c0c5940d48526f9dac9a46c8afda5d718c8f108cd3f22cd85be16c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
