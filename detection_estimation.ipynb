{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96432088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config, CameraConfig\n",
    "from optimized_ingestion.video import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.detection_estimation.segment_mapping import map_imgsegment_roadsegment, CameraSegmentMapping\n",
    "from optimized_ingestion.detection_estimation.utils import trajectory_3d\n",
    "from optimized_ingestion.detection_estimation.detection_estimation import construct_all_detection_info, detection_to_img_segment, obj_detection, generate_sample_plan, DetectionInfo, samplePlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.payload import Payload\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOSTON_VIDEO_DIR = os.path.join(os.environ['NUSCENES_PROCESSED_DATA'], 'videos/boston-seaport')\n",
    "BOSTON_VIDEO_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_loc3d_ground_truth = [(1991, 874), (1949.181, 873.164)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BOSTON_VIDEO_DIR, 'frames.pickle'), 'rb') as f:\n",
    "    videoconfigs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_detection(test_file_path: str, full_img_detection):\n",
    "    test_frame = cv2.imread(test_file_path)\n",
    "    for obj_idx, detection in full_img_detection.items():\n",
    "        obj_cls, bbox = detection\n",
    "        if obj_cls == 'car':\n",
    "            x,y,w,h = list(map(int,bbox))\n",
    "            cv2.rectangle(test_frame,(x-w//2,y-h//2),(x+w//2,y+h//2),(0,255,0),2)\n",
    "            cv2.putText(test_frame, '_'.join([obj_cls, str(obj_idx)]), (x+w//2+5,y+h//2+5),0,0.3,(0,255,0))\n",
    "    cv2.imshow('detection', test_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdcba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(videoname: str, framesdict: dict) -> \"Video\":\n",
    "    videodata = framesdict[videoname]\n",
    "    filename = videodata['filename']\n",
    "    frames = videodata['frames']\n",
    "    configs = [camera_config(*f, 0) for f in frames]\n",
    "    return Video(os.path.join(BOSTON_VIDEO_DIR, filename), configs, videodata['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ego car trajectory\n",
    "def prepare_ego(test_video: str) -> \"Tuple[Video, List[trajectory_3d]]\":\n",
    "    video = get_video(test_video, videoconfigs)\n",
    "    ego_trajectory = [trajectory_3d(f.ego_translation, f.timestamp) for f in video]\n",
    "    return video, ego_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_plan_once(\n",
    "    video: \"str\",\n",
    "    ego_config: \"CameraConfig\",\n",
    "    mapping: \"List[CameraSegmentMapping]\",\n",
    "    next_frame_num: \"int\",\n",
    "    car_loc3d=None,\n",
    "    target_car_detection=None,\n",
    "    all_detection_info: \"List[obj_detection]\" = None\n",
    ") -> \"Tuple[samplePlan, None]\":\n",
    "    # if all_detection_info is None:\n",
    "    #     assert target_car_detection and car_loc3d\n",
    "    #     x,y,w,h = list(map(int, target_car_detection))\n",
    "    #     car_loc2d = (x, y+h//2)\n",
    "    #     car_bbox2d = (x-w//2,y-h//2,x+w//2,y+h//2)\n",
    "    #     car_bbox3d = None\n",
    "    #     all_detections = []\n",
    "    #     all_detections.append(obj_detection('car_1', car_loc3d, car_loc2d, car_bbox3d, car_bbox2d))\n",
    "    #     all_detection_info = construct_all_detection_info(cam_segment_mapping, ego_trajectory, ego_config, all_detections)\n",
    "    if all_detection_info:\n",
    "        print(all_detection_info[0].road_type)\n",
    "    next_sample_plan = generate_sample_plan(video, next_frame_num, all_detection_info,  50)\n",
    "    # next_frame = None\n",
    "    next_sample_frame_info = next_sample_plan.get_next_sample_frame_info()\n",
    "    if next_sample_frame_info:\n",
    "        next_sample_frame_name, next_sample_frame_num, _ = next_sample_frame_info\n",
    "        print(\"next frame name\", next_sample_frame_name)\n",
    "        print(\"next frame num\", next_sample_frame_num)\n",
    "    #     print(next_sample_plan.action)\n",
    "        # TODO: should not read next frame -> get the next frame from frames.pickle\n",
    "        # next_frame = cv2.imread(test_img_base_dir+next_sample_frame_name)\n",
    "#         cv2.imshow(\"next_frame\", next_frame)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "    return next_sample_plan, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be562f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_estimated_all_detection_info(\n",
    "    detections: \"npt.NDArray\",\n",
    "    cam_segment_mapping: \"List[CameraSegmentMapping]\",\n",
    "    ego_config: \"CameraConfig\",\n",
    "    ego_trajectory: \"trajectory_3d\"\n",
    ") -> \"List[DetectionInfo]\":\n",
    "    all_detections = []\n",
    "    for det in detections:\n",
    "        bbox = det[:4]\n",
    "        obj_cls = det[5]\n",
    "        x, y, x2, y2 = list(map(int,bbox))\n",
    "        w = x2 - x\n",
    "        h = y2 - y\n",
    "        car_loc2d = (x + w // 2, y+h//2)\n",
    "#         print(car_loc2d)\n",
    "        car_bbox2d = ((x-w//2, y-h//2), (x+w//2, y+h//2))\n",
    "        car_bbox3d = None\n",
    "        estimate_3d = detection_to_img_segment(car_loc2d, cam_segment_mapping)\n",
    "        if estimate_3d and estimate_3d.road_segment_info.segment_type in ['lane', 'laneSection']:\n",
    "            car_loc3d = tuple(Polygon(estimate_3d.road_segment_info.segment_polygon).centroid.coords)\n",
    "#             print(tuple(car_loc3d))\n",
    "            all_detections.append(obj_detection('car_1', car_loc3d, car_loc2d, car_bbox3d, car_bbox2d))\n",
    "    print(\"all_detections\", all_detections)\n",
    "    all_detection_info = construct_all_detection_info(cam_segment_mapping, ego_config, ego_trajectory, all_detections)\n",
    "    return all_detection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dry_run(\n",
    "    payload: \"Payload\",\n",
    "    start_frame_num: \"int\",\n",
    "    ego_trajectory: \"List[trajectory_3d]\",\n",
    "    video: \"str\"\n",
    "):\n",
    "    skipped_frame_num = []\n",
    "    next_frame_num = start_frame_num\n",
    "    action_type_counts = {}\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    display_video = cv2.VideoWriter(f'sampled_frames_{video.replace(\"/\", \"_\")}.avi',fourcc, 10, (1600, 900))\n",
    "    start_time = time.time()\n",
    "    total_detection_time = 0\n",
    "    total_sample_plan_time = 0\n",
    "    for i in range(len(payload.video)-1):\n",
    "        current_ego_config = payload.video[i]\n",
    "        if i != next_frame_num:\n",
    "            skipped_frame_num.append(i)\n",
    "            continue\n",
    "        next_frame_num = i + 1\n",
    "        cam_segment_mapping = map_imgsegment_roadsegment(current_ego_config)\n",
    "        print(\"mapping length\", len(cam_segment_mapping))\n",
    "        # current_frame = test_img_base_dir + current_ego_config['fileName']\n",
    "        # display_video.write(cv2.imread(current_frame))\n",
    "        start_detection_time = time.time()\n",
    "        all_detection_info = construct_estimated_all_detection_info(YoloDetection.get(payload)[i][0], cam_segment_mapping, current_ego_config, ego_trajectory)\n",
    "        total_detection_time += time.time()-start_detection_time\n",
    "        start_generate_sample_plan = time.time()\n",
    "        next_sample_plan, _ = generate_sample_plan_once(payload.video, current_ego_config, cam_segment_mapping, next_frame_num, all_detection_info=all_detection_info)\n",
    "        total_sample_plan_time += time.time() - start_generate_sample_plan\n",
    "        next_action_type = next_sample_plan.get_action_type()\n",
    "        if next_action_type not in action_type_counts:\n",
    "            action_type_counts[next_action_type] = 1\n",
    "        else:\n",
    "            action_type_counts[next_action_type] += 1\n",
    "        next_frame_num = next_sample_plan.get_next_frame_num(next_frame_num)\n",
    "\n",
    "    display_video.release()\n",
    "    print(\"sorted_ego_config_length\", len(payload.video))\n",
    "    print(\"number of skipped\", len(skipped_frame_num))\n",
    "    print(skipped_frame_num)\n",
    "    print(action_type_counts)\n",
    "    total_run_time = time.time()-start_time\n",
    "    num_runs = len(payload.video) - len(skipped_frame_num)\n",
    "    print(\"total_run_time\", total_run_time)\n",
    "    print(\"avg run time\", total_run_time/num_runs)\n",
    "    print(\"total_detection_time\", total_detection_time)\n",
    "    print(\"avg detection time\", total_detection_time/num_runs)\n",
    "    print(\"total_generate_sample_plan_time\", total_sample_plan_time)\n",
    "    print(\"avg generate_sample_plan time\", total_sample_plan_time/num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4423e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pipeline -> decoding frames -> 2D Detection -> 3D Detection\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_filter(ParallelDecodeFrame())\n",
    "pipeline.add_filter(YoloDetection())\n",
    "\n",
    "test_video1 = 'scene-0757-CAM_FRONT'\n",
    "video1, ego_trajectory1 = prepare_ego(test_video1)\n",
    "payload1 = pipeline.run(Payload(video1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run(payload1, 0, ego_trajectory1, test_video1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c61b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5f7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (apperception)",
   "language": "python",
   "name": "apperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
