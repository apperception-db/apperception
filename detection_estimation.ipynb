{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c9badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/chanwutk/code/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2022-11-22 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.filter_car_facing_sideway import FilterCarFacingSideway\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT\n",
    "from optimized_ingestion.stages.tracking_2d.tracking_2d import Tracking2D\n",
    "from optimized_ingestion.stages.tracking_3d.from_2d_and_road import From2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult\n",
    "# from optimized_ingestion.trackers.yolov5_strongsort_osnet_tracker import TrackingResult\n",
    "from optimized_ingestion.video import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cd29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOSTON_VIDEOS = [\n",
    "#     \"scene-0757-CAM_FRONT\",\n",
    "    # \"scene-0103-CAM_FRONT\",\n",
    "    # \"scene-0553-CAM_FRONT\",\n",
    "    # \"scene-0665-CAM_FRONT\",\n",
    "#     \"scene-0655-CAM_FRONT_RIGHT\",\n",
    "    \"scene-0655-CAM_BACK_RIGHT\",\n",
    "]\n",
    "\n",
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436432cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /data/chanwutk/code/weights/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2022-11-22 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0103-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "388\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "388\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                 | 0/387 [00:00<?, ?it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:77: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  a, b = line.boundary\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                     | 215/387 [00:05<00:05, 31.45it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:120: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for intersect in intersection:\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 387/387 [00:22<00:00, 17.16it/s]\n",
      "YOLOv5 🚀 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "None\n",
      "  filtered frames: 39.94845360824742%\n",
      "K..............................................................K............KK....................KK\n",
      ".K............K............K............K............KKKKKKKKKKKKK...K...K...KKKKKKKKKKKK...........\n",
      ".K............KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.......................K.....................K\n",
      "KKKKKKKKKKKKKKKKKKKK.............KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/chanwutk/code/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [02:02<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "388\n",
      "  filtered frames: 39.94845360824742%\n",
      "K..............................................................K............KK....................KK\n",
      ".K............K............K............K............KKKKKKKKKKKKK...K...K...KKKKKKKKKKKK...........\n",
      ".K............KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.......................K.....................K\n",
      "KKKKKKKKKKKKKKKKKKKK.............KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:00<00:00, 5895.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "388\n",
      "  filtered frames: 39.94845360824742%\n",
      "K..............................................................K............KK....................KK\n",
      ".K............K............K............K............KKKKKKKKKKKKK...K...K...KKKKKKKKKKKK...........\n",
      ".K............KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.......................K.....................K\n",
      "KKKKKKKKKKKKKKKKKKKK.............KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  FilterCarFacingSideway\n",
      "388\n",
      "388\n",
      "  filtered frames: 22.938144329896907%\n",
      "....................................................................................................\n",
      "........................................................KKK.....KK...K........KKKKKK................\n",
      ".K.............K.KKK.KK.K..KK.KK.KK..KKKK..KKKKKKKK..K..............................................\n",
      ".KK.KKKKKK.KKKKKKK................KKK.KKKKK.KK.K...KKKKKKKKKK..K..K..K.KK..KKK..K..KKKKK\n",
      "scene-0553-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "398\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "398\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                 | 0/397 [00:00<?, ?it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:77: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  a, b = line.boundary\n",
      "/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:120: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for intersect in intersection:\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 397/397 [01:13<00:00,  5.43it/s]\n",
      "YOLOv5 🚀 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "None\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/chanwutk/code/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 398/398 [03:21<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "398\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 398/398 [00:00<00:00, 6573.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "398\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  FilterCarFacingSideway\n",
      "398\n",
      "398\n",
      "  filtered frames: 93.96984924623115%\n",
      "..KK.KK.KKK.KKKK..KKK.KK.KKKK.KK.KKKKKKKKKKKKKKKK...KKKK.KKKK.KKKKK.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKK.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.KKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.KKK.KKKK.KKK.\n",
      "scene-0655-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                 | 0/395 [00:00<?, ?it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:77: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  a, b = line.boundary\n",
      " 36%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                       | 144/395 [00:11<00:07, 32.03it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:120: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for intersect in intersection:\n",
      " 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                       | 216/395 [00:20<00:35,  5.11it/s]TopologyException: Input geom 1 is invalid: Self-intersection at 1970.5685294845796 813.21200944847021\n",
      "Self-intersection at or near point 1970.5685294845796 813.21200944847021\n",
      " 56%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 223/395 [00:21<00:25,  6.88it/s]TopologyException: Input geom 1 is invalid: Self-intersection at 1971.6916461421656 813.45076914750007\n",
      "Self-intersection at or near point 1971.6916461421656 813.45076914750007\n",
      " 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                 | 225/395 [00:21<00:38,  4.46it/s]TopologyException: Input geom 1 is invalid: Self-intersection at 1971.6916461421656 813.45076914750007\n",
      "Self-intersection at or near point 1971.6916461421656 813.45076914750007\n",
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                | 226/395 [00:22<00:44,  3.83it/s]TopologyException: Input geom 1 is invalid: Self-intersection at 1971.6916461421656 813.45076914750007\n",
      "Self-intersection at or near point 1971.6916461421656 813.45076914750007\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 395/395 [01:24<00:00,  4.67it/s]\n",
      "YOLOv5 🚀 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "None\n",
      "  filtered frames: 63.13131313131313%\n",
      "KKKKKKKKKKKK....KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK...............K...............KKKKK.....\n",
      ".........KKKKKK............................KKKKKKKK...............KKKKKKKKK...............KKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKK.....KKKKKKK.....K.........K.........KKKK........KKKKKKKKKKKKKKKKKKKK....KKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/chanwutk/code/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 396/396 [01:22<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "396\n",
      "  filtered frames: 63.13131313131313%\n",
      "KKKKKKKKKKKK....KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK...............K...............KKKKK.....\n",
      ".........KKKKKK............................KKKKKKKK...............KKKKKKKKK...............KKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKK.....KKKKKKK.....K.........K.........KKKK........KKKKKKKKKKKKKKKKKKKK....KKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 396/396 [00:00<00:00, 12753.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "396\n",
      "  filtered frames: 63.13131313131313%\n",
      "KKKKKKKKKKKK....KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK...............K...............KKKKK.....\n",
      ".........KKKKKK............................KKKKKKKK...............KKKKKKKKK...............KKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKK.....KKKKKKK.....K.........K.........KKKK........KKKKKKKKKKKKKKKKKKKK....KKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  FilterCarFacingSideway\n",
      "396\n",
      "396\n",
      "  filtered frames: 25.505050505050505%\n",
      "..KK...KKK.K....KKKK.KK.KKKKKKKKKK...K.K.KK..KK.KKKKKKKKKKK...............K...................K.....\n",
      "..........KKK.K..............................KKKKKK...............K.KKK.K.K...................K.KK..\n",
      "KK..KK.KKK..K.KK.......KK.KK...............K.........KK.K..........K...K.KK.KKKK.KKK.............K..\n",
      ".....K.KK..KK......K...........................................K..K..KK........K................\n",
      "scene-0757-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "397\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "397\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                 | 0/396 [00:00<?, ?it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:77: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  a, b = line.boundary\n",
      "  1%|██▋                                                                                                                                                                                                                                                                      | 4/396 [00:00<00:32, 11.93it/s]/data/chanwutk/code/apperception/optimized_ingestion/stages/detection_estimation/utils.py:120: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for intersect in intersection:\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 396/396 [00:24<00:00, 15.86it/s]\n",
      "YOLOv5 🚀 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n",
      "None\n",
      "  filtered frames: 77.32997481108312%\n",
      "KKKK.......................KK....................K.........K..........KKKKKKKKKKKK..K..KK..KKKKKKKKK\n",
      "KKKKKKKKKKKK.........KKKKKKK..........KKKKKKK.K.K.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/chanwutk/code/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 397/397 [03:19<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "397\n",
      "  filtered frames: 77.32997481108312%\n",
      "KKKK.......................KK....................K.........K..........KKKKKKKKKKKK..K..KK..KKKKKKKKK\n",
      "KKKKKKKKKKKK.........KKKKKKK..........KKKKKKK.K.K.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 397/397 [00:00<00:00, 5565.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "397\n",
      "  filtered frames: 77.32997481108312%\n",
      "KKKK.......................KK....................K.........K..........KKKKKKKKKKKK..K..KK..KKKKKKKKK\n",
      "KKKKKKKKKKKK.........KKKKKKK..........KKKKKKK.K.K.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  FilterCarFacingSideway\n",
      "397\n",
      "397\n",
      "  filtered frames: 70.02518891687657%\n",
      "........................................................................KK.KKKKKKK..K..KK....KKKK.KK\n",
      "K.KK.KKK.KKK..........KKKKKK............KKKKK.K.K.KKKKKKKKKKK.KKKKK..KKKKKKKKKKKKKK.KKKKKKKKKKKKKKKK\n",
      "KKKK.KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK..KKKKKK.KKKKKKKKKKKKKK.KKKKKKKKKKKK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "# pipeline.add_filter(filter=InView(distance=10, segment_type=\"intersection\"))\n",
    "# pipeline.add_filter(filter=Stopped(min_stopped_frames=2, stopped_threshold=1.0))\n",
    "pipeline.add_filter(filter=DecodeFrame())\n",
    "pipeline.add_filter(filter=YoloDetection())\n",
    "\n",
    "pipeline.add_filter(filter=DetectionEstimation())  # 5 Frame p Second\n",
    "pipeline.add_filter(filter=StrongSORT())  # 2 Frame p Second\n",
    "\n",
    "pipeline.add_filter(filter=From2DAndRoad())\n",
    "pipeline.add_filter(filter=FilterCarFacingSideway())\n",
    "\n",
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "with open(os.path.join(DATA_DIR, \"videos/boston-seaport\", \"frames.pickle\"), \"rb\") as f:\n",
    "    videos = pickle.load(f)\n",
    "\n",
    "for name, video in videos.items():\n",
    "#     if name not in BOSTON_VIDEOS:\n",
    "#         continue\n",
    "#     if not name.endswith('CAM_FRONT'):\n",
    "#         continue\n",
    "\n",
    "    print(name, '--------------------------------------------------------------------------------')\n",
    "    frames = Video(\n",
    "        os.path.join(DATA_DIR, \"videos/boston-seaport\", video[\"filename\"]),\n",
    "        [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "        video[\"start\"],\n",
    "    )\n",
    "\n",
    "    output = pipeline.run(Payload(frames))\n",
    "\n",
    "benchmark = []\n",
    "for stage in pipeline.stages:\n",
    "    benchmark.append({\n",
    "        \"stage\": stage.classname(),\n",
    "        \"runtimes\": stage.runtimes,\n",
    "    })\n",
    "\n",
    "with open(\"./outputs/benchmark-with-estimation.json\", \"w\") as f3:\n",
    "    json.dump(benchmark, f3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "# pipeline.add_filter(filter=InView(distance=10, segment_type=\"intersection\"))\n",
    "# pipeline.add_filter(filter=Stopped(min_stopped_frames=2, stopped_threshold=1.0))\n",
    "pipeline.add_filter(filter=DecodeFrame())\n",
    "pipeline.add_filter(filter=YoloDetection())\n",
    "\n",
    "# pipeline.add_filter(filter=DetectionEstimation())  # 5 Frame p Second\n",
    "pipeline.add_filter(filter=StrongSORT())  # 2 Frame p Second\n",
    "\n",
    "pipeline.add_filter(filter=From2DAndRoad())\n",
    "pipeline.add_filter(filter=FilterCarFacingSideway())\n",
    "\n",
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "with open(os.path.join(DATA_DIR, \"videos/boston-seaport\", \"frames.pickle\"), \"rb\") as f:\n",
    "    videos = pickle.load(f)\n",
    "\n",
    "for name, video in videos.items():\n",
    "#     if name not in BOSTON_VIDEOS:\n",
    "#         continue\n",
    "#     if not name.endswith('CAM_FRONT'):\n",
    "#         continue\n",
    "\n",
    "    print(name, '--------------------------------------------------------------------------------')\n",
    "    frames = Video(\n",
    "        os.path.join(DATA_DIR, \"videos/boston-seaport\", video[\"filename\"]),\n",
    "        [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "        video[\"start\"],\n",
    "    )\n",
    "\n",
    "    output = pipeline.run(Payload(frames))\n",
    "\n",
    "benchmark = []\n",
    "for stage in pipeline.stages:\n",
    "    benchmark.append({\n",
    "        \"stage\": stage.classname(),\n",
    "        \"runtimes\": stage.runtimes,\n",
    "    })\n",
    "\n",
    "with open(\"./outputs/benchmark-without-estimation.json\", \"w\") as f3:\n",
    "    json.dump(benchmark, f3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (apperception)",
   "language": "python",
   "name": "apperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
