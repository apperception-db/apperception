{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6fece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import numpy.typing as npt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96432088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3f8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config, CameraConfig\n",
    "from optimized_ingestion.video import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6402e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.detection_estimation.segment_mapping import map_imgsegment_roadsegment, CameraSegmentMapping\n",
    "from optimized_ingestion.detection_estimation.utils import trajectory_3d\n",
    "# from optimized_ingestion.detection_estimation.sample_plan_algorithms import *\n",
    "from optimized_ingestion.detection_estimation.detection_estimation import construct_all_detection_info, detection_to_img_segment, obj_detection, generate_sample_plan, DetectionInfo, samplePlan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb5ef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/eecs/chanwutk/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.payload import Payload\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239d4c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/apperception-data/processed/nuscenes/full-dataset-v1.0/Mini/videos/boston-seaport'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOSTON_VIDEO_DIR = os.path.join(os.environ['NUSCENES_PROCESSED_DATA'], 'videos/boston-seaport')\n",
    "BOSTON_VIDEO_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad073f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_loc3d_ground_truth = [(1991, 874), (1949.181, 873.164)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a9d740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BOSTON_VIDEO_DIR, 'frames.pickle'), 'rb') as f:\n",
    "    videoconfigs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7c2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_detection(test_file_path: str, full_img_detection):\n",
    "    test_frame = cv2.imread(test_file_path)\n",
    "    for obj_idx, detection in full_img_detection.items():\n",
    "        obj_cls, bbox = detection\n",
    "        if obj_cls == 'car':\n",
    "            x,y,w,h = list(map(int,bbox))\n",
    "            cv2.rectangle(test_frame,(x-w//2,y-h//2),(x+w//2,y+h//2),(0,255,0),2)\n",
    "            cv2.putText(test_frame, '_'.join([obj_cls, str(obj_idx)]), (x+w//2+5,y+h//2+5),0,0.3,(0,255,0))\n",
    "    cv2.imshow('detection', test_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cdcba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(videoname: str, framesdict: dict) -> \"Video\":\n",
    "    videodata = framesdict[videoname]\n",
    "    filename = videodata['filename']\n",
    "    frames = videodata['frames']\n",
    "    configs = [camera_config(*f, 0) for f in frames]\n",
    "    return Video(os.path.join(BOSTON_VIDEO_DIR, filename), configs, videodata['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0d7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ego car trajectory\n",
    "def prepare_ego(test_video: str) -> \"Tuple[Video, List[trajectory_3d]]\":\n",
    "    video = get_video(test_video, videoconfigs)\n",
    "    ego_trajectory = [trajectory_3d(f.ego_translation, f.timestamp) for f in video]\n",
    "    return video, ego_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088f61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_plan_once(\n",
    "    video: \"str\",\n",
    "    ego_config: \"CameraConfig\",\n",
    "    mapping: \"List[CameraSegmentMapping]\",\n",
    "    next_frame_num: \"int\",\n",
    "    car_loc3d=None,\n",
    "    target_car_detection=None,\n",
    "    all_detection_info: \"List[obj_detection]\" = None\n",
    ") -> \"Tuple[samplePlan, None]\":\n",
    "    # if all_detection_info is None:\n",
    "    #     assert target_car_detection and car_loc3d\n",
    "    #     x,y,w,h = list(map(int, target_car_detection))\n",
    "    #     car_loc2d = (x, y+h//2)\n",
    "    #     car_bbox2d = (x-w//2,y-h//2,x+w//2,y+h//2)\n",
    "    #     car_bbox3d = None\n",
    "    #     all_detections = []\n",
    "    #     all_detections.append(obj_detection('car_1', car_loc3d, car_loc2d, car_bbox3d, car_bbox2d))\n",
    "    #     all_detection_info = construct_all_detection_info(cam_segment_mapping, ego_trajectory, ego_config, all_detections)\n",
    "    if all_detection_info:\n",
    "        print(all_detection_info[0].road_type)\n",
    "    next_sample_plan = generate_sample_plan(video, next_frame_num, all_detection_info,  50)\n",
    "    # next_frame = None\n",
    "    next_sample_frame_info = next_sample_plan.get_next_sample_frame_info()\n",
    "    if next_sample_frame_info:\n",
    "        next_sample_frame_name, next_sample_frame_num, _ = next_sample_frame_info\n",
    "        print(\"next frame name\", next_sample_frame_name)\n",
    "        print(\"next frame num\", next_sample_frame_num)\n",
    "    #     print(next_sample_plan.action)\n",
    "        # TODO: should not read next frame -> get the next frame from frames.pickle\n",
    "        # next_frame = cv2.imread(test_img_base_dir+next_sample_frame_name)\n",
    "#         cv2.imshow(\"next_frame\", next_frame)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "    return next_sample_plan, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be562f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_estimated_all_detection_info(\n",
    "    detections: \"npt.NDArray\",\n",
    "    cam_segment_mapping: \"List[CameraSegmentMapping]\",\n",
    "    ego_config: \"CameraConfig\",\n",
    "    ego_trajectory: \"trajectory_3d\"\n",
    ") -> \"List[DetectionInfo]\":\n",
    "    all_detections = []\n",
    "    for det in detections:\n",
    "        bbox = det[:4]\n",
    "        obj_cls = det[5]\n",
    "        x, y, x2, y2 = list(map(int,bbox))\n",
    "        w = x2 - x\n",
    "        h = y2 - y\n",
    "        car_loc2d = (x + w // 2, y+h//2)\n",
    "#         print(car_loc2d)\n",
    "        car_bbox2d = ((x-w//2, y-h//2), (x+w//2, y+h//2))\n",
    "        car_bbox3d = None\n",
    "        estimate_3d = detection_to_img_segment(car_loc2d, cam_segment_mapping)\n",
    "        if estimate_3d and estimate_3d.road_segment_info.segment_type in ['lane', 'laneSection']:\n",
    "            car_loc3d = tuple(Polygon(estimate_3d.road_segment_info.segment_polygon).centroid.coords)\n",
    "#             print(tuple(car_loc3d))\n",
    "            all_detections.append(obj_detection('car_1', car_loc3d, car_loc2d, car_bbox3d, car_bbox2d))\n",
    "    print(\"all_detections\", all_detections)\n",
    "    all_detection_info = construct_all_detection_info(cam_segment_mapping, ego_config, ego_trajectory, all_detections)\n",
    "    return all_detection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "277d76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dry_run(\n",
    "    payload: \"Payload\",\n",
    "    start_frame_num: \"int\",\n",
    "    ego_trajectory: \"List[trajectory_3d]\",\n",
    "    video: \"str\"\n",
    "):\n",
    "    skipped_frame_num = []\n",
    "    next_frame_num = start_frame_num\n",
    "    action_type_counts = {}\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    display_video = cv2.VideoWriter(f'sampled_frames_{video.replace(\"/\", \"_\")}.avi',fourcc, 10, (1600, 900))\n",
    "    start_time = time.time()\n",
    "    total_detection_time = 0\n",
    "    total_sample_plan_time = 0\n",
    "    for i in range(len(payload.video)-1):\n",
    "        current_ego_config = payload.video[i]\n",
    "        if i != next_frame_num:\n",
    "            skipped_frame_num.append(i)\n",
    "            continue\n",
    "        next_frame_num = i + 1\n",
    "        cam_segment_mapping = map_imgsegment_roadsegment(current_ego_config)\n",
    "        print(\"mapping length\", len(cam_segment_mapping))\n",
    "        # current_frame = test_img_base_dir + current_ego_config['fileName']\n",
    "        # display_video.write(cv2.imread(current_frame))\n",
    "        start_detection_time = time.time()\n",
    "        all_detection_info = construct_estimated_all_detection_info(YoloDetection.get(payload)[i][0], cam_segment_mapping, current_ego_config, ego_trajectory)\n",
    "        total_detection_time += time.time()-start_detection_time\n",
    "        start_generate_sample_plan = time.time()\n",
    "        next_sample_plan, _ = generate_sample_plan_once(payload.video, current_ego_config, cam_segment_mapping, next_frame_num, all_detection_info=all_detection_info)\n",
    "        total_sample_plan_time += time.time() - start_generate_sample_plan\n",
    "        next_action_type = next_sample_plan.get_action_type()\n",
    "        if next_action_type not in action_type_counts:\n",
    "            action_type_counts[next_action_type] = 1\n",
    "        else:\n",
    "            action_type_counts[next_action_type] += 1\n",
    "        next_frame_num = next_sample_plan.get_next_frame_num(next_frame_num)\n",
    "\n",
    "    display_video.release()\n",
    "    print(\"sorted_ego_config_length\", len(payload.video))\n",
    "    print(\"number of skipped\", len(skipped_frame_num))\n",
    "    print(skipped_frame_num)\n",
    "    print(action_type_counts)\n",
    "    total_run_time = time.time()-start_time\n",
    "    num_runs = len(payload.video) - len(skipped_frame_num)\n",
    "    print(\"total_run_time\", total_run_time)\n",
    "    print(\"avg run time\", total_run_time/num_runs)\n",
    "    print(\"total_detection_time\", total_detection_time)\n",
    "    print(\"avg detection time\", total_detection_time/num_runs)\n",
    "    print(\"total_generate_sample_plan_time\", total_sample_plan_time)\n",
    "    print(\"avg generate_sample_plan time\", total_sample_plan_time/num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4423e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /home/eecs/chanwutk/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage:  DecodeFrame.ParallelDecodeFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:15<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 397/397 [00:09<00:00, 43.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_filter(ParallelDecodeFrame())\n",
    "pipeline.add_filter(YoloDetection())\n",
    "\n",
    "test_video1 = 'scene-0757-CAM_FRONT'\n",
    "video1, ego_trajectory1 = prepare_ego(test_video1)\n",
    "payload1 = pipeline.run(Payload(video1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79ad2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/utils.py:66: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  a, b = line.boundary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total mapping time:  0.26101160049438477\n",
      "mapping length 24\n",
      "all_detections []\n",
      "total mapping time:  0.08991837501525879\n",
      "mapping length 24\n",
      "all_detections []\n",
      "total mapping time:  0.06955862045288086\n",
      "mapping length 24\n",
      "all_detections []\n",
      "total mapping time:  0.0667426586151123\n",
      "mapping length 24\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((341.7109839644813, 658.8090580685604),), car_loc2d=(801, 415), car_bbox3d=None, car_bbox2d=((791, 397), (801, 415)))]\n",
      "lane\n",
      "relative_direction_2 18.84942836926756 2018-08-30 12:25:08.412404\n",
      "next frame name None\n",
      "next frame num 27\n",
      "total mapping time:  0.10233020782470703\n",
      "mapping length 24\n",
      "all_detections []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/utils.py:107: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for intersect in intersection:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total mapping time:  0.09741592407226562\n",
      "mapping length 24\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((341.7109839644813, 658.8090580685604),), car_loc2d=(723, 415), car_bbox3d=None, car_bbox2d=((711, 391), (723, 415)))]\n",
      "lane\n",
      "relative_direction_2 18.84942836926756 2018-08-30 12:25:09.662404\n",
      "next frame name None\n",
      "next frame num 49\n",
      "total mapping time:  0.08903026580810547\n",
      "mapping length 21\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((272.5255063086455, 677.2313501542442),), car_loc2d=(807, 497), car_bbox3d=None, car_bbox2d=((613, 421), (807, 497)))]\n",
      "lane\n",
      "relative_direction_2 7.357008780646023 2018-08-30 12:25:10.712404\n",
      "next frame name None\n",
      "next frame num 58\n",
      "total mapping time:  0.09136438369750977\n",
      "mapping length 21\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((275.7307376440405, 681.7115228383127),), car_loc2d=(870, 490), car_bbox3d=None, car_bbox2d=((654, 412), (870, 490)))]\n",
      "lane\n",
      "relative_direction_2 8.560413870929743 2018-08-30 12:25:11.162404\n",
      "next frame name None\n",
      "next frame num 69\n",
      "total mapping time:  0.06554913520812988\n",
      "mapping length 21\n",
      "all_detections []\n",
      "total mapping time:  0.07242918014526367\n",
      "mapping length 21\n",
      "all_detections []\n",
      "total mapping time:  0.08919763565063477\n",
      "mapping length 21\n",
      "all_detections []\n",
      "total mapping time:  0.08928775787353516\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.0879373550415039\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.08886027336120605\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06328058242797852\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.061179399490356445\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.07243800163269043\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.0608980655670166\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.0679774284362793\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.09027242660522461\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.0596919059753418\n",
      "mapping length 20\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((294.86952765301635, 684.6738983818827),), car_loc2d=(1269, 506), car_bbox3d=None, car_bbox2d=((973, 402), (1269, 506)))]\n",
      "lane\n",
      "relative_direction_2 2.5024759313580867 2018-08-30 12:25:12.312404\n",
      "next frame name None\n",
      "next frame num 84\n",
      "total mapping time:  0.06217789649963379\n",
      "mapping length 20\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((294.86952765301635, 684.6738983818827),), car_loc2d=(1335, 506), car_bbox3d=None, car_bbox2d=((1061, 394), (1335, 506)))]\n",
      "lane\n",
      "relative_direction_2 2.5024759313580867 2018-08-30 12:25:12.462404\n",
      "next frame name None\n",
      "next frame num 87\n",
      "total mapping time:  0.06816244125366211\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06444621086120605\n",
      "mapping length 20\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((294.86952765301635, 684.6738983818827),), car_loc2d=(1381, 508), car_bbox3d=None, car_bbox2d=((1155, 396), (1381, 508)))]\n",
      "lane\n",
      "relative_direction_2 2.5024759313580867 2018-08-30 12:25:12.662404\n",
      "next frame name None\n",
      "next frame num 91\n",
      "total mapping time:  0.08611655235290527\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.09133434295654297\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.05845236778259277\n",
      "mapping length 20\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((287.99582643895366, 665.8682439156884),), car_loc2d=(271, 545), car_bbox3d=None, car_bbox2d=((215, 453), (271, 545)))]\n",
      "lane\n",
      "relative_direction_2 0.37091213393126066 2018-08-30 12:25:12.912404\n",
      "next frame name None\n",
      "next frame num 93\n",
      "total mapping time:  0.06947946548461914\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.08190584182739258\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06841802597045898\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06527280807495117\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06629633903503418\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.0734865665435791\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.08993101119995117\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.07523512840270996\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06841611862182617\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06844353675842285\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06606888771057129\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06729578971862793\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.08848094940185547\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.09700751304626465\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.08829760551452637\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.0777139663696289\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.07130622863769531\n",
      "mapping length 20\n",
      "all_detections []\n",
      "total mapping time:  0.06242179870605469\n",
      "mapping length 20\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((272.5255063086455, 677.2313501542442),), car_loc2d=(550, 503), car_bbox3d=None, car_bbox2d=((264, 411), (550, 503)))]\n",
      "lane\n",
      "relative_direction_2 7.357008780646023 2018-08-30 12:25:13.812404\n",
      "next frame name None\n",
      "next frame num 120\n",
      "total mapping time:  0.0696418285369873\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.07885599136352539\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.06987214088439941\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.08962297439575195\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.08201313018798828\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.06379008293151855\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.06736612319946289\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.06554126739501953\n",
      "mapping length 17\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((275.7307376440405, 681.7115228383127),), car_loc2d=(806, 510), car_bbox3d=None, car_bbox2d=((454, 396), (806, 510)))]\n",
      "lane\n",
      "relative_direction_2 8.560413870929743 2018-08-30 12:25:14.612404\n",
      "next frame name None\n",
      "next frame num 138\n",
      "total mapping time:  0.061093807220458984\n",
      "mapping length 17\n",
      "all_detections []\n",
      "total mapping time:  0.061397552490234375\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.06249046325683594\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.06192183494567871\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.05762434005737305\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.059600830078125\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.05766916275024414\n",
      "mapping length 15\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((293.7027547625998, 684.1626328502749),), car_loc2d=(1273, 513), car_bbox3d=None, car_bbox2d=((849, 387), (1273, 513)))]\n",
      "lane\n",
      "relative_dierction_1 1.4586675697642646 2018-08-30 12:25:15.462404 15.6464\n",
      "next frame name None\n",
      "next frame num 146\n",
      "total mapping time:  0.05725240707397461\n",
      "mapping length 15\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((293.7027547625998, 684.1626328502749),), car_loc2d=(1345, 512), car_bbox3d=None, car_bbox2d=((891, 386), (1345, 512)))]\n",
      "lane\n",
      "relative_dierction_1 1.4586675697642646 2018-08-30 12:25:15.562404 15.6464\n",
      "next frame name None\n",
      "next frame num 148\n",
      "total mapping time:  0.05823993682861328\n",
      "mapping length 15\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((293.7027547625998, 684.1626328502749),), car_loc2d=(1355, 511), car_bbox3d=None, car_bbox2d=((887, 383), (1355, 511)))]\n",
      "lane\n",
      "relative_dierction_1 1.4586675697642646 2018-08-30 12:25:15.662404 15.6464\n",
      "next frame name None\n",
      "next frame num 150\n",
      "total mapping time:  0.09180903434753418\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.07686996459960938\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.05727076530456543\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.05810666084289551\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.07972502708435059\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.05700182914733887\n",
      "mapping length 14\n",
      "all_detections []\n",
      "total mapping time:  0.05923342704772949\n",
      "mapping length 14\n",
      "all_detections []\n",
      "total mapping time:  0.06762290000915527\n",
      "mapping length 14\n",
      "all_detections []\n",
      "total mapping time:  0.07420539855957031\n",
      "mapping length 14\n",
      "all_detections []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total mapping time:  0.06888651847839355\n",
      "mapping length 14\n",
      "all_detections []\n",
      "total mapping time:  0.05882072448730469\n",
      "mapping length 14\n",
      "all_detections []\n",
      "total mapping time:  0.05796003341674805\n",
      "mapping length 14\n",
      "all_detections []\n",
      "total mapping time:  0.05967521667480469\n",
      "mapping length 12\n",
      "all_detections []\n",
      "total mapping time:  0.05949807167053223\n",
      "mapping length 12\n",
      "all_detections []\n",
      "total mapping time:  0.05967092514038086\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.05961036682128906\n",
      "mapping length 15\n",
      "all_detections []\n",
      "total mapping time:  0.06023359298706055\n",
      "mapping length 15\n",
      "all_detections [obj_detection(id='car_1', car_loc3d=((275.7307376440405, 681.7115228383127),), car_loc2d=(805, 493), car_bbox3d=None, car_bbox2d=((511, 399), (805, 493)))]\n",
      "lane\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "2018-08-30 12:25:15.562404 2018-08-30 12:25:16.562404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdry_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mego_trajectory1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_video1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [14], line 29\u001b[0m, in \u001b[0;36mdry_run\u001b[0;34m(payload, start_frame_num, ego_trajectory, video)\u001b[0m\n\u001b[1;32m     27\u001b[0m total_detection_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_detection_time\n\u001b[1;32m     28\u001b[0m start_generate_sample_plan \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 29\u001b[0m next_sample_plan, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sample_plan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_ego_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam_segment_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_frame_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_detection_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_detection_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m total_sample_plan_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_generate_sample_plan\n\u001b[1;32m     31\u001b[0m next_action_type \u001b[38;5;241m=\u001b[39m next_sample_plan\u001b[38;5;241m.\u001b[39mget_action_type()\n",
      "Cell \u001b[0;32mIn [12], line 21\u001b[0m, in \u001b[0;36mgenerate_sample_plan_once\u001b[0;34m(video, ego_config, mapping, next_frame_num, car_loc3d, target_car_detection, all_detection_info)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_detection_info:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(all_detection_info[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mroad_type)\n\u001b[0;32m---> 21\u001b[0m next_sample_plan \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sample_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_frame_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_detection_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# next_frame = None\u001b[39;00m\n\u001b[1;32m     23\u001b[0m next_sample_frame_info \u001b[38;5;241m=\u001b[39m next_sample_plan\u001b[38;5;241m.\u001b[39mget_next_sample_frame_info()\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/detection_estimation.py:218\u001b[0m, in \u001b[0;36mgenerate_sample_plan\u001b[0;34m(video, next_frame_num, all_detection_info, view_distance)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_sample_plan\u001b[39m(\n\u001b[1;32m    210\u001b[0m     video: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     next_frame_num: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m### the object detection with higher priority doesn't necessarily get sampled first,\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# it also based on the sample plan\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     sample_plan \u001b[38;5;241m=\u001b[39m samplePlan(video, next_frame_num, all_detection_info)\n\u001b[0;32m--> 218\u001b[0m     \u001b[43msample_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mview_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sample_plan\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/detection_estimation.py:112\u001b[0m, in \u001b[0;36msamplePlan.generate_sample_plan\u001b[0;34m(self, view_distance)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_detection_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection_info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_detection_info:\n\u001b[0;32m--> 112\u001b[0m     priority, sample_action \u001b[38;5;241m=\u001b[39m \u001b[43mdetection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_single_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mview_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(priority, sample_action)\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/detection_estimation.py:96\u001b[0m, in \u001b[0;36mDetectionInfo.generate_single_sample_action\u001b[0;34m(self, view_distance)\u001b[0m\n\u001b[1;32m     94\u001b[0m sample_action_alg \u001b[38;5;241m=\u001b[39m get_sample_action_alg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_direction)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sample_action_alg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriority, \u001b[43msample_action_alg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_distance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/sample_plan_algorithms.py:136\u001b[0m, in \u001b[0;36msame_direction_sample_action\u001b[0;34m(detection_info, view_distance)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ego_stop:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ego_stop_action\n\u001b[0;32m--> 136\u001b[0m ego_exit_segment_action \u001b[38;5;241m=\u001b[39m \u001b[43mego_exit_current_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetection_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mego_trajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mego_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# print('ego_exit_segment_action', ego_exit_segment_action)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m car_exit_segment_action \u001b[38;5;241m=\u001b[39m car_exit_current_segment(detection_info)\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/sample_plan_algorithms.py:77\u001b[0m, in \u001b[0;36mego_exit_current_segment\u001b[0;34m(detection_info, ego_trajectory, ego_config)\u001b[0m\n\u001b[1;32m     74\u001b[0m ego_loc \u001b[38;5;241m=\u001b[39m ego_config\u001b[38;5;241m.\u001b[39mego_translation[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     75\u001b[0m exit_time, exit_point \u001b[38;5;241m=\u001b[39m time_to_exit_current_segment(\n\u001b[1;32m     76\u001b[0m     current_segment_info, current_time, ego_loc, ego_trajectory)\n\u001b[0;32m---> 77\u001b[0m exit_action \u001b[38;5;241m=\u001b[39m \u001b[43mAction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexit_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mego_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexit_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                     \u001b[49m\u001b[43maction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEGO_EXIT_SEGMENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exit_action\n",
      "File \u001b[0;32m<string>:9\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, start_time, finish_time, start_loc, end_loc, action_type, target_obj_id)\u001b[0m\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/detection_estimation/sample_plan_algorithms.py:46\u001b[0m, in \u001b[0;36mAction.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimated_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinish_time \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_time\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvalid_action:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinish_time) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_time))\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_type \u001b[38;5;129;01min\u001b[39;00m OBJ_BASED_ACTION:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_obj_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: 2018-08-30 12:25:15.562404 2018-08-30 12:25:16.562404"
     ]
    }
   ],
   "source": [
    "dry_run(payload1, 0, ego_trajectory1, test_video1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (apperception)",
   "language": "python",
   "name": "apperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
