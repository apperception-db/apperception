{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvmjEjf_QgnM"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSzN1aVqNWOp",
        "outputId": "ca981541-4552-4fc8-a39d-c27d13683d9f"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /data/sets/nuscenes  # Make the directory to store the nuScenes dataset in.\n",
        "\n",
        "!wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
        "\n",
        "!tar -xf v1.0-mini.tgz -C /data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
        "\n",
        "!pip install nuscenes-devkit &> /dev/null  # Install nuScenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktwFixEUNWOr",
        "outputId": "172a9847-3e3b-4cea-dfd8-b5c4cd82e4f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======\n",
            "Loading NuScenes tables for version v1.0-trainval...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "64386 instance,\n",
            "12 sensor,\n",
            "10200 calibrated_sensor,\n",
            "2631083 ego_pose,\n",
            "68 log,\n",
            "850 scene,\n",
            "34149 sample,\n",
            "2631083 sample_data,\n",
            "1166187 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 88.140 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 12.6 seconds.\n",
            "======\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "import numpy as np\n",
        "\n",
        "nusc = NuScenes(version='v1.0-trainval', dataroot='/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Trainval', verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "di_qpPG7kn7M"
      },
      "outputs": [],
      "source": [
        "from nuscenes.map_expansion.map_api import NuScenesMap\n",
        "from nuscenes.map_expansion import arcline_path_utils\n",
        "from nuscenes.map_expansion.bitmap import BitMap\n",
        "\n",
        "nusc_map = NuScenesMap(dataroot='/work/apperception/data/raw/nuScenes/Map-expansion', map_name='boston-seaport')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B3_v977HZJKf"
      },
      "outputs": [],
      "source": [
        "class Instance():\n",
        "  def __init__(self, timestamp, sample_record, annotation_token, ego_pose_token, annotation_token2=None, annotation_token3=None):\n",
        "    self.timestamp = timestamp\n",
        "    self.sample_record = sample_record\n",
        "    self.annotation_token = annotation_token\n",
        "    self.annotation_token2 = annotation_token2\n",
        "    self.annotation_token3 = annotation_token3\n",
        "    self.ego_pose_token = ego_pose_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ff1FT8C3tG0x"
      },
      "outputs": [],
      "source": [
        "from pyquaternion import Quaternion\n",
        "import math\n",
        "\n",
        "def normalizeAngle(angle) -> float:\n",
        "    while angle > math.pi:\n",
        "        angle -= math.tau\n",
        "    while angle < -math.pi:\n",
        "        angle += math.tau\n",
        "    assert -math.pi <= angle <= math.pi\n",
        "    return angle\n",
        "\n",
        "def get_heading(rotation):\n",
        "    yaw = Quaternion(rotation).yaw_pitch_roll[0]\n",
        "    return normalizeAngle(yaw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F2rbQH5d-EzH"
      },
      "outputs": [],
      "source": [
        "def get_road_direction(position):\n",
        "  x, y, z = position\n",
        "  closest_lane = nusc_map.get_closest_lane(x, y, radius=2)\n",
        "  if closest_lane:\n",
        "    lane_record = nusc_map.get_arcline_path(closest_lane)\n",
        "    poses = arcline_path_utils.discretize_lane(lane_record, resolution_meters=1)\n",
        "    closest_pose_on_lane, distance_along_lane = arcline_path_utils.project_pose_to_lane((x, y, 0), lane_record)\n",
        "    yaw = closest_pose_on_lane[2]\n",
        "    return normalizeAngle(yaw)\n",
        "  else:\n",
        "    return None  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3tpHG78c-IjC"
      },
      "outputs": [],
      "source": [
        "def is_contained(position, segment_type):\n",
        "  x, y, z = position\n",
        "  return nusc_map.layers_on_point(x, y)[segment_type] != ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uXnF2wBUuwTK"
      },
      "outputs": [],
      "source": [
        "def is_contained_intersection(position):\n",
        "  x, y, z = position\n",
        "  road_segment_token = nusc_map.layers_on_point(x, y)['road_segment']\n",
        "  if road_segment_token != '':\n",
        "    road_segment = nusc_map.get('road_segment', road_segment_token)\n",
        "    return road_segment[\"is_intersection\"]\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-hkNoumA67I_"
      },
      "outputs": [],
      "source": [
        "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
        "\n",
        "def is_visible(sample_record, annotation_token):\n",
        "  camera = sample_record[\"data\"][\"CAM_FRONT\"]\n",
        "  _, boxes, _ = nusc.get_sample_data(camera, box_vis_level=BoxVisibility.ANY, selected_anntokens=[annotation_token])\n",
        "  return len(boxes) > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_camera(cam_position, cam_heading, obj_point):\n",
        "    cam_x, cam_y, _ = cam_position\n",
        "    obj_x, obj_y, _ = obj_point\n",
        "    \n",
        "    subtract_x = obj_x - cam_x\n",
        "    subtract_y = obj_y - cam_y\n",
        "\n",
        "    subtract_mag = np.sqrt(subtract_x**2 + subtract_y**2)\n",
        "\n",
        "    res_x = subtract_mag * np.cos(-cam_heading + np.arctan2(subtract_y, subtract_x))\n",
        "    res_y = subtract_mag * np.sin(-cam_heading + np.arctan2(subtract_y, subtract_x))\n",
        "\n",
        "    return res_x, res_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSf0zbS6RBqV"
      },
      "source": [
        "## Figure 12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtM-reRjOhue"
      },
      "outputs": [],
      "source": [
        "# world = world.filter(\n",
        "#     F.like(o.type, lit('human.pedestrian%')) &\n",
        "#     F.contained(c.ego, 'road') &\n",
        "#     (F.contained_margin(o.bbox@c.time, F.road_segment('road'), lit(0.50)) | F.contained(o.trans@c.time, 'road')) &\n",
        "#     F.angle_excluding(F.facing_relative(o.traj@c.time, c.ego), lit(-70), lit(70)) &\n",
        "#     F.angle_between(F.facing_relative(c.ego, c.roadDirection), lit(-15), lit(15)) &\n",
        "#     (F.distance(c.camAbs, o.traj@c.time) < lit(50)) &\n",
        "#     (F.view_angle(o.trans@c.time, c.camAbs) < lit(35))\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYQZz-QnOdMn"
      },
      "outputs": [],
      "source": [
        "# ego = Car on drivableRoad,\n",
        "#         facing Range(-15, 15) deg relative to roadDirection,\n",
        "#         with visibleDistance 50, \n",
        "#         with viewAngle 135 deg\n",
        "# ped = Pedestrian on roadsOrIntersections,\n",
        "#         with regionContainedIn roadRegion,\n",
        "#         facing Range(-180, 180) deg\n",
        "\n",
        "# require abs(relative heading of ped from ego) > 70 deg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbCySIaIRHUN"
      },
      "outputs": [],
      "source": [
        "### Devkit Plan\n",
        "# 1. Get all instances of Egos\n",
        "#     - such that on road (prob not needed)\n",
        "#     - such that facing Range(-15, 15) relative to roadDirection\n",
        "# 2. Geet all instances of pedestrians wrt egos\n",
        "#     - such that withitn 50 meters of ego\n",
        "#     - such that on road\n",
        "#     - such that visibile from ego (viewAngle if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jDPvs4eXrN7",
        "outputId": "57c9b325-8710-49ae-89c5-078a3d5250a0"
      },
      "outputs": [],
      "source": [
        "## Get all possible pedestrian + ego instances\n",
        "instances = []\n",
        "for sample in nusc.sample:\n",
        "  scene = nusc.get('scene', sample['scene_token'])\n",
        "  log = nusc.get('log', scene['log_token'])\n",
        "  if log['location'] == 'boston-seaport':\n",
        "    for annotation in sample['anns']:\n",
        "      annotation_metadata = nusc.get('sample_annotation', annotation)\n",
        "      if annotation_metadata['category_name'] == 'human.pedestrian.adult':\n",
        "        CAM_FRONT_SENSOR = sample['data']['CAM_FRONT']\n",
        "        sample_data = nusc.get('sample_data', CAM_FRONT_SENSOR)\n",
        "        ego_pose_token = sample_data['ego_pose_token']\n",
        "        instances.append(Instance(timestamp=sample_data['timestamp'], sample_record=sample, annotation_token=annotation, ego_pose_token=ego_pose_token))\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gNsG4WioQ61",
        "outputId": "ed14e4b3-f269-4e8e-de7f-b787b0224914"
      },
      "outputs": [],
      "source": [
        "## Filter for pedestrians that are within 50 meters of the ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  ped_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  distance = np.linalg.norm(ped_trans - ego_trans)\n",
        "\n",
        "  if distance < 50:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agr2UDpJ-64T",
        "outputId": "5b40c657-c95c-4e7a-9997-8fc0bd6b4795"
      },
      "outputs": [],
      "source": [
        "## Filter so that pedestrian is visible from ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ped_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token)\n",
        "  if ped_visible:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF_3QaXaWdDZ",
        "outputId": "ce76eecb-a261-4f40-c28d-200d82df0664"
      },
      "outputs": [],
      "source": [
        "## Filter so that for pedestrians that are on a road\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  ped_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  if is_contained(ped_trans, 'road_segment'):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEIo2k6L-0pR",
        "outputId": "a23431f1-c68a-49b6-b030-37937b95fbf4"
      },
      "outputs": [],
      "source": [
        "## Filter for egos whos heading is aligned with the road direction\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  ped_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  road_direction = get_road_direction(ego_trans)\n",
        "  if road_direction == None:\n",
        "    new_instances.append(instance)\n",
        "  elif normalizeAngle(abs(ego_heading - road_direction)) < math.radians(15):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwNDzAqhDR0S",
        "outputId": "c00bad60-c687-412c-e2f6-9d1bd5d8d7c4"
      },
      "outputs": [],
      "source": [
        "## require abs(relative heading of ped from ego) > 70 deg\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  ped_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  ped_heading = get_heading(annotation['rotation'])\n",
        "  if abs(ego_heading - ped_heading) > math.radians(70):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w17IV9oN_T8k"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for instance in instances:\n",
        "  camera_token = instance.sample_record['data']['CAM_FRONT']\n",
        "  camera_data = nusc.get('sample_data', camera_token)\n",
        "  results[camera_data['token']] = camera_data['filename'].split('/')[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t5OTc0feBmzs",
        "outputId": "e89b35c3-7d0d-497a-cc8f-cea4c264eb3f"
      },
      "outputs": [],
      "source": [
        "for token in results:\n",
        "  nusc.render_sample_data(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8RBjZII_G9M",
        "outputId": "0d4f9991-441e-4977-a221-ae745cf8d3af"
      },
      "outputs": [],
      "source": [
        "############# Validation ####################\n",
        "expected_imgs = [\n",
        "    'n008-2018-05-21-11-06-59-0400__CAM_FRONT__1526915471412465.jpg',\n",
        "    'n008-2018-07-27-12-07-38-0400__CAM_FRONT__1532707917112404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153162404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153662404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385154162404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385154662404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385155162404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385158662404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159162404.jpg',\n",
        "    'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159662404.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656805162404.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656805662415.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656806162404.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656806612404.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656807162404.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656807662404.jpg',\n",
        "    'n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656808162404.jpg',\n",
        "    'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659404362404.jpg',\n",
        "    'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659404762404.jpg',\n",
        "    'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659405262404.jpg',\n",
        "    'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659405762404.jpg',\n",
        "    'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659406262404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535728830362404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326412404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326912404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729327412404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729327912404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729328412404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729328912404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729329412404.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729329912795.jpg',\n",
        "    'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729330362404.jpg',\n",
        "    'n008-2018-08-31-11-37-23-0400__CAM_FRONT__1535730293412404.jpg',\n",
        "    'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731236162404.jpg',\n",
        "    'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731236662404.jpg',\n",
        "    'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731237112404.jpg',\n",
        "    'n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731237612404.jpg',\n",
        "    'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293291162404.jpg',\n",
        "    'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293291662404.jpg',\n",
        "    'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293292162404.jpg',\n",
        "    'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293292662404.jpg',\n",
        "    'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293293162404.jpg',\n",
        "    'n008-2018-09-18-13-41-50-0400__CAM_FRONT__1537293293662404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299143862404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299144362404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299144862404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299145362404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299145862404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299146362404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299146862404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299147362404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299147862404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299148362404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299148862404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299149412404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299229362404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299239112404.jpg',\n",
        "    'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299240112404.jpg',\n",
        "]\n",
        "\n",
        "missing = 0\n",
        "missing_images = []\n",
        "for expected_img in expected_imgs:\n",
        "    if expected_img not in results.values():\n",
        "        missing += 1\n",
        "        # missing_images.append(expected_img)\n",
        "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
        "# show_images(missing_images, sample=10)\n",
        "\n",
        "extra = 0\n",
        "extra_images = {}\n",
        "for img in results:\n",
        "    if results[img] not in expected_imgs:\n",
        "        extra += 1\n",
        "        # extra_images[img] = resultImages[img]\n",
        "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(results), \"=\", 100 * extra / len(results), \"%\")\n",
        "# show_images(extra_images.keys(), sample=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "RZx8KE1JzOK7",
        "outputId": "1b1eeaf1-6d04-4320-aff0-3c5382c9a4d3"
      },
      "outputs": [],
      "source": [
        "fig, ax = nusc_map.render_layers(nusc_map.non_geometric_layers, figsize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYWWf4PGpOdj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRmO8-tsqYZY"
      },
      "source": [
        "## Figure 13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7qHuYVKqYZd"
      },
      "outputs": [],
      "source": [
        "# ego = Car on drivableRoad,\n",
        "#         facing Range(-15, 15) deg relative to roadDirection,\n",
        "#         with visibleDistance 50,\n",
        "#         with viewAngle 135 deg\n",
        "\n",
        "# other1 = Car on intersection,\n",
        "#             facing Range(50, 135) deg relative to ego.heading\n",
        "\n",
        "# other2 = Car on intersection,\n",
        "#             facing -1 * Range(50, 135) deg relative to ego.heading\n",
        "\n",
        "# require abs(relative heading of other1 from other2) > 100 deg\n",
        "# require (distance from ego to intersectionRegion) < 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0pjpXVzqYZd"
      },
      "outputs": [],
      "source": [
        "# world = world.filter(\n",
        "#     (obj1.id != obj2.id) &\n",
        "#     F.like(obj1.type, 'vehicle%') &\n",
        "#     F.like(obj2.type, 'vehicle%') &\n",
        "#     F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) &\n",
        "#     (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
        "#     (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
        "#     (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
        "#     (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
        "#     F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
        "#     F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 50, 135) &\n",
        "#     F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
        "#     (F.min_distance(cam.ego, F.road_segment('intersection')) < 10) &\n",
        "#     F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-MTXMoaqYZe",
        "outputId": "128d270b-3a02-4fad-93a5-a4dada147ce9"
      },
      "outputs": [],
      "source": [
        "## Get all possible car1 + car2 instances\n",
        "instances = []\n",
        "for sample in nusc.sample:\n",
        "  scene = nusc.get('scene', sample['scene_token'])\n",
        "  log = nusc.get('log', scene['log_token'])\n",
        "  if scene['name'] == 'scene-0757' and log['location'] == 'boston-seaport':\n",
        "    if log['location'] == 'boston-seaport':\n",
        "      for annotation1 in sample['anns']:\n",
        "        for annotation2 in sample['anns']:\n",
        "          annotation_metadata1 = nusc.get('sample_annotation', annotation1)\n",
        "          annotation_metadata2 = nusc.get('sample_annotation', annotation2)\n",
        "          if annotation_metadata1['category_name'] == 'vehicle.car' or annotation_metadata1['category_name'] == 'vehicle.bus.rigid' or annotation_metadata1['category_name'] == 'vehicle.truck':\n",
        "            if annotation_metadata2['category_name'] == 'vehicle.car' or annotation_metadata1['category_name'] == 'vehicle.bus.rigid' or annotation_metadata2['category_name'] == 'vehicle.truck':\n",
        "              CAM_FRONT_SENSOR = sample['data']['CAM_FRONT']\n",
        "              sample_data = nusc.get('sample_data', CAM_FRONT_SENSOR)\n",
        "              ego_pose_token = sample_data['ego_pose_token']\n",
        "              instances.append(Instance(timestamp=sample_data['timestamp'], sample_record=sample, annotation_token=annotation1, annotation_token2=annotation2, ego_pose_token=ego_pose_token))\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDNh355fqYZe",
        "outputId": "9e95975b-4d8d-49a5-9191-284049ca8e18"
      },
      "outputs": [],
      "source": [
        "## Filter for cars  that are within 50 meters of the ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation1 = nusc.get('sample_annotation', instance.annotation_token)\n",
        "  annotation2 = nusc.get('sample_annotation', instance.annotation_token2)\n",
        "\n",
        "  car1_trans = np.array(annotation1['translation'])\n",
        "  car2_trans = np.array(annotation2['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  distance1 = np.linalg.norm(car1_trans - ego_trans)\n",
        "  distance2 = np.linalg.norm(car2_trans - ego_trans)\n",
        "\n",
        "  if distance1 < 50 and distance2 < 50:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3SjK55RqYZe",
        "outputId": "a9d7baaa-2b0a-43e0-90a1-e09963417ed3"
      },
      "outputs": [],
      "source": [
        "## Filter so that cars are visible from ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  car1_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token)\n",
        "  car2_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token2)\n",
        "  if car1_visible and car2_visible:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MaGzg5tqYZe",
        "outputId": "9137cd45-bb5f-41a9-db78-580ac94c386a"
      },
      "outputs": [],
      "source": [
        "## Filter for relative headings wrt to ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation1 = nusc.get('sample_annotation', instance.annotation_token)\n",
        "  annotation2 = nusc.get('sample_annotation', instance.annotation_token2)\n",
        "\n",
        "  \n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  car1_heading = get_heading(annotation1['rotation'])\n",
        "  car2_heading = get_heading(annotation2['rotation'])\n",
        "  \n",
        "  car1_diff = normalizeAngle(ego_heading - car1_heading)\n",
        "  car2_diff = normalizeAngle(ego_heading - car2_heading)\n",
        "  \n",
        "  if math.radians(50) < car1_diff and car1_diff < math.radians(135):\n",
        "    if math.radians(-135) < car2_diff and car2_diff < math.radians(-50):\n",
        "      if abs(car1_heading - car2_heading) > math.radians(100):\n",
        "        new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnXKIzvFqYZe",
        "outputId": "7a936e37-07e5-4cc5-ef23-917430a7ab89"
      },
      "outputs": [],
      "source": [
        "## Filter so that for cars that are in an intersection\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation1 = nusc.get('sample_annotation', instance.annotation_token)\n",
        "  annotation2 = nusc.get('sample_annotation', instance.annotation_token2)\n",
        "\n",
        "  car1_trans = np.array(annotation1['translation'])\n",
        "  car2_trans = np.array(annotation2['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  if is_contained_intersection(car1_trans) and is_contained_intersection(car2_trans):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjdHIU_SqYZe",
        "outputId": "5d9a2506-6201-4e7b-cdfe-c3b4ba1a82e1"
      },
      "outputs": [],
      "source": [
        "## Filter for egos whos heading is aligned with the road direction\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  ped_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  road_direction = get_road_direction(ego_trans)\n",
        "  if road_direction == None:\n",
        "    new_instances.append(instance)\n",
        "  elif normalizeAngle(abs(ego_heading - road_direction)) < math.radians(15):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OxA6w03qYZe"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for instance in instances:\n",
        "  camera_token = instance.sample_record['data']['CAM_FRONT']\n",
        "  camera_data = nusc.get('sample_data', camera_token)\n",
        "  results[camera_data['token']] = camera_data['filename'] # .split('/')[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c-WHNyyQqYZe",
        "outputId": "f7859534-9375-4c1a-fce2-8042cc3ff908"
      },
      "outputs": [],
      "source": [
        "for token in results:\n",
        "  print(results[token])\n",
        "  nusc.render_sample_data(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypei1q5-qYZf",
        "outputId": "7acb305d-901d-4245-c72c-3f5163b269c1"
      },
      "outputs": [],
      "source": [
        "############# Validation ####################\n",
        "expected_imgs = ['sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657111412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657111762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657112862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657114362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657114362404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657114612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657114612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657115012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657115112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657115162404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657116112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657120912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121162404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657121912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657126012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657126012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657126862404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657127912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657128012404.jpg']\n",
        "\n",
        "expected_imgs = [x for x in expected_imgs if \"samples\" in x]\n",
        "\n",
        "missing = 0\n",
        "missing_images = []\n",
        "for expected_img in expected_imgs:\n",
        "    if expected_img not in results.values():\n",
        "        missing += 1\n",
        "        # missing_images.append(expected_img)\n",
        "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
        "# show_images(missing_images, sample=10)\n",
        "\n",
        "extra = 0\n",
        "\n",
        "extra_images = {}\n",
        "for img in results:\n",
        "    if results[img] not in expected_imgs:\n",
        "        extra += 1\n",
        "        # extra_images[img] = resultImages[img]\n",
        "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(results), \"=\", 100 * extra / len(results), \"%\")\n",
        "# show_images(extra_images.keys(), sample=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aWvEg56hzYa",
        "outputId": "fa877eca-0d47-4653-f998-2973c188b6e2"
      },
      "outputs": [],
      "source": [
        "print(list(results.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "s6kWTF4KqYZf",
        "outputId": "1b1eeaf1-6d04-4320-aff0-3c5382c9a4d3"
      },
      "outputs": [],
      "source": [
        "fig, ax = nusc_map.render_layers(nusc_map.non_geometric_layers, figsize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txyq-yRRqYZf",
        "outputId": "bc25c578-feed-4a50-803e-8c8447c060da"
      },
      "outputs": [],
      "source": [
        "nusc.list_scenes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vWiJJF6wcyP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOLQXBj2IwQZ"
      },
      "source": [
        "## Figure 14\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD7k_-xuIwQo"
      },
      "outputs": [],
      "source": [
        "# ego = Car on drivableRoad,\n",
        "#         facing offset relative to roadDirection,\n",
        "#         with visibleDistance 50,\n",
        "#         with viewAngle 135 deg\n",
        "\n",
        "# otherCar = Car on visible road,\n",
        "#             facing Range(-15, 15) deg relative to roadDirection\n",
        "\n",
        "# require (distance from ego to otherCar) < 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KyyfBEcIwQo"
      },
      "outputs": [],
      "source": [
        "# world = world.filter(\"lambda obj1, cam: \" + \n",
        "#         \"F.like(obj1.object_type, 'vehicle%') and \" +\n",
        "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 50 and \" +\n",
        "#         \"F.view_angle(obj1, cam.ego, cam.timestamp) < 70 / 2 and \" +\n",
        "#         \"F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.timestamp, cam.ego), cam.timestamp), -180, -90) and \" +\n",
        "#         \"F.contained(cam.ego, F.road_segment('road')) and \" +\n",
        "#         \"F.contained(obj1.traj, F.road_segment('road'), cam.timestamp) and \" +\n",
        "#         \"F.angle_between(F.facing_relative(obj1, F.road_direction(obj1.traj, cam.timestamp, cam.ego), cam.timestamp), -15, 15) and \" +\n",
        "#         \"F.distance(cam.ego, obj1, cam.timestamp) < 10\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnvQfimOIwQp",
        "outputId": "d4e20b0c-73b1-4a7c-d88d-2c421bb16e40"
      },
      "outputs": [],
      "source": [
        "## Get all possible car + ego instances\n",
        "instances = []\n",
        "for sample in nusc.sample:\n",
        "  scene = nusc.get('scene', sample['scene_token'])\n",
        "  log = nusc.get('log', scene['log_token'])\n",
        "  if log['location'] == 'boston-seaport' and scene[\"name\"] == \"scene-0769\":\n",
        "    for annotation in sample['anns']:\n",
        "      annotation_metadata = nusc.get('sample_annotation', annotation)\n",
        "      if annotation_metadata['category_name'] == 'vehicle.car' or annotation_metadata['category_name'] == 'vehicle.bus.rigid' or annotation_metadata['category_name'] == 'vehicle.truck':\n",
        "        CAM_FRONT_SENSOR = sample['data']['CAM_FRONT']\n",
        "        sample_data = nusc.get('sample_data', CAM_FRONT_SENSOR)\n",
        "        ego_pose_token = sample_data['ego_pose_token']\n",
        "        instances.append(Instance(timestamp=sample_data['timestamp'], sample_record=sample, annotation_token=annotation, ego_pose_token=ego_pose_token))\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYS2dSzJIwQq",
        "outputId": "ac9ec825-010b-49e6-e17e-b0fdf08e03b5"
      },
      "outputs": [],
      "source": [
        "## Filter for cars  that are within 10 meters of the ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation1 = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  car1_trans = np.array(annotation1['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  distance1 = np.linalg.norm(car1_trans - ego_trans)\n",
        "\n",
        "  if distance1 < 50:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfsuZQWIIwQr",
        "outputId": "dbf3033d-a70c-4876-8143-08d8fa098cb6"
      },
      "outputs": [],
      "source": [
        "## Filter so that cars are visible from ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  car1_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token)\n",
        "  if car1_visible:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLiO0F1kIwQt",
        "outputId": "1cf34218-1f5c-44d5-e3d2-d243f364acae"
      },
      "outputs": [],
      "source": [
        "## Filter for cars whos heading is aligned with the road direction\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  car_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  \n",
        "  car_heading = get_heading(annotation['rotation'])\n",
        "  road_direction = get_road_direction(car_trans)\n",
        "  if road_direction == None:\n",
        "    new_instances.append(instance)\n",
        "  elif math.radians(-15) < normalizeAngle(abs(car_heading - road_direction)) and normalizeAngle(abs(car_heading - road_direction)) < math.radians(15):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLsg62vUJZfy",
        "outputId": "78ebf3dd-8325-470c-c6c3-9a48684a7587"
      },
      "outputs": [],
      "source": [
        "## Filter for egos who are moving in opposite direction\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "  \n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "\n",
        "  road_direction = get_road_direction(ego_trans)\n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  if road_direction == None:\n",
        "    new_instances.append(instance)\n",
        "    continue\n",
        "  diff = normalizeAngle(ego_heading - road_direction) \n",
        "  if (math.radians(-180) < diff and diff < math.radians(-90)) or (math.radians(90) < diff and diff < math.radians(180)):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhz4vG68IwQu"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for instance in instances:\n",
        "  camera_token = instance.sample_record['data']['CAM_FRONT']\n",
        "  camera_data = nusc.get('sample_data', camera_token)\n",
        "  results[camera_data['token']] = camera_data['filename'] #.split('/')[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8cl2SjsJIwQu",
        "outputId": "fd226682-ce73-44c4-ee08-9f98aa249e1a"
      },
      "outputs": [],
      "source": [
        "for token in results:\n",
        "  print(results[token])\n",
        "  nusc.render_sample_data(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yExo2U1xIwQv",
        "outputId": "7acb305d-901d-4245-c72c-3f5163b269c1"
      },
      "outputs": [],
      "source": [
        "############# Validation ####################\n",
        "expected_imgs = ['sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657490862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657490912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657490912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491512404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491662404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491862404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492012404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657492412404.jpg']\n",
        "\n",
        "expected_imgs = list(set([x for x in expected_imgs if \"samples\" in x]))\n",
        "\n",
        "missing = 0\n",
        "missing_images = []\n",
        "for expected_img in expected_imgs:\n",
        "    if expected_img not in results.values():\n",
        "        missing += 1\n",
        "        # missing_images.append(expected_img)\n",
        "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
        "# show_images(missing_images, sample=10)\n",
        "\n",
        "extra = 0\n",
        "extra_images = []\n",
        "for img in results:\n",
        "    if results[img] not in expected_imgs:\n",
        "        extra += 1\n",
        "        extra_images.append(results[img])\n",
        "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(results), \"=\", 100 * extra / len(results), \"%\")\n",
        "# show_images(extra_images.keys(), sample=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(results.values())\n",
        "print(expected_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657491612404.jpg' in results.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extra_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h6bDlldIwQv",
        "outputId": "fa877eca-0d47-4653-f998-2973c188b6e2"
      },
      "outputs": [],
      "source": [
        "print(list(results.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "Y6ef3fG1IwQv",
        "outputId": "1b1eeaf1-6d04-4320-aff0-3c5382c9a4d3"
      },
      "outputs": [],
      "source": [
        "fig, ax = nusc_map.render_layers(nusc_map.non_geometric_layers, figsize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUue-iynIwQw",
        "outputId": "bc25c578-feed-4a50-803e-8c8447c060da"
      },
      "outputs": [],
      "source": [
        "nusc.list_scenes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBTr6XUZIwQw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mo7wF57NkCu"
      },
      "source": [
        "## Figure 15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzmidvyyNkC7"
      },
      "outputs": [],
      "source": [
        "# ego = Car on drivableRoad,\n",
        "#         facing Range(-15, 15) deg relative to roadDirection,\n",
        "#         with visibleDistance 50,\n",
        "#         with viewAngle 135 deg\n",
        "\n",
        "# point1 = OrientedPoint ahead of ego by Range(0, 40)\n",
        "# Car at (point1 offset by Range(-1, 1) @ 0),\n",
        "#     facing Range(-15, 15) deg relative to roadDirection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eQaJNOyNkC8"
      },
      "outputs": [],
      "source": [
        "# world = world.filter(\n",
        "#     (F.like(car1.type, 'car') | F.like(car1.type, 'truck')) &\n",
        "#     (F.like(car2.type, 'car') | F.like(car2.type, 'truck')) &\n",
        "#     (F.like(opposite_car.type, 'car') | F.like(opposite_car.type, 'truck')) &\n",
        "#     (opposite_car.id != car2.id) &\n",
        "#     (car1.id != car2.id) &\n",
        "#     (car1.id != opposite_car.id) &\n",
        "\n",
        "#     F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) &\n",
        "#     (F.view_angle(car1.traj@cam.time, cam.ego) < 70 / 2) &\n",
        "#     (F.distance(cam.ego, car1.traj@cam.time) < 50) &\n",
        "# #     F.angle_between(F.facing_relative(car1.traj@cam.time, cam.ego), -15, 15) &\n",
        "# #     F.angle_between(F.facing_relative(car1.traj@cam.time, F.road_direction(car1.traj@cam.time, cam.ego)), -15, 15) &\n",
        "#     F.ahead(car1.traj@cam.time, cam.ego) &\n",
        "#     F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) &\n",
        "#     (F.convert_camera(opposite_car.traj@cam.time, cam.ego) > [-10, 0]) &\n",
        "#     (F.convert_camera(opposite_car.traj@cam.time, cam.ego) < [-1, 50]) &\n",
        "#     F.angle_between(F.facing_relative(opposite_car.traj@cam.time, cam.ego), 140, 180) &\n",
        "#     (F.distance(opposite_car@cam.time, car2@cam.time) < 40) &\n",
        "# #     F.angle_between(F.facing_relative(car2.traj@cam.time, F.road_direction(car2.traj@cam.time, cam.ego)), -15, 15) &\n",
        "#     F.ahead(car2.traj@cam.time, opposite_car.traj@cam.time)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2prcOsnVNkC8",
        "outputId": "e447cce2-e77f-43a1-e17a-76abc84355ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "260334"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Get all possible car + car + car + ego instances\n",
        "instances = []\n",
        "for sample in nusc.sample:\n",
        "  scene = nusc.get('scene', sample['scene_token'])\n",
        "  log = nusc.get('log', scene['log_token'])\n",
        "  if log['location'] == 'boston-seaport' and scene[\"name\"] == \"scene-0207\":\n",
        "    for annotation1 in sample['anns']:\n",
        "      for annotation2 in sample['anns']:\n",
        "        for annotation3 in sample['anns']:\n",
        "          annotation1_metadata = nusc.get('sample_annotation', annotation1)\n",
        "          annotation2_metadata = nusc.get('sample_annotation', annotation2)\n",
        "          annotation3_metadata = nusc.get('sample_annotation', annotation3)\n",
        "          if annotation1 != annotation2 and annotation2 != annotation3 and annotation1 != annotation3:\n",
        "            if (annotation1_metadata['category_name'] == 'vehicle.car' or annotation1_metadata['category_name'] == 'vehicle.truck') \\\n",
        "              and (annotation2_metadata['category_name'] == 'vehicle.car' or annotation2_metadata['category_name'] == 'vehicle.truck') \\\n",
        "              and (annotation3_metadata['category_name'] == 'vehicle.car' or annotation3_metadata['category_name'] == 'vehicle.truck'):\n",
        "              CAM_FRONT_SENSOR = sample['data']['CAM_FRONT']\n",
        "              sample_data = nusc.get('sample_data', CAM_FRONT_SENSOR)\n",
        "              ego_pose_token = sample_data['ego_pose_token']\n",
        "              instances.append(Instance(timestamp=sample_data['timestamp'], sample_record=sample, annotation_token=annotation1, ego_pose_token=ego_pose_token, annotation_token2=annotation2, annotation_token3=annotation3))\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jZS9C4SNkC9",
        "outputId": "60ff6aae-27d2-4e84-efec-d745cc17791b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83488"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter for distances\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation1 = nusc.get('sample_annotation', instance.annotation_token)\n",
        "  annotation2 = nusc.get('sample_annotation', instance.annotation_token2)\n",
        "  annotation3 = nusc.get('sample_annotation', instance.annotation_token3)\n",
        "\n",
        "  oppposite_car_trans = np.array(annotation3['translation'])\n",
        "  car_2_trans = np.array(annotation2['translation'])\n",
        "  car_1_trans = np.array(annotation1['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  distance1 = np.linalg.norm(oppposite_car_trans - car_2_trans)\n",
        "  distance2 = np.linalg.norm(car_1_trans - ego_trans)\n",
        "\n",
        "  if distance1 < 40 and distance2 < 50:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsxsKsV9NkC9",
        "outputId": "3fe2781f-f679-4fe8-e8ca-a0023ed26928"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2072"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter so that car 1s are visible from ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  car1_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token)\n",
        "  car2_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token2)\n",
        "  car3_visible = is_visible(sample_record=instance.sample_record, annotation_token=instance.annotation_token3)\n",
        "\n",
        "  if car1_visible and car2_visible and car3_visible:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2008"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter so that car1s that are ahead of ego\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  # convert_camera(cam_position, cam_heading, obj_point)\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation1 = nusc.get('sample_annotation', instance.annotation_token)\n",
        "  car_1_trans = np.array(annotation1['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  \n",
        "  conv_x, conv_y = convert_camera(ego_trans, ego_heading, car_1_trans)\n",
        "  if conv_y > 0:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1208"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter so that car2s that are ahead of opposite_car\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  # convert_camera(cam_position, cam_heading, obj_point)\n",
        "  annotation2 = nusc.get('sample_annotation', instance.annotation_token2)\n",
        "  annotation3 = nusc.get('sample_annotation', instance.annotation_token3)\n",
        "  car_2_trans = np.array(annotation2['translation'])\n",
        "  opposite_car_trans = np.array(annotation3['translation'])\n",
        "  opposite_car_heading = get_heading(annotation3['rotation'])\n",
        "  \n",
        "  conv_x, conv_y = convert_camera(opposite_car_trans, opposite_car_heading, car_2_trans)\n",
        "  if conv_y > 0:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "instances = t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter for convertCameras\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  # convert_camera(cam_position, cam_heading, obj_point)\n",
        "  annotation3 = nusc.get('sample_annotation', instance.annotation_token3)\n",
        "\n",
        "  opposite_car_trans = np.array(annotation3['translation'])\n",
        "  opposite_car_heading = get_heading(annotation3['rotation'])\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  \n",
        "  conv_x, conv_y = convert_camera(ego_trans, ego_heading, opposite_car_trans)\n",
        "  # print(conv_x, conv_y)\n",
        "  if 1 < conv_y and conv_y < 10 and 0 < conv_x and conv_x < 50:\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7LZH2pfNkC9",
        "outputId": "3b7de815-8e76-42c3-fc49-bfa7c855d3b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1208"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter for egos whos heading is aligned with the road direction\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation = nusc.get('sample_annotation', instance.annotation_token)\n",
        "\n",
        "  ped_trans = np.array(annotation['translation'])\n",
        "  ego_trans = np.array(ego_pose['translation'])\n",
        "  \n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  road_direction = get_road_direction(ego_trans)\n",
        "  if road_direction == None:\n",
        "    new_instances.append(instance)\n",
        "  elif normalizeAngle(abs(ego_heading - road_direction)) < math.radians(15):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "instances = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWZ6xwp3NkC-",
        "outputId": "caa0a85d-661a-411b-ec37-af47bc5ccaea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "565"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Filter for ego and opposite car headings\n",
        "new_instances = []\n",
        "for instance in instances:\n",
        "  ego_pose = nusc.get('ego_pose', instance.ego_pose_token)\n",
        "  annotation3 = nusc.get('sample_annotation', instance.annotation_token3)\n",
        "  \n",
        "  ego_heading = get_heading(ego_pose['rotation'])\n",
        "  opposite_car_heading = get_heading(annotation3['rotation'])\n",
        "  if math.radians(140) < abs(normalizeAngle(ego_heading - opposite_car_heading)) and abs(normalizeAngle(ego_heading - opposite_car_heading)) < math.radians(180):\n",
        "    new_instances.append(instance)\n",
        "instances = new_instances\n",
        "len(instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Bf_ai5BSNkC-"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for instance in instances:\n",
        "  camera_token = instance.sample_record['data']['CAM_FRONT']\n",
        "  camera_data = nusc.get('sample_data', camera_token)\n",
        "  results[camera_data['token']] = camera_data['filename'] #.split('/')[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QH6chVPWNkC_",
        "outputId": "31ca7609-afb7-42fe-9a03-d80c5a13680e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621915112404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621915662404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621916162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621916662404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621917162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621918162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621918662404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621919162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621919662404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920662404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621921162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621921662404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621922162404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621922612404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621923112404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621923612404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621924112404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621924612404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621926012404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621926512404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621927012404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621927512892.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621928012404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621928512404.jpg\n",
            "samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621929012404.jpg\n"
          ]
        }
      ],
      "source": [
        "for token in results:\n",
        "  print(results[token])\n",
        "  # nusc.render_sample_data(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zdfBxIDNkC_",
        "outputId": "7acb305d-901d-4245-c72c-3f5163b269c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of expected results missing from query:  0 / 3 = 0.0 %\n",
            "Percentage of images in query but not in expected results:  23 / 26 = 88.46153846153847 %\n"
          ]
        }
      ],
      "source": [
        "############# Validation ####################\n",
        "expected_imgs = ['sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621918762404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920012404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920112404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920362404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920512404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920612404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621920662404.jpg',\n",
        " 'samples/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621923112404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621923162404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621923262404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621923412404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621927912404.jpg',\n",
        " 'sweeps/CAM_FRONT/n008-2018-07-26-12-13-50-0400__CAM_FRONT__1532621928262404.jpg']\n",
        "\n",
        "expected_imgs = list(set([x for x in expected_imgs if \"samples\" in x]))\n",
        "\n",
        "missing = 0\n",
        "missing_images = []\n",
        "for expected_img in expected_imgs:\n",
        "    if expected_img not in results.values():\n",
        "        missing += 1\n",
        "        # missing_images.append(expected_img)\n",
        "print(\"Percentage of expected results missing from query: \", missing, \"/\", len(expected_imgs), \"=\", 100 * missing / len(expected_imgs), \"%\")\n",
        "# show_images(missing_images, sample=10)\n",
        "\n",
        "extra = 0\n",
        "extra_images = {}\n",
        "for img in results:\n",
        "    if results[img] not in expected_imgs:\n",
        "        extra += 1\n",
        "        # extra_images[img] = resultImages[img]\n",
        "print(\"Percentage of images in query but not in expected results: \", extra, \"/\", len(results), \"=\", 100 * extra / len(results), \"%\")\n",
        "# show_images(extra_images.keys(), sample=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM1FPlFsNkDA",
        "outputId": "fa877eca-0d47-4653-f998-2973c188b6e2"
      },
      "outputs": [],
      "source": [
        "print(expected_imgs)\n",
        "print(list(results.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "RAW_DATA_DIR = \"/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Trainval/\"\n",
        "# Create figure and axes\n",
        "\n",
        "for img in expected_imgs:\n",
        "    im = Image.open(RAW_DATA_DIR + img)\n",
        "    # Display the image\n",
        "    plt.figure()\n",
        "    plt.imshow(im)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "L4M9bu4QNkDA",
        "outputId": "1b1eeaf1-6d04-4320-aff0-3c5382c9a4d3"
      },
      "outputs": [],
      "source": [
        "fig, ax = nusc_map.render_layers(nusc_map.non_geometric_layers, figsize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26PAYhF7NkDB",
        "outputId": "bc25c578-feed-4a50-803e-8c8447c060da"
      },
      "outputs": [],
      "source": [
        "nusc.list_scenes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g6-DjTMNkDB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FSf0zbS6RBqV",
        "XRmO8-tsqYZY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
