{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e4726-2856-4e5f-a220-e3bef1c110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "import shutil\n",
    "import socket\n",
    "import time\n",
    "from os import environ\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import psycopg2\n",
    "\n",
    "subprocess.Popen('nvidia-smi', shell=True).wait()\n",
    "process = subprocess.Popen('docker container start mobilitydb', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaf7b9-8b3f-4f2f-ad00-08b197795820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hostname = socket.gethostname()\n",
    "test = hostname.split(\"-\")[-1]\n",
    "print(\"test\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        else:\n",
    "            # Other type (?)\n",
    "            return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_notebook():\n",
    "    %cd ..\n",
    "    from tqdm.notebook import tqdm\n",
    "    from nbutils.report_progress import report_progress\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    from playground.nbutils.report_progress import report_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4d993-d0a4-49d5-8b4d-1b3a62f66da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.video import Video\n",
    "from optimized_ingestion.metadata_json_encoder import MetadataJSONEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b7bd6-7bc4-4658-bb06-043ba955aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stages\n",
    "from optimized_ingestion.stages.in_view import InView\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "\n",
    "from optimized_ingestion.stages.detection_2d.detection_2d import Detection2D\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_2d.ground_truth import GroundTruthDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9880e-27d0-47f3-a3dd-36b70d199d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_road import FromDetection2DAndRoad\n",
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_depth import FromDetection2DAndDepth\n",
    "\n",
    "from optimized_ingestion.stages.depth_estimation import DepthEstimation\n",
    "\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.detection_estimation.segment_mapping import RoadPolygonInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bddca-a1ae-4806-be85-8cf397d01ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking.strongsort import StrongSORT\n",
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT as StrongSORT2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737b34b-d928-45aa-940e-b23a7a6e5eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_road import FromTracking2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_depth import FromTracking2DAndDepth\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "\n",
    "from optimized_ingestion.stages.segment_trajectory import SegmentTrajectory\n",
    "from optimized_ingestion.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "from optimized_ingestion.stages.segment_trajectory.from_tracking_3d import FromTracking3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59907886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650e6ca-9d7c-41e9-98ee-f682b399040f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.utils.process_pipeline import format_trajectory, insert_trajectory, get_tracks\n",
    "from optimized_ingestion.actions.tracking2d_overlay import tracking2d_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c8190-89ee-472a-bd73-d553eb3e3278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from apperception.utils.ingest_road import ingest_road\n",
    "from apperception.database import database, Database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b8977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "# with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "#     videos = pickle.load(f)\n",
    "with open(os.path.join(DATA_DIR, 'videos', 'videos.json'), 'r') as f:\n",
    "    videos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./data/evaluation/video-samples/boston-seaport.txt', 'r') as f:\n",
    "    sampled_scenes = f.read().split('\\n')\n",
    "print(sampled_scenes[0], sampled_scenes[-1], len(sampled_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3599c-3807-4044-9636-45b2d94fe7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCHMARK_DIR = \"./outputs/run\"\n",
    "\n",
    "\n",
    "def bm_dir(*args: \"str\"):\n",
    "    return os.path.join(BENCHMARK_DIR, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275836d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename, predicates, run=0, ignore_error=False):\n",
    "    print(filename)\n",
    "    try:\n",
    "        metadata_strongsort = {}\n",
    "        metadata_d2d = {}\n",
    "        failed_videos = []\n",
    "        runtime_input = []\n",
    "        runtime_query = []\n",
    "        runtime_video = []\n",
    "\n",
    "        all_metadata = {\n",
    "            'detection': metadata_d2d,\n",
    "            'sort': metadata_strongsort,\n",
    "        }\n",
    "\n",
    "        names = set(sampled_scenes[:100])\n",
    "        filtered_videos = [\n",
    "            n for n in videos\n",
    "            if n[6:10] in names and n.endswith('FRONT')\n",
    "        ]\n",
    "        print('# of total    videos:', len(videos))\n",
    "        print('# of filtered videos:', len(filtered_videos))\n",
    "        # ingest_road(database, './data/scenic/road-network/boston-seaport')\n",
    "\n",
    "        for pre in all_metadata.keys():\n",
    "            p = os.path.join(BENCHMARK_DIR, f\"{pre}--{filename}_{run}\")\n",
    "            if os.path.exists(p):\n",
    "                shutil.rmtree(p)\n",
    "            os.makedirs(p)\n",
    "\n",
    "        def save_perf():\n",
    "            with open(bm_dir(f\"failed_videos--{filename}_{run}.json\"), \"w\") as f:\n",
    "                json.dump(failed_videos, f, indent=1)\n",
    "\n",
    "            with open(bm_dir(f\"perf--{filename}_{run}.json\"), \"w\") as f:\n",
    "                performance = [\n",
    "                    {\n",
    "                        \"stage\": stage.classname(),\n",
    "                        \"benchmark\": stage.benchmark,\n",
    "                        **(\n",
    "                            {'explains': stage.explains}\n",
    "                            if hasattr(stage, 'explains')\n",
    "                            else {}\n",
    "                        ),\n",
    "                        **(\n",
    "                            {\"ss-benchmark\": stage.ss_benchmark}\n",
    "                            if hasattr(stage, 'ss_benchmark')\n",
    "                            else {}\n",
    "                        )\n",
    "                    }\n",
    "                    for stage\n",
    "                    in pipeline.stages\n",
    "                ]\n",
    "                json.dump(performance, f, indent=1)\n",
    "            with open(bm_dir(f\"perfexec--{filename}_{run}.json\"), 'w') as f:\n",
    "                json.dump({\n",
    "                    'ingest': 2.2629338979721068,\n",
    "                    'input': runtime_input,\n",
    "                    'query': runtime_query,\n",
    "                    'save': runtime_video\n",
    "                }, f, indent=1)\n",
    "\n",
    "        for i, name in tqdm(enumerate(filtered_videos), total=len(filtered_videos)):\n",
    "            # if i % int(len(filtered_videos) / 200) == 0:\n",
    "            #     report_progress(i, len(filtered_videos), filename, str(run))\n",
    "            try:\n",
    "                start_input = time.time()\n",
    "                with open(os.path.join(DATA_DIR, 'videos', 'boston-seaport-' + name + '.pkl'), 'rb') as f:\n",
    "                    video = pickle.load(f)\n",
    "                video_filename = video['filename']\n",
    "                # if not video_filename.startswith('boston') or 'FRONT' not in name:\n",
    "                #     continue\n",
    "\n",
    "                frames = Video(\n",
    "                    os.path.join(DATA_DIR, \"videos\", video[\"filename\"]),\n",
    "                    [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "                )\n",
    "                time_input = time.time() - start_input\n",
    "                runtime_input.append({'name': name, 'runtime': time_input})\n",
    "\n",
    "                output = pipeline.run(Payload(frames))\n",
    "\n",
    "                metadata_strongsort[name] = output[StrongSORT2D]\n",
    "                metadata_d2d[name] = output[Detection2D]\n",
    "\n",
    "                for pre, metadata in all_metadata.items():\n",
    "                    p = bm_dir(f\"{pre}--{filename}_{run}\", f\"{name}.json\")\n",
    "                    with open(p, \"w\") as f:\n",
    "                        json.dump(metadata[name], f, cls=MetadataJSONEncoder, indent=1)\n",
    "\n",
    "                for i, (predicate, n_objects) in enumerate(predicates):\n",
    "                    start_rquery = time.time()\n",
    "                    database.reset(True)\n",
    "                    ego_meta = frames.interpolated_frames\n",
    "                    sortmeta = FromTracking2DAndRoad.get(output)\n",
    "                    segment_trajectory_mapping = FromTracking3D.get(output)\n",
    "                    tracks = get_tracks(sortmeta, ego_meta, segment_trajectory_mapping, True)\n",
    "                    for obj_id, track in tracks.items():\n",
    "                        trajectory = format_trajectory(name, obj_id, track, True)\n",
    "                        if trajectory:\n",
    "                            insert_trajectory(database, *trajectory)\n",
    "\n",
    "                    world = empty_world()\n",
    "                    world = world.filter(predicate)\n",
    "                    _ = world.get_id_time_camId_filename(num_joined_tables=n_objects)\n",
    "                    time_rquery = time.time() - start_rquery\n",
    "                    runtime_query.append({'name': name, 'predicate': i, 'runtime': time_rquery})\n",
    "\n",
    "                # save video\n",
    "                start_video = time.time()\n",
    "                tracking2d_overlay(output, './tmp.mp4')\n",
    "                time_video = time.time() - start_video\n",
    "                runtime_video.append({'name': name, 'runtime': time_video})\n",
    "            except Exception as e:\n",
    "                if ignore_error:\n",
    "                    message = str(traceback.format_exc())\n",
    "                    failed_videos.append((name, message))\n",
    "                    print(video_filename)\n",
    "                    print(e)\n",
    "                    print(message)\n",
    "                    print(\"------------------------------------------------------------------------------------\")\n",
    "                    print()\n",
    "                    print()\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "            if len(metadata_d2d) % 10 == 0:\n",
    "                save_perf()\n",
    "    except KeyboardInterrupt:\n",
    "        print('keyboard inturrupted')\n",
    "    save_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98283938-b68f-4925-a5ef-eee7c6c46c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "    ss_update_when_skip=True,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, predicate=predicate))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(DecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "            df_annotations = pickle.load(f)\n",
    "        pipeline.add_filter(GroundTruthDetection(df_annotations))\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        # if isinstance(object_filter, bool):\n",
    "        #     object_filter = ['car', 'truck']\n",
    "        # TODO: filter objects based on predicate\n",
    "        pipeline.add_filter(ObjectTypeFilter(predicate=predicate))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromDetection2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(FromDetection2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(StrongSORT2D(\n",
    "        # method='update-empty' if ss_update_when_skip else 'increment-ages',\n",
    "        method='update-empty',\n",
    "        cache=True\n",
    "    ))\n",
    "\n",
    "    pipeline.add_filter(FromTracking2DAndRoad())\n",
    "\n",
    "    # Segment Trajectory\n",
    "    pipeline.add_filter(FromTracking3D())\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adca3d-7963-4dc6-bde1-d0ce107ae959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicate = None\n",
    "\n",
    "p_noOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_inview = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objectFilter = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_de = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_deIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_opt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_optDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_optIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_optDeIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_gtOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_gtOptDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"noopt\": p_noOpt,\n",
    "    \"inview\": p_inview,\n",
    "    \"objectfilter\": p_objectFilter,\n",
    "    \"geo\": p_geo,\n",
    "    \"de\": p_de,\n",
    "    \"deincr\": p_deIncr,\n",
    "    \"opt\": p_opt,\n",
    "    \"optincr\": p_optIncr,\n",
    "    \"optde\": p_optDe,\n",
    "    \"optdeincr\": p_optDeIncr,\n",
    "\n",
    "    \"gtopt\": p_gtOpt,\n",
    "    \"gtoptde\": p_gtOptDe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e586a-a98c-4c15-ac5a-17551b3155db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test == 'dev':\n",
    "    test = 'optde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7c558-dc6e-4b86-b447-a3ffac74c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(test):\n",
    "    o = objects[0]\n",
    "    c = camera\n",
    "    pred1 = (\n",
    "        (o.type == 'person') &\n",
    "        F.contained(c.ego, 'intersection') &\n",
    "        (F.contained_margin(o.bbox@c.time, F.road_segment('road'), lit(0.50)) | F.contained(o.trans@c.time, 'intersection')) &\n",
    "        F.angle_excluding(F.facing_relative(o.traj@c.time, c.ego), lit(-70), lit(70)) &\n",
    "        F.angle_between(F.facing_relative(c.ego, c.roadDirection), lit(-15), lit(15)) &\n",
    "        (F.distance(c.camAbs, o.traj@c.time) < lit(50)) &\n",
    "        (F.view_angle(o.trans@c.time, c.camAbs) < lit(35))\n",
    "    )\n",
    "\n",
    "    obj1 = objects[0]\n",
    "    obj2 = objects[1]\n",
    "    cam = camera\n",
    "    pred2 = (\n",
    "        (obj1.id != obj2.id) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        ((obj2.type == 'car') | (obj2.type == 'truck')) &\n",
    "        F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego)), -15, 15) &\n",
    "        (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
    "        (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "        (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
    "        (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "        F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 40, 135) &\n",
    "        F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
    "        (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    "    )\n",
    "\n",
    "    obj1 = objects[0]\n",
    "    cam = camera\n",
    "    pred3 = (\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        (F.distance(cam.ego, obj1.trans@cam.timestamp) < 50) &\n",
    "        (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2) &\n",
    "        F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -180, -90) &\n",
    "        F.contained(cam.ego, F.road_segment('road')) &\n",
    "        F.contained(obj1.trans@cam.time, F.road_segment('road')) &\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, F.road_direction(obj1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        (F.distance(cam.ego, obj1.trans@cam.time) < 10)\n",
    "    )\n",
    "\n",
    "    cam = camera\n",
    "    car1 = objects[0]\n",
    "    opposite_car = objects[1]\n",
    "    car2 = objects[2]\n",
    "\n",
    "    pred4 = (\n",
    "        ((car1.type == 'car') | (car1.type == 'truck')) &\n",
    "        ((car2.type == 'car') | (car2.type == 'truck')) &\n",
    "        ((opposite_car.type == 'car') | (opposite_car.type == 'truck')) &\n",
    "        (opposite_car.id != car2.id) &\n",
    "        (car1.id != car2.id) &\n",
    "        (car1.id != opposite_car.id) &\n",
    "\n",
    "        F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) &\n",
    "        (F.view_angle(car1.traj@cam.time, cam.ego) < 70 / 2) &\n",
    "        (F.distance(cam.ego, car1.traj@cam.time) < 40) &\n",
    "        F.angle_between(F.facing_relative(car1.traj@cam.time, cam.ego), -15, 15) &\n",
    "        F.angle_between(F.facing_relative(car1.traj@cam.time, F.road_direction(car1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        F.ahead(car1.traj@cam.time, cam.ego) &\n",
    "        F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego, cam.ego)), -15, 15) &\n",
    "        (F.convert_camera(opposite_car.traj@cam.time, cam.ego) > [-10, 0]) &\n",
    "        (F.convert_camera(opposite_car.traj@cam.time, cam.ego) < [-1, 50]) &\n",
    "        F.angle_between(F.facing_relative(opposite_car.traj@cam.time, cam.ego), 140, 180) &\n",
    "        (F.distance(opposite_car@cam.time, car2@cam.time) < 40) &\n",
    "        F.angle_between(F.facing_relative(car2.traj@cam.time, F.road_direction(car2.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        F.ahead(car2.traj@cam.time, opposite_car.traj@cam.time)\n",
    "    )\n",
    "\n",
    "    p1 = pipelines[test](pred1)\n",
    "    p2 = pipelines[test](pred2)\n",
    "    p34 = pipelines[test](pred3)\n",
    "\n",
    "    if test != 'optde' and test != 'de':\n",
    "        run_benchmark(p1, 'q1-' + test, [(pred1, 1)], run=1, ignore_error=True)\n",
    "\n",
    "    run_benchmark(p2, 'q2-' + test, [(pred2, 2)], run=1, ignore_error=True)\n",
    "\n",
    "    run_benchmark(p34, 'q34-' + test, [(pred3, 1), (pred4, 3)], run=1, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443364e8-c58b-4940-9fd4-539ee77d043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14e9fd-6083-4351-bceb-6b31b19a4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test == 'opt':\n",
    "    run('optde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a04b-e888-417c-967a-0399f1c8c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_notebook():\n",
    "    subprocess.Popen('sudo shutdown -h now', shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
