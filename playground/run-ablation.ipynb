{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e4726-2856-4e5f-a220-e3bef1c110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "import shutil\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "\n",
    "from os import environ\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import psycopg2\n",
    "\n",
    "subprocess.Popen('nvidia-smi', shell=True).wait()\n",
    "process = subprocess.Popen('docker container start mobilitydb', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaf7b9-8b3f-4f2f-ad00-08b197795820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hostname = socket.gethostname()\n",
    "test = hostname.split(\"-\")[-1]\n",
    "print(\"test\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        else:\n",
    "            # Other type (?)\n",
    "            return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_notebook():\n",
    "    %cd ..\n",
    "    from tqdm.notebook import tqdm\n",
    "    from nbutils.report_progress import report_progress\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    from playground.nbutils.report_progress import report_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4d993-d0a4-49d5-8b4d-1b3a62f66da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.video import Video\n",
    "from optimized_ingestion.metadata_json_encoder import MetadataJSONEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b7bd6-7bc4-4658-bb06-043ba955aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stages\n",
    "from optimized_ingestion.stages.in_view import InView\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "\n",
    "from optimized_ingestion.stages.detection_2d.detection_2d import Detection2D\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_2d.ground_truth import GroundTruthDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9880e-27d0-47f3-a3dd-36b70d199d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_road import FromDetection2DAndRoad\n",
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_depth import FromDetection2DAndDepth\n",
    "\n",
    "from optimized_ingestion.stages.depth_estimation import DepthEstimation\n",
    "\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.detection_estimation.segment_mapping import RoadPolygonInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bddca-a1ae-4806-be85-8cf397d01ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking.strongsort import StrongSORT\n",
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT as StrongSORT2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737b34b-d928-45aa-940e-b23a7a6e5eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_road import FromTracking2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_depth import FromTracking2DAndDepth\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "\n",
    "from optimized_ingestion.stages.segment_trajectory import SegmentTrajectory\n",
    "from optimized_ingestion.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "from optimized_ingestion.stages.segment_trajectory.from_tracking_3d import FromTracking3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59907886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650e6ca-9d7c-41e9-98ee-f682b399040f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.utils.process_pipeline import format_trajectory, insert_trajectory, get_tracks\n",
    "from optimized_ingestion.actions.tracking2d_overlay import tracking2d_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c8190-89ee-472a-bd73-d553eb3e3278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from apperception.utils.ingest_road import ingest_road\n",
    "from apperception.database import database, Database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects, lit, FindAllTablesVisitor, normalize, MapTablesTransformer, GenSqlVisitor\n",
    "from apperception.data_types.camera import Camera as ACamera\n",
    "from apperception.data_types.camera_config import CameraConfig as ACameraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b8977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "# with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "#     videos = pickle.load(f)\n",
    "with open(os.path.join(DATA_DIR, 'videos', 'videos.json'), 'r') as f:\n",
    "    videos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./data/evaluation/video-samples/boston-seaport.txt', 'r') as f:\n",
    "    sampled_scenes = f.read().split('\\n')\n",
    "print(sampled_scenes[0], sampled_scenes[-1], len(sampled_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3599c-3807-4044-9636-45b2d94fe7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCHMARK_DIR = \"./outputs/run\"\n",
    "\n",
    "\n",
    "def bm_dir(*args: \"str\"):\n",
    "    return os.path.join(BENCHMARK_DIR, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97a25a-0356-4d7e-9096-f26c00d2d9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sql(predicate: \"PredicateNode\"):\n",
    "    tables, camera = FindAllTablesVisitor()(predicate)\n",
    "    tables = sorted(tables)\n",
    "    mapping = {t: i for i, t in enumerate(tables)}\n",
    "    predicate = normalize(predicate)\n",
    "    predicate = MapTablesTransformer(mapping)(predicate)\n",
    "\n",
    "    t_tables = ''\n",
    "    t_outputs = ''\n",
    "    for i in range(len(tables)):\n",
    "        t_tables += '\\n' \\\n",
    "            'JOIN Item_General_Trajectory ' \\\n",
    "            f'AS t{i} ' \\\n",
    "            f'ON Cameras.timestamp <@ t{i}.trajCentroids::period'\n",
    "        t_outputs += f', t{i}.itemId'\n",
    "\n",
    "    return f\"\"\"\n",
    "        SELECT Cameras.frameNum {t_outputs}\n",
    "        FROM Cameras{t_tables}\n",
    "        WHERE\n",
    "        {GenSqlVisitor()(predicate)}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4149a3-43b5-4531-90dd-31dd795bdaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slices = {\n",
    "    \"noopt\": (0, 1),\n",
    "    \"inview\": (1, 2),\n",
    "    \"objectfilter\": (2, 3),\n",
    "    \"geo\": (3, 4),\n",
    "    \"de\": (4, 5),\n",
    "    \"opt\": (5, 6),\n",
    "    # \"optde\": (6, 7),\n",
    "    'dev': (0, 2),\n",
    "    'freddie': (1, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275836d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename, predicates, run=0, ignore_error=False):\n",
    "    print(filename)\n",
    "    metadata_strongsort = {}\n",
    "    metadata_d2d = {}\n",
    "    failed_videos = []\n",
    "\n",
    "    all_metadata = {\n",
    "        'detection': metadata_d2d,\n",
    "        'sort': metadata_strongsort,\n",
    "    }\n",
    "    print('# of total    videos:', len(videos))\n",
    "\n",
    "    names = set(sampled_scenes[:50])\n",
    "    filtered_videos = [\n",
    "        n for n in videos\n",
    "        if n[6:10] in names and 'FRONT' in n\n",
    "    ]\n",
    "    N = len(filtered_videos)\n",
    "    print('# of filtered videos:', N)\n",
    "\n",
    "    # s_from, s_to = slices[test]\n",
    "    s_from, s_to = (int(test), int(test) + 1)\n",
    "    STEP = N // 10\n",
    "    print('test', test)\n",
    "    print('from', s_from*STEP)\n",
    "    print('to  ', s_to*STEP)\n",
    "    filtered_videos = filtered_videos[s_from*STEP:s_to*STEP]\n",
    "    print('# of sliced   videos:', len(filtered_videos))\n",
    "    # ingest_road(database, './data/scenic/road-network/boston-seaport')\n",
    "\n",
    "    for pre in [*all_metadata.keys(), 'qresult', 'performance', 'failedvideos']:\n",
    "        p = os.path.join(BENCHMARK_DIR, f\"{pre}--{filename}_{run}\")\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p)\n",
    "        os.makedirs(p)\n",
    "\n",
    "    def save_perf():\n",
    "        for n, message in failed_videos:\n",
    "            p = bm_dir(f'failedvideos--{filename}_{run}', f'{n}.txt')\n",
    "            with open(p, \"w\") as f:\n",
    "                f.write(message)\n",
    "\n",
    "    for i, name in tqdm(enumerate(filtered_videos), total=len(filtered_videos)):\n",
    "        try:\n",
    "            start_input = time.time()\n",
    "            with open(os.path.join(DATA_DIR, 'videos', 'boston-seaport-' + name + '.pkl'), 'rb') as f:\n",
    "                video = pickle.load(f)\n",
    "            video_filename = video['filename']\n",
    "\n",
    "            frames = Video(\n",
    "                os.path.join(DATA_DIR, \"videos\", video[\"filename\"]),\n",
    "                [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "            )\n",
    "            time_input = time.time() - start_input\n",
    "\n",
    "            output = pipeline.run(Payload(frames))\n",
    "\n",
    "            metadata_strongsort[name] = output[StrongSORT2D]\n",
    "            metadata_d2d[name] = output[Detection2D]\n",
    "\n",
    "            for pre, metadata in all_metadata.items():\n",
    "                p = bm_dir(f\"{pre}--{filename}_{run}\", f\"{name}.json\")\n",
    "                with open(p, \"w\") as f:\n",
    "                    json.dump(metadata[name], f, cls=MetadataJSONEncoder,\n",
    "                              indent=1)\n",
    "\n",
    "            times_rquery = []\n",
    "            for i, predicate in enumerate(predicates):\n",
    "                start_rquery = time.time()\n",
    "                database.reset(True)\n",
    "\n",
    "                # Ingest Trackings\n",
    "                ego_meta = frames.interpolated_frames\n",
    "                sortmeta = FromTracking2DAndRoad.get(output)\n",
    "                assert sortmeta is not None\n",
    "                segment_trajectories = FromTracking3D.get(output)\n",
    "                tracks = get_tracks(sortmeta, ego_meta, segment_trajectories)\n",
    "                for obj_id, track in tracks.items():\n",
    "                    trajectory = format_trajectory(name, obj_id, track)\n",
    "                    if trajectory:\n",
    "                        insert_trajectory(database, *trajectory)\n",
    "\n",
    "                # Ingest Camera\n",
    "                accs: 'ACameraConfig' = []\n",
    "                for idx, cc in enumerate(frames.interpolated_frames):\n",
    "                    acc = ACameraConfig(\n",
    "                        frame_id=cc.frame_id,\n",
    "                        frame_num=idx,\n",
    "                        filename=cc.filename,\n",
    "                        camera_translation=cc.camera_translation,\n",
    "                        camera_rotation=cc.camera_rotation,\n",
    "                        camera_intrinsic=cc.camera_intrinsic,\n",
    "                        ego_translation=cc.ego_translation,\n",
    "                        ego_rotation=cc.ego_rotation,\n",
    "                        timestamp=cc.timestamp,\n",
    "                        cameraHeading=cc.camera_heading,\n",
    "                        egoHeading=cc.ego_heading,\n",
    "                    )\n",
    "                    accs.append(acc)\n",
    "                camera = ACamera(accs, cc.camera_id)\n",
    "                database.insert_cam(camera)\n",
    "\n",
    "                query = get_sql(predicate)\n",
    "                qresult = database.execute(query)\n",
    "\n",
    "                p = bm_dir(f\"qresult--{filename}_{run}\", f\"{name}-{i}.json\")\n",
    "                with open(p, 'w') as f:\n",
    "                    json.dump(qresult, f, indent=1)\n",
    "                time_rquery = time.time() - start_rquery\n",
    "                times_rquery.append(time_rquery)\n",
    "                # runtime_query.append({'name': name, 'predicate': i, 'runtime': time_rquery})\n",
    "\n",
    "            # save video\n",
    "            start_video = time.time()\n",
    "            tracking2d_overlay(output, './tmp.mp4')\n",
    "            time_video = time.time() - start_video\n",
    "            # runtime_video.append({'name': name, 'runtime': time_video})\n",
    "\n",
    "            perf = []\n",
    "            for stage in pipeline.stages:\n",
    "                benchmarks = [*filter(\n",
    "                    lambda x: video['filename'] in x['name'],\n",
    "                    stage.benchmark\n",
    "                )]\n",
    "                assert len(benchmarks) == 1\n",
    "                perf.append({\n",
    "                    'stage': stage.classname(),\n",
    "                    'benchmark': benchmarks[0]\n",
    "                })\n",
    "\n",
    "                for bm in getattr(stage, '_benchmark', []):\n",
    "                    if video['filename'] in bm['name']:\n",
    "                        perf.append({\n",
    "                            'stage': stage.classname(),\n",
    "                            'addition': True,\n",
    "                            'benchmark': bm,\n",
    "                        })\n",
    "\n",
    "            perf.append({\n",
    "                'stage': 'ingest',\n",
    "                'benchmark': {\n",
    "                    'name': name,\n",
    "                    'runtime': time_input\n",
    "                }\n",
    "            })\n",
    "            perf.append({\n",
    "                'stage': 'save',\n",
    "                'benchmark': {\n",
    "                    'name': name,\n",
    "                    'runtime': time_video\n",
    "                }\n",
    "            })\n",
    "            for i, time_rquery in enumerate(times_rquery):\n",
    "                perf.append({\n",
    "                    'stage': 'query',\n",
    "                    'benchmark': {\n",
    "                        'name': name,\n",
    "                        'predicate': i,\n",
    "                        'runtime': time_rquery\n",
    "                    }\n",
    "                })\n",
    "            p = bm_dir(f'performance--{filename}_{run}', f'{name}.json')\n",
    "            with open(p, \"w\") as f:\n",
    "                json.dump(perf, f, indent=1)\n",
    "        except Exception as e:\n",
    "            if ignore_error:\n",
    "                message = str(traceback.format_exc())\n",
    "                failed_videos.append((name, message))\n",
    "                print(video_filename)\n",
    "                print(e)\n",
    "                print(message)\n",
    "                print(\"------------------------------------------------------------------------------------\")\n",
    "                print()\n",
    "                print()\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        if len(metadata_d2d) % 10 == 0:\n",
    "            save_perf()\n",
    "    save_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98283938-b68f-4925-a5ef-eee7c6c46c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "    ss_update_when_skip=True,\n",
    "    ss_cache=True,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, predicate=predicate))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(DecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "            df_annotations = pickle.load(f)\n",
    "        pipeline.add_filter(GroundTruthDetection(df_annotations))\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        # if isinstance(object_filter, bool):\n",
    "        #     object_filter = ['car', 'truck']\n",
    "        # TODO: filter objects based on predicate\n",
    "        pipeline.add_filter(ObjectTypeFilter(predicate=predicate))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromDetection2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(FromDetection2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(StrongSORT2D(\n",
    "        # method='update-empty' if ss_update_when_skip else 'increment-ages',\n",
    "        method='update-empty',\n",
    "        cache=ss_cache,\n",
    "    ))\n",
    "\n",
    "    pipeline.add_filter(FromTracking2DAndRoad())\n",
    "\n",
    "    # Segment Trajectory\n",
    "    # pipeline.add_filter(FromTracking3D())\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adca3d-7963-4dc6-bde1-d0ce107ae959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_noSSOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False,\n",
    "    ss_cache=False,\n",
    ")\n",
    "\n",
    "p_noOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_inview = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objectFilter = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_de = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_deIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_opt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_optDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_optIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_optDeIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_gtOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_gtOptDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"nossopt\": p_noSSOpt,\n",
    "    \"noopt\": p_noOpt,\n",
    "    \"inview\": p_inview,\n",
    "    \"objectfilter\": p_objectFilter,\n",
    "    \"geo\": p_geo,\n",
    "    \"de\": p_de,\n",
    "    # \"deincr\": p_deIncr,\n",
    "    \"opt\": p_opt,\n",
    "    # \"optincr\": p_optIncr,\n",
    "    \"optde\": p_optDe,\n",
    "    # \"optdeincr\": p_optDeIncr,\n",
    "\n",
    "    # \"gtopt\": p_gtOpt,\n",
    "    # \"gtoptde\": p_gtOptDe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e586a-a98c-4c15-ac5a-17551b3155db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if test == 'dev':\n",
    "#     test = 'opt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7c558-dc6e-4b86-b447-a3ffac74c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(__test):\n",
    "    o = objects[0]\n",
    "    c = camera\n",
    "    pred1 = (\n",
    "        (o.type == 'person') &\n",
    "        # F.contained(c.ego, 'intersection') &\n",
    "        F.contained(o.trans@c.time, 'intersection') &\n",
    "        F.angle_excluding(F.facing_relative(o.traj@c.time, c.cam), lit(-70), lit(70)) &\n",
    "        # F.angle_between(F.facing_relative(c.cam, F.road_direction(c.ego)), lit(-15), lit(15)) &\n",
    "        (F.distance(c.cam, o.traj@c.time) < lit(50)) # &\n",
    "        # (F.view_angle(o.trans@c.time, c.camAbs) < lit(35))\n",
    "    )\n",
    "    pred1_notrack = (\n",
    "        F.contained(o.trans@c.time, 'intersection') &\n",
    "        (F.distance(c.cam, o.traj@c.time) < lit(50)) &\n",
    "        (o.type == 'person')\n",
    "    )\n",
    "\n",
    "    obj1 = objects[0]\n",
    "    obj2 = objects[1]\n",
    "    cam = camera\n",
    "    pred2 = (\n",
    "        (obj1.id != obj2.id) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        ((obj2.type == 'car') | (obj2.type == 'truck')) &\n",
    "        F.angle_between(F.facing_relative(cam.cam, F.road_direction(cam.cam)), -15, 15) &\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 50) &\n",
    "\n",
    "        # (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "        (F.distance(cam.cam, obj2.trans@cam.time) < 50) &\n",
    "        # (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "        F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "        # F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.cam), 40, 135) &\n",
    "        # F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.cam), -135, -50)\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), -180, -90)\n",
    "        # (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "        # F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    "    )\n",
    "    pred2_notrack = (\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 50) &\n",
    "        (F.distance(cam.cam, obj2.trans@cam.time) < 50) &\n",
    "        F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "        (obj1.id != obj2.id) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        ((obj2.type == 'car') | (obj2.type == 'truck'))\n",
    "    )\n",
    "\n",
    "    obj1 = objects[0]\n",
    "    cam = camera\n",
    "    pred3 = (\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        # (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2) &\n",
    "        F.angle_between(F.facing_relative(cam.cam, F.road_direction(cam.ego, cam.ego)), 135, 225) &\n",
    "        F.contained(cam.cam, F.road_segment('lane')) &\n",
    "        F.contained(obj1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, F.road_direction(obj1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        # F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 135, 225) &\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 10)\n",
    "    )\n",
    "    pred3_notrack = (\n",
    "        # F.contained(cam.cam, F.road_segment('lane')) &\n",
    "        F.contained(obj1.trans@cam.time, F.road_segment('lane')) &\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 10) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck'))\n",
    "    )\n",
    "\n",
    "    cam = camera\n",
    "    car1 = objects[0]\n",
    "    opposite_car_1 = objects[1]\n",
    "    opposite_car_2 = objects[2]\n",
    "\n",
    "    pred4 = (\n",
    "        ((car1.type == 'car') | (car1.type == 'truck')) &\n",
    "        ((opposite_car_2.type == 'car') | (opposite_car_2.type == 'truck')) &\n",
    "        ((opposite_car_1.type == 'car') | (opposite_car_1.type == 'truck')) &\n",
    "        (opposite_car_1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_1.id) &\n",
    "\n",
    "        F.contained(cam.cam, F.road_segment('lane')) &\n",
    "        F.contained(car1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_2.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.angle_between(F.facing_relative(cam.cam, F.road_direction(cam.cam, cam.cam)), -15, 15) &\n",
    "        # (F.view_angle(car1.traj@cam.time, cam.ego) < 70 / 2) &\n",
    "        (F.distance(cam.cam, car1.traj@cam.time) < 40) &\n",
    "        F.angle_between(F.facing_relative(car1.traj@cam.time, cam.ego), -15, 15) &\n",
    "        # F.angle_between(F.facing_relative(car1.traj@cam.time, F.road_direction(car1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        F.ahead(car1.traj@cam.time, cam.cam) &\n",
    "        # (F.convert_camera(opposite_car.traj@cam.time, cam.ego) > [-10, 0]) &\n",
    "        # (F.convert_camera(opposite_car.traj@cam.time, cam.ego) < [-1, 50]) &\n",
    "        F.angle_between(F.facing_relative(opposite_car_1.traj@cam.time, cam.ego), 135, 225) &\n",
    "        # (F.distance(opposite_car@cam.time, car2@cam.time) < 40)# &\n",
    "        F.angle_between(F.facing_relative(opposite_car_2.traj@cam.time, opposite_car_1.traj@cam.time), -15, 15) &\n",
    "        F.angle_between(F.facing_relative(opposite_car_2.traj@cam.time, F.road_direction(opposite_car_2.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        F.ahead(opposite_car_2.traj@cam.time, opposite_car_1.traj@cam.time)\n",
    "    )\n",
    "    pred4_notrack = (\n",
    "        # F.contained(cam.cam,                       F.road_segment('lane')) &\n",
    "        F.contained(car1.trans@cam.time,           F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_2.trans@cam.time, F.road_segment('lane')) &\n",
    "        ((car1.type == 'car') | (car1.type == 'truck')) &\n",
    "        ((opposite_car_2.type == 'car') | (opposite_car_2.type == 'truck')) &\n",
    "        ((opposite_car_1.type == 'car') | (opposite_car_1.type == 'truck')) &\n",
    "        (opposite_car_1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_1.id)\n",
    "    )\n",
    "\n",
    "    p1 = pipelines[__test](pred1)\n",
    "    p2 = pipelines[__test](pred2)\n",
    "    p34 = pipelines[__test](pred3)\n",
    "\n",
    "    print('Pipeline P2:')\n",
    "    for s in p2.stages:\n",
    "        print(' -', s)\n",
    "    run_benchmark(p2, 'q2-' + __test, [pred2, pred2_notrack], run=1, ignore_error=True)\n",
    "\n",
    "    # print('Pipeline P3,P4:')\n",
    "    # for s in p34.stages:\n",
    "    #     print(' -', s)\n",
    "    # run_benchmark(p34, 'q34-' + __test, [pred3, pred4, pred3_notrack, pred4_notrack], run=1, ignore_error=True)\n",
    "\n",
    "    # if __test != 'optde' and __test != 'de':\n",
    "    #     print('Pipeline P1:')\n",
    "    #     for s in p1.stages:\n",
    "    #         print(' -', s)\n",
    "    #     run_benchmark(p1, 'q1-' + __test, [pred1, pred1_notrack], run=1, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c4351-f2a7-478b-b264-69a3e8d75c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests = ['de', 'optde', 'noopt', 'inview', 'objectfilter', 'geo', 'opt']\n",
    "# tests = ['de', 'optde']\n",
    "# tests = ['de']\n",
    "# random.shuffle(tests)\n",
    "\n",
    "for _test in tests:\n",
    "    assert isinstance(pipelines[_test](lit(True)), Pipeline)\n",
    "\n",
    "for idx, _test in enumerate(tests):\n",
    "    print(f'----------- {idx} / {len(tests)} --- {_test} -----------')\n",
    "    done = False\n",
    "    retry = 0\n",
    "    while not done and retry < 5:\n",
    "        try:\n",
    "            run(_test)\n",
    "            done = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('retrying...')\n",
    "            time.sleep(60)\n",
    "            retry += 1\n",
    "            with open(os.path.join(BENCHMARK_DIR, f'exception--bm{test}-t{_test}-r{retry}'), 'w') as f:\n",
    "                f.write(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443364e8-c58b-4940-9fd4-539ee77d043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14e9fd-6083-4351-bceb-6b31b19a4e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if test == 'opt':\n",
    "#     run('optde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a04b-e888-417c-967a-0399f1c8c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_notebook():\n",
    "    subprocess.Popen('sudo shutdown -h now', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad6fa9-3d74-4dc1-989d-08dfda7f3489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
