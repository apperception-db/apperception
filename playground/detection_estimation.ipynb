{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ea91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "from detection_estimation.segment_mapping import *\n",
    "import matplotlib.pyplot as plt\n",
    "from apperception.utils import fetch_camera_config, fetch_camera_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32e753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_config = fetch_camera_config('samples/CAM_FRONT/n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385108912404.jpg', database)\n",
    "# test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = map_imgsegment_roadsegment(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file_path = '/home/yongming/workspace/research/apperception/v1.0-mini/samples/CAM_FRONT/n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385108912404.jpg'\n",
    "# visualization(test_file_path, test_config, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8abf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../Yolov5_StrongSORT_OSNet\n",
    "import sample_frame_tracker\n",
    "# full_img_detection = sample_frame_tracker.run(test_file_path, save_vid=True, detect_only=True)\n",
    "# full_img_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96223b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_detection(test_file_path, full_img_detection):\n",
    "    import cv2\n",
    "    test_frame = cv2.imread(test_file_path)\n",
    "    for obj_idx, detection in full_img_detection.items():\n",
    "        obj_cls, bbox = detection\n",
    "        if obj_cls == 'car':\n",
    "            x,y,w,h = list(map(int,bbox))\n",
    "            cv2.rectangle(test_frame,(x-w//2,y-h//2),(x+w//2,y+h//2),(0,255,0),2)\n",
    "            cv2.putText(test_frame, '_'.join([obj_cls, str(obj_idx)]), (x+w//2+5,y+h//2+5),0,0.3,(0,255,0))\n",
    "    cv2.imshow('detection', test_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_estimation.utils import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ego car trajectory\n",
    "def prepare_ego(test_video):\n",
    "    ego_trajectory = get_ego_trajectory(test_video)\n",
    "    video_trajectory = fetch_camera_trajectory(test_video, database)\n",
    "    sorted_ego_configs = [fetch_camera_config(e['fileName'], database) for e in video_trajectory]\n",
    "    return sorted_ego_configs, ego_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ego_speed = get_ego_speed(ego_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [time_to_nearest_frame(test_video, point.timestamp) for point in ego_trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6659ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# test_timestamp = datetime.datetime(2018, 8, 27, 8, 51, 32, 162404, tzinfo=datetime.timezone.utc)\n",
    "# timestamp_to_nearest_trajectory(ego_trajectory, test_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ed7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_point = [1772, 865, 0.0]\n",
    "# point_to_nearest_trajectory(test_point, ego_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_estimation.sample_plan_algorithms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73351a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/yongming/workspace/research/apperception_new_local/boston-seaport'\n",
    "test_img_base_dir = '/home/yongming/workspace/research/apperception/v1.0-mini/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(os.path.join(base_dir, f'frames.pickle'), \"rb\") as f:\n",
    "#     df_sample_data = pickle.loads(f.read())\n",
    "# df_sample_data\n",
    "# i = 0\n",
    "# for frame in df_sample_data['scene-0655-CAM_FRONT']['frames']:\n",
    "#     if frame[2] == 1194:\n",
    "#         print(i)\n",
    "#         break\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848684da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_estimation.detection_estimation import *\n",
    "# ### Integration\n",
    "# target_config_idx = 218\n",
    "# video = 'scene-0655-CAM_FRONT'\n",
    "# configs = df_sample_data[video]\n",
    "# sorted_ego_config = [dict(zip(configs['columns'], frame))\n",
    "#                      for frame in configs['frames']]\n",
    "# len(sorted_ego_config)\n",
    "# # all_car_loc3d = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_ego_config = sorted_ego_config[target_config_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_loc3d_ground_truth = [(1991, 874), (1949.181, 873.164)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "def generate_sample_plan_once(video, ego_config, mapping, next_frame_num, car_loc3d=None, target_car_detection=None, all_detection_info=None):\n",
    "    if all_detection_info is None:\n",
    "        assert target_car_detection and car_loc3d\n",
    "        x,y,w,h = list(map(int, target_car_detection))\n",
    "        car_loc2d = (x, y+h//2)\n",
    "        car_bbox2d = (x-w//2,y-h//2,x+w//2,y+h//2)\n",
    "        car_bbox3d = None\n",
    "        all_detections = []\n",
    "        all_detections.append(obj_detection('car_1', car_loc3d, car_loc2d, car_bbox3d, car_bbox2d))\n",
    "        all_detection_info = construct_all_detection_info(\n",
    "            current_frame, cam_segment_mapping, ego_trajectory, ego_config, all_detections)\n",
    "    if all_detection_info:\n",
    "        print(all_detection_info[0].road_type)\n",
    "    next_sample_plan = generate_sample_plan(video, next_frame_num, all_detection_info,  50)\n",
    "    next_frame = None\n",
    "    if next_sample_plan.get_next_sample_frame_info():\n",
    "        next_sample_frame_name, next_sample_frame_num, next_sample_frame_time = (\n",
    "            next_sample_plan.get_next_sample_frame_info())\n",
    "        print(\"next frame name\", next_sample_frame_name)\n",
    "        print(\"next frame num\", next_sample_frame_num)\n",
    "    #     print(next_sample_plan.action)\n",
    "        next_frame = cv2.imread(test_img_base_dir+next_sample_frame_name)\n",
    "#         cv2.imshow(\"next_frame\", next_frame)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "    return next_sample_plan, next_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ad4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_estimated_all_detection_info(current_frame, cam_segment_mapping, ego_config, ego_trajectory):\n",
    "    all_detections = []\n",
    "    full_img_detection = sample_frame_tracker.run(current_frame, save_vid=True, detect_only=True)\n",
    "#     display_detection(current_frame, full_img_detection)\n",
    "    for obj_idx, detection in full_img_detection.items():\n",
    "        obj_cls, bbox = detection\n",
    "        x,y,w,h = list(map(int,bbox))\n",
    "        car_loc2d = (x,y+h//2)\n",
    "#         print(car_loc2d)\n",
    "        car_bbox2d = (x-w//2,y-h//2,x+w//2,y+h//2)\n",
    "        car_bbox3d = None\n",
    "        estimate_3d = detection_to_img_segment(car_loc2d, cam_segment_mapping)\n",
    "        if estimate_3d and estimate_3d.road_segment_info.segment_type in ['lane', 'laneSection']:\n",
    "            car_loc3d = tuple(Polygon(estimate_3d.road_segment_info.segment_polygon).centroid.coords)\n",
    "#             print(tuple(car_loc3d))\n",
    "            all_detections.append(obj_detection('car_1', car_loc3d, car_loc2d, car_bbox3d, car_bbox2d))\n",
    "    print(\"all_detections\", all_detections)\n",
    "    all_detection_info = construct_all_detection_info(\n",
    "        current_frame, cam_segment_mapping, ego_trajectory, ego_config, all_detections)\n",
    "    return all_detection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dry_run(sorted_ego_configs, start_frame_num, ego_trajectory, video):\n",
    "    skipped_frame_num = []\n",
    "    next_frame_num = start_frame_num\n",
    "    action_type_counts = {}\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    display_video = cv2.VideoWriter(f'sampled_frames_{video.replace(\"/\", \"_\")}.avi',fourcc, 10, (1600, 900))\n",
    "    start_time = time.time()\n",
    "    total_detection_time = 0\n",
    "    total_sample_plan_time = 0\n",
    "    for i in range(len(sorted_ego_configs)-1):\n",
    "        current_ego_config = sorted_ego_configs[i]\n",
    "        if current_ego_config['frameNum'] != next_frame_num:\n",
    "            skipped_frame_num.append(current_ego_config['frameNum'])\n",
    "            continue\n",
    "        next_frame_num = sorted_ego_configs[i+1]['frameNum']\n",
    "        cam_segment_mapping = map_imgsegment_roadsegment(current_ego_config)\n",
    "        print(\"mapping length\", len(cam_segment_mapping))\n",
    "        current_frame = test_img_base_dir + current_ego_config['fileName']\n",
    "        display_video.write(cv2.imread(current_frame))\n",
    "        start_detection_time = time.time()\n",
    "        all_detection_info = construct_estimated_all_detection_info(\n",
    "            current_frame, cam_segment_mapping, current_ego_config, ego_trajectory)\n",
    "        total_detection_time += time.time()-start_detection_time\n",
    "        start_generate_sample_plan = time.time()\n",
    "        next_sample_plan, next_frame = generate_sample_plan_once(\n",
    "            video, current_ego_config, cam_segment_mapping, next_frame_num, all_detection_info=all_detection_info)\n",
    "        total_sample_plan_time += time.time() - start_generate_sample_plan\n",
    "        next_action_type = next_sample_plan.get_action_type()\n",
    "        if next_action_type not in action_type_counts:\n",
    "            action_type_counts[next_action_type] = 1\n",
    "        else:\n",
    "            action_type_counts[next_action_type] += 1\n",
    "        next_frame_num = next_sample_plan.get_next_frame_num(next_frame_num)\n",
    "    display_video.release()\n",
    "    print(\"sorted_ego_config_length\", len(sorted_ego_configs))\n",
    "    print(\"number of skipped\", len(skipped_frame_num))\n",
    "    print(skipped_frame_num)\n",
    "    print(action_type_counts)\n",
    "    total_run_time = time.time()-start_time\n",
    "    num_runs = len(sorted_ego_configs) - len(skipped_frame_num)\n",
    "    print(\"total_run_time\", total_run_time)\n",
    "    print(\"avg run time\", total_run_time/num_runs)\n",
    "    print(\"total_detection_time\", total_detection_time)\n",
    "    print(\"avg detection time\", total_detection_time/num_runs)\n",
    "    print(\"total_generate_sample_plan_time\", total_sample_plan_time)\n",
    "    print(\"avg generate_sample_plan time\", total_sample_plan_time/num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video1 = 'CAM_FRONT/n008-2018-08-27'\n",
    "sorted_ego_configs1, ego_trajectory1 = prepare_ego(test_video1)\n",
    "dry_run(sorted_ego_configs1, 2, ego_trajectory1, test_video1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c133465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video2 = 'CAM_FRONT/n008-2018-08-01'\n",
    "sorted_ego_configs2, ego_trajectory2 = prepare_ego(test_video2)\n",
    "dry_run(sorted_ego_configs2, 2, ego_trajectory2, test_video2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ef874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (apperception)",
   "language": "python",
   "name": "apperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef986073a7322f2daa7cef2e5604e6018e5522cc159657af8e7aa863491a7631"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
