{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f63a0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T20:57:26.124175Z",
     "iopub.status.busy": "2022-12-07T20:57:26.123441Z",
     "iopub.status.idle": "2022-12-07T20:57:31.010468Z",
     "shell.execute_reply": "2022-12-07T20:57:31.009584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/code/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0676a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/.installs/mambaforge/envs/apperception/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /data/chanwutk/code/apperception/weights/ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-22 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_3d.from_2d_and_road import From2DAndRoad as FromD2DAndRoad\n",
    "from optimized_ingestion.stages.filter_car_facing_sideway import FilterCarFacingSideway\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT\n",
    "from optimized_ingestion.stages.tracking_2d.tracking_2d import Tracking2D, Tracking2DResult\n",
    "from optimized_ingestion.stages.tracking_3d.from_2d_and_road import From2DAndRoad as FromT2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult\n",
    "from optimized_ingestion.stages.segment_trajectory import SegmentTrajectory\n",
    "from optimized_ingestion.stages.segment_trajectory.from_tracking_3d import FromTracking3D\n",
    "\n",
    "from optimized_ingestion.video import Video\n",
    "from optimized_ingestion.video_skipped import VideoSkipped\n",
    "from optimized_ingestion.video_compressed import VideoCompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59907886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T20:57:31.015935Z",
     "iopub.status.busy": "2022-12-07T20:57:31.015521Z",
     "iopub.status.idle": "2022-12-07T20:57:31.019398Z",
     "shell.execute_reply": "2022-12-07T20:57:31.018612Z"
    }
   },
   "outputs": [],
   "source": [
    "# from optimized_ingestion.cache import disable_cache\n",
    "# disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229308b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T20:57:31.022886Z",
     "iopub.status.busy": "2022-12-07T20:57:31.022266Z",
     "iopub.status.idle": "2022-12-07T20:57:31.039286Z",
     "shell.execute_reply": "2022-12-07T20:57:31.038315Z"
    }
   },
   "outputs": [],
   "source": [
    "BOSTON_VIDEOS = [\n",
    "#     \"scene-0757-CAM_FRONT\",\n",
    "    # \"scene-0103-CAM_FRONT\",\n",
    "    # \"scene-0553-CAM_FRONT\",\n",
    "    # \"scene-0665-CAM_FRONT\",\n",
    "#     \"scene-0655-CAM_FRONT_RIGHT\",\n",
    "    \"scene-0655-CAM_BACK_RIGHT\",\n",
    "]\n",
    "\n",
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ed7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440a39c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T20:57:31.043573Z",
     "iopub.status.busy": "2022-12-07T20:57:31.042785Z",
     "iopub.status.idle": "2022-12-07T20:57:31.060228Z",
     "shell.execute_reply": "2022-12-07T20:57:31.059269Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataclassJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, Tracking3DResult):\n",
    "            return {\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"object_id\": o.object_id,\n",
    "                \"point_from_camera\": o.point_from_camera,\n",
    "                \"point\": o.point.tolist(),\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "            }\n",
    "        if isinstance(o, Tracking2DResult):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"object_id\": o.object_id,\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"confidence\": o.confidence\n",
    "            }\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.tolist()\n",
    "        if isinstance(o, np.ndarray):\n",
    "            return o.tolist()\n",
    "        return super().default(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355b8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/data/apperception-data/processed/nuscenes/full-dataset-v1.0/Mini\n"
     ]
    }
   ],
   "source": [
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c1dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "with open(os.path.join(DATA_DIR, \"videos/boston-seaport\", \"frames-compressed.pickle\"), \"rb\") as f:\n",
    "    videos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "275836d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename):\n",
    "    metadata_strongsort = {}\n",
    "    metadata_3d = {}\n",
    "    failed_videos = []\n",
    "    for name, video in videos.items():\n",
    "#         try:\n",
    "        print(name, '--------------------------------------------------------------------------------')\n",
    "        frames = VideoCompressed(\n",
    "            os.path.join(DATA_DIR, \"videos/boston-seaport\", video[\"filename\"]),\n",
    "            [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "        )\n",
    "\n",
    "        output = pipeline.run(Payload(frames))\n",
    "        metadata_strongsort[name] = StrongSORT.get(output)\n",
    "        metadata_3d[name] = FromT2DAndRoad.get(output)\n",
    "#         except:\n",
    "#             failed_videos.append(name)\n",
    "#             print('error')\n",
    "#         break\n",
    "\n",
    "    with open(f\"./outputs/{filename}.json\", \"w\") as f:\n",
    "        json.dump(metadata_strongsort, f, cls=DataclassJSONEncoder, indent=2)\n",
    "        \n",
    "    with open(f\"./outputs/{filename}-3d.json\", \"w\") as f:\n",
    "        json.dump(metadata_3d, f, cls=DataclassJSONEncoder, indent=2)\n",
    "    \n",
    "    with open(f\"./outputs/{filename}-failed-videos.json\", \"w\") as f:\n",
    "        json.dump(failed_videos, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1b46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_filter = ['motorcycle', 'car', 'truck', 'bus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c883701",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /data/chanwutk/code/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-22 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0103-CAM_FRONT_LEFT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "231\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "231\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.ObjectTypeFilter\n",
      "None\n",
      "231\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:00, 3643.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "231\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:11<00:00, 20.26it/s]\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n",
      "231\n",
      "  filtered frames: 6.4935064935064934%\n",
      "...........................................K...K.......KKKKKK.......................................\n",
      "................................K.............K............K......K......K..............K......K....\n",
      "...............................\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/chanwutk/code/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:01<00:00, 206.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "231\n",
      "  filtered frames: 6.4935064935064934%\n",
      "...........................................K...K.......KKKKKK.......................................\n",
      "................................K.............K............K......K......K..............K......K....\n",
      "...............................\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<00:00, 203504.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "231\n",
      "  filtered frames: 6.4935064935064934%\n",
      "...........................................K...K.......KKKKKK.......................................\n",
      "................................K.............K............K......K......K..............K......K....\n",
      "...............................\n",
      "Stage:  SegmentTrajectory\n",
      "obj_trajectories 2\n",
      "3 4\n",
      "4 3\n",
      "None\n",
      "231\n",
      "  filtered frames: 6.4935064935064934%\n",
      "...........................................K...K.......KKKKKK.......................................\n",
      "................................K.............K............K......K......K..............K......K....\n",
      "...............................\n",
      "scene-0103-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "229\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "229\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.ObjectTypeFilter\n",
      "None\n",
      "229\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "229it [00:00, 2379.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "229\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:16<00:00, 14.22it/s]\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "229\n",
      "  filtered frames: 37.55458515283843%\n",
      "KKKKKKKKKK.K..KKKKKKKKKKKKKKKKKKKKKKKKK.......K.......KKKKKKKKKKKKKKKKKKKKKK..............K.........\n",
      ".....KKKKKKKKK............KKKKKK.............K..........K.......K...........K..........K............\n",
      "......KKK......KKK...........\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/chanwutk/code/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [00:22<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "229\n",
      "  filtered frames: 37.55458515283843%\n",
      "KKKKKKKKKK.K..KKKKKKKKKKKKKKKKKKKKKKKKK.......K.......KKKKKKKKKKKKKKKKKKKKKK..............K.........\n",
      ".....KKKKKKKKK............KKKKKK.............K..........K.......K...........K..........K............\n",
      "......KKK......KKK...........\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [00:00<00:00, 10238.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "229\n",
      "  filtered frames: 37.55458515283843%\n",
      "KKKKKKKKKK.K..KKKKKKKKKKKKKKKKKKKKKKKKK.......K.......KKKKKKKKKKKKKKKKKKKKKK..............K.........\n",
      ".....KKKKKKKKK............KKKKKK.............K..........K.......K...........K..........K............\n",
      "......KKK......KKK...........\n",
      "Stage:  SegmentTrajectory\n",
      "obj_trajectories 64\n",
      "1 38\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m pipeline\u001b[38;5;241m.\u001b[39madd_filter(\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mFromT2DAndRoad())\n\u001b[1;32m     12\u001b[0m pipeline\u001b[38;5;241m.\u001b[39madd_filter(\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mSegmentTrajectory())\n\u001b[0;32m---> 14\u001b[0m \u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtracking-with-de\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 13\u001b[0m, in \u001b[0;36mrun_benchmark\u001b[0;34m(pipeline, filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m frames \u001b[38;5;241m=\u001b[39m VideoCompressed(\n\u001b[1;32m      9\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideos/boston-seaport\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     10\u001b[0m     [camera_config(\u001b[38;5;241m*\u001b[39mf, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPayload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m metadata_strongsort[name] \u001b[38;5;241m=\u001b[39m StrongSORT\u001b[38;5;241m.\u001b[39mget(output)\n\u001b[1;32m     15\u001b[0m metadata_3d[name] \u001b[38;5;241m=\u001b[39m FromT2DAndRoad\u001b[38;5;241m.\u001b[39mget(output)\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m---> 22\u001b[0m         payload \u001b[38;5;241m=\u001b[39m \u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/payload.py:45\u001b[0m, in \u001b[0;36mPayload.filter\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mfilter\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mclassname())\n\u001b[0;32m---> 45\u001b[0m     keep, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(keep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keep))\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metadata \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mget(metadata)))\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/stages/stage.py:25\u001b[0m, in \u001b[0;36mStage.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple[bitarray | None, Dict[str, List[T]] | None]\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m     s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     e \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntimes\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mvideofile,\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m: e \u001b[38;5;241m-\u001b[39m s\n\u001b[1;32m     31\u001b[0m     })\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/stages/segment_trajectory/__init__.py:31\u001b[0m, in \u001b[0;36mSegmentTrajectory._run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     28\u001b[0m detection_infos \u001b[38;5;241m=\u001b[39m [tt[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tt \u001b[38;5;129;01min\u001b[39;00m t]\n\u001b[1;32m     29\u001b[0m frame_indices \u001b[38;5;241m=\u001b[39m [tt[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tt \u001b[38;5;129;01min\u001b[39;00m t]\n\u001b[0;32m---> 31\u001b[0m calibrated_trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectory_3d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetection_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m calibrated_trajectory:\n\u001b[1;32m     33\u001b[0m     t\u001b[38;5;241m.\u001b[39mobj_id \u001b[38;5;241m=\u001b[39m oid\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/stages/segment_trajectory/construct_segment_trajectory.py:373\u001b[0m, in \u001b[0;36mcalibrate\u001b[0;34m(trajectory_3d, detection_infos, frame_indices, payload)\u001b[0m\n\u001b[1;32m    362\u001b[0m     new_segment_line, new_heading \u001b[38;5;241m=\u001b[39m get_segment_line(current_road_segment_info, current_point3d)\n\u001b[1;32m    363\u001b[0m     road_segment_trajectory\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    364\u001b[0m         SegmentPoint(\n\u001b[1;32m    365\u001b[0m             detection_info\u001b[38;5;241m.\u001b[39mdetection_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m             frame_idx,\n\u001b[1;32m    372\u001b[0m         ))\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplete_segment_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroad_segment_trajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/stages/segment_trajectory/construct_segment_trajectory.py:280\u001b[0m, in \u001b[0;36mcomplete_segment_trajectory\u001b[0;34m(road_segment_trajectory, payload)\u001b[0m\n\u001b[1;32m    277\u001b[0m completed_segment_trajectory: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist[SegmentPoint]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m [road_segment_trajectory[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_segment, next_segment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(road_segment_trajectory[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], road_segment_trajectory[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[0;32m--> 280\u001b[0m     completed_segment_trajectory\u001b[38;5;241m.\u001b[39mextend(\u001b[43mbinary_search_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    281\u001b[0m     completed_segment_trajectory\u001b[38;5;241m.\u001b[39mappend(next_segment)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completed_segment_trajectory\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/stages/segment_trajectory/construct_segment_trajectory.py:267\u001b[0m, in \u001b[0;36mbinary_search_segment\u001b[0;34m(current_segment, next_segment, payload)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(interpolate_segment, configs_with_index[st:ed])]\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# elif current_segment_polygon.intersects(next_segment_polygon):\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m#     # both polygons are the same one of next to each other\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#     # TODO: remove because we still need to fill in approximate locations\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m#     # of frames in between\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m#     return []\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     middle_segment \u001b[38;5;241m=\u001b[39m \u001b[43mfind_middle_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# import code; code.interact(local=vars())\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     before \u001b[38;5;241m=\u001b[39m binary_search_segment(current_segment, middle_segment, payload)\n",
      "File \u001b[0;32m/data/chanwutk/code/apperception/optimized_ingestion/stages/segment_trajectory/construct_segment_trajectory.py:158\u001b[0m, in \u001b[0;36mfind_middle_segment\u001b[0;34m(current_segment, next_segment, payload)\u001b[0m\n\u001b[1;32m    155\u001b[0m current_segment_polygon \u001b[38;5;241m=\u001b[39m current_segment\u001b[38;5;241m.\u001b[39mroad_segment_info\u001b[38;5;241m.\u001b[39mpolygon\n\u001b[1;32m    156\u001b[0m next_segment_polygon \u001b[38;5;241m=\u001b[39m next_segment\u001b[38;5;241m.\u001b[39mroad_segment_info\u001b[38;5;241m.\u001b[39mpolygon\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m current_segment_polygon\u001b[38;5;241m.\u001b[39mintersects(next_segment_polygon)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# current_center_point = current_segment.road_segment_info.segment_polygon.centroid\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# next_center_point = next_segment.road_segment_info.segment_polygon.centroid\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# connected_center = LineString([current_center_point, next_center_point])\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# current_intersection = connected_center.intersection(current_segment_polygon).coords[0]\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# next_intersection = connected_center.intersection(next_segment_polygon).coords[0]\u001b[39;00m\n\u001b[1;32m    165\u001b[0m p1, p2 \u001b[38;5;241m=\u001b[39m nearest_points(current_segment_polygon, next_segment_polygon)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_filter(ParallelDecodeFrame())\n",
    "# pipeline.add_filter(DecodeFrame())\n",
    "pipeline.add_filter(filter=YoloDetection())\n",
    "pipeline.add_filter(filter=ObjectTypeFilter(type_filter))\n",
    "\n",
    "pipeline.add_filter(filter=FromD2DAndRoad())\n",
    "pipeline.add_filter(filter=DetectionEstimation())\n",
    "pipeline.add_filter(filter=StrongSORT())\n",
    "pipeline.add_filter(filter=FromT2DAndRoad())\n",
    "\n",
    "pipeline.add_filter(filter=SegmentTrajectory())\n",
    "\n",
    "run_benchmark(pipeline, 'tracking-with-de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6df4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1652f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T21:12:20.349340Z",
     "iopub.status.busy": "2022-12-07T21:12:20.348942Z",
     "iopub.status.idle": "2022-12-07T21:39:03.457596Z",
     "shell.execute_reply": "2022-12-07T21:39:03.456343Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_filter(ParallelDecodeFrame())\n",
    "# pipeline.add_filter(DecodeFrame())\n",
    "pipeline.add_filter(filter=YoloDetection())\n",
    "pipeline.add_filter(filter=ObjectTypeFilter(type_filter))\n",
    "\n",
    "pipeline.add_filter(filter=FromD2DAndRoad())\n",
    "pipeline.add_filter(filter=StrongSORT())\n",
    "pipeline.add_filter(filter=FromT2DAndRoad())\n",
    "\n",
    "pipeline.add_filter(filter=FromTracking3D())\n",
    "\n",
    "run_benchmark(pipeline, 'tracking-without-de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e66e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e53b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
