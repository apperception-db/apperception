{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9badc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T00:15:43.617706Z",
     "iopub.status.busy": "2022-12-08T00:15:43.616466Z",
     "iopub.status.idle": "2022-12-08T00:15:48.654505Z",
     "shell.execute_reply": "2022-12-08T00:15:48.653531Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152abe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects\n",
    "from optimized_ingestion.utils.preprocess import preprocess\n",
    "database.connection\n",
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066065fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/data/processed/full-dataset/trainval\"\n",
    "NUSCENES_RAW_DATA = \"NUSCENES_RAW_DATA\"\n",
    "if NUSCENES_RAW_DATA in os.environ:\n",
    "    RAW_DATA_DIR = os.environ[NUSCENES_RAW_DATA]\n",
    "else:\n",
    "    RAW_DATA_DIR = \"/data/full-dataset/trainval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847750d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/evaluation/video-samples/boston-seaport.txt', 'r') as f:\n",
    "    scenes = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bechmark_detection_estimation_gain(world,video_names=[], scenes=[], path_suffix=None):\n",
    "    base_benchmark_path = f'./outputs/base_pipeline_benchmark{\"_\"+path_suffix if path_suffix else \"\"}.json'\n",
    "    ### base pipeline\n",
    "    preprocess(world, DATA_DIR, video_names, scenes,\n",
    "               benchmark_path=base_benchmark_path)\n",
    "    ### detection estimation benchmark\n",
    "    for skip_ratio in [0.1 * i for i in range(1,10)]:\n",
    "        print(f\"current skip ratio{skip_ratio}\")\n",
    "        optimize_benchmark_path = f'./outputs/detection_estimation_pipeline_{int(skip_ratio*10)}{\"_\"+path_suffix if path_suffix else \"\"}.json'\n",
    "        preprocess(world, DATA_DIR, video_names,\n",
    "                   base=False,\n",
    "                   benchmark_path=optimize_benchmark_path,\n",
    "                   skip_ratio=skip_ratio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ScenicWorld' # world name\n",
    "world = empty_world(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72817974",
   "metadata": {},
   "outputs": [],
   "source": [
    "bechmark_detection_estimation_gain(world, scenes=scenes[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98facc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = objects[0]\n",
    "cam = camera\n",
    "car_world = empty_world(name=name).filter(\n",
    "    (F.like(obj1.type, 'car') | F.like(obj1.type, 'truck') | F.like(obj1.type, 'bus'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "bechmark_detection_estimation_gain(car_world, scenes=scenes[:200], path_suffix=\"only_car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbf69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./outputs/base_pipeline_benchmark.json') as benchmark_file:\n",
    "    benchmark_content = benchmark_file.read()\n",
    "\n",
    "parsed_json = json.loads(benchmark_content)\n",
    "baseline_total_runtime = parsed_json[0]['total_runtime']\n",
    "baseline_avg_runtime = parsed_json[1]['average runtime']\n",
    "baseline_stage_runtimes = parsed_json[0]['stage_runtimes']\n",
    "for stage_runtime in baseline_stage_runtimes:\n",
    "    if stage_runtime['stage'] == 'Tracking2D.StrongSORT':\n",
    "        baseline_strong_sort_runtime = sum([r['runtime'] for r in stage_runtime['runtimes']])\n",
    "\n",
    "# num_videos = parsed_json[2]['number of videos']\n",
    "print(baseline_total_runtime)\n",
    "print(baseline_avg_runtime)\n",
    "print(baseline_strong_sort_runetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f94e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_ratios = [i for i in range(1, 10)]\n",
    "all_obj_total_runtimes = []\n",
    "all_obj_avg_runtimes = []\n",
    "all_obj_strong_sort_runtimes = []\n",
    "only_car_total_runtimes = []\n",
    "only_car_avg_runtimes = []\n",
    "only_car_strong_sort_runtimes = []\n",
    "for i in skip_ratios:\n",
    "    with open(f'./outputs/detection_estimation_pipeline_{i}.json') as benchmark_file:\n",
    "        benchmark_content = benchmark_file.read()\n",
    "\n",
    "    parsed_json = json.loads(benchmark_content)\n",
    "    all_obj_total_runtimes.append(parsed_json[0]['total_runtime'])\n",
    "    all_obj_avg_runtimes.append(parsed_json[1]['average runtime'])\n",
    "    all_obj_stage_runtimes = parsed_json[0]['staged_runtimes']\n",
    "    for stage_runtime in all_obj_stage_runtimes:\n",
    "        if stage_runtime['stage'] == 'Tracking2D.StrongSORT':\n",
    "            all_obj_strong_sort_runtimes.append(sum([r['runtime'] for r in stage_runtime['runtimes']]))\n",
    "\n",
    "    with open(f'./outputs/detection_estimation_pipeline_{i}_only_car.json') as benchmark_file:\n",
    "        benchmark_content = benchmark_file.read()\n",
    "\n",
    "    parsed_json = json.loads(benchmark_content)\n",
    "    only_car_total_runtimes.append(parsed_json[0]['total_runtime'])\n",
    "    only_car_avg_runtimes.append(parsed_json[1]['average runtime'])\n",
    "    only_car_stage_runetimes = parsed_json[0]['staged_runtimes']\n",
    "    for stage_runtime in only_car_stage_runetimes:\n",
    "        if stage_runtime['stage'] == 'Tracking2D.StrongSORT':\n",
    "            only_car_strong_sort_runtimes.append(sum([r['runtime'] for r in stage_runtime['runtimes']]))\n",
    "\n",
    "print(all_obj_total_runtimes)\n",
    "print(all_obj_avg_runtimes)\n",
    "print(only_car_total_runtimes)\n",
    "print(only_car_avg_runtimes)\n",
    "print(all_obj_strong_sort_runtimes)\n",
    "print(only_car_strong_sort_runtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(f'number of videos {num_videos}')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(skip_ratios, len(skip_ratios)*[baseline_total_runtime], label='baseline')\n",
    "ax.plot(skip_ratios, all_obj_total_runtimes, label='all obj')\n",
    "ax.plot(skip_ratios, only_car_total_runtimes, label='only car')\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "plt.ylabel('total run time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(f'number of videos {num_videos}')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(skip_ratios, len(skip_ratios)*[baseline_total_runtime/baseline_total_runtime], label='baseline')\n",
    "ax.plot(skip_ratios, [e/baseline_total_runtime for e in all_obj_total_runtimes], label='all obj')\n",
    "ax.plot(skip_ratios, [e/baseline_total_runtime for e in only_car_total_runtimes], label='only car')\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "plt.ylabel('total run time/baseline total run time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc43bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(f'number of videos {num_videos}')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(skip_ratios, len(skip_ratios)*[baseline_avg_runtime], label='baseline')\n",
    "ax.plot(skip_ratios, all_obj_avg_runtimes, label='all obj')\n",
    "ax.plot(skip_ratios, only_car_avg_runtimes, label='only car')\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "plt.ylabel('avg run time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8cb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(f'number of videos {num_videos}')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(skip_ratios, len(skip_ratios)*[baseline_strong_sort_runetime], label='baseline')\n",
    "ax.plot(skip_ratios, all_obj_strong_sort_runetime, label='all obj')\n",
    "ax.plot(skip_ratios, only_car_strong_sort_runetime, label='only car')\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "plt.ylabel('strongsort run time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
