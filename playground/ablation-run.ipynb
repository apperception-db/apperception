{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569e4726-2856-4e5f-a220-e3bef1c110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "import shutil\n",
    "import socket\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "process = subprocess.Popen('docker container start mobilitydb', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcaf7b9-8b3f-4f2f-ad00-08b197795820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dev\n"
     ]
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "test = hostname.split(\"-\")[-1]\n",
    "print(\"test\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chanwutk/Documents/apperception\n",
      "mobilitydb\n"
     ]
    }
   ],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        else:\n",
    "            # Other type (?)\n",
    "            return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_notebook():\n",
    "    %cd ..\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb4d993-d0a4-49d5-8b4d-1b3a62f66da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.video import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863b7bd6-7bc4-4658-bb06-043ba955aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stages\n",
    "from optimized_ingestion.stages.in_view import InView\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "\n",
    "from optimized_ingestion.stages.detection_2d.detection_2d import Detection2D\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_2d.ground_truth import GroundTruthDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee9880e-27d0-47f3-a3dd-36b70d199d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_road import FromDetection2DAndRoad\n",
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_depth import FromDetection2DAndDepth\n",
    "\n",
    "from optimized_ingestion.stages.depth_estimation import DepthEstimation\n",
    "\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.detection_estimation.segment_mapping import RoadPolygonInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4bddca-a1ae-4806-be85-8cf397d01ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94373d1d-10de-4183-b688-b6ddbeb09d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_2d.tracking_2d import Tracking2D, Tracking2DResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6737b34b-d928-45aa-940e-b23a7a6e5eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_road import FromTracking2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_depth import FromTracking2DAndDepth\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "\n",
    "from optimized_ingestion.stages.segment_trajectory import SegmentTrajectory\n",
    "from optimized_ingestion.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "from optimized_ingestion.stages.segment_trajectory.from_tracking_3d import FromTracking3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59907886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229308b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440a39c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataclassJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, Tracking3DResult):\n",
    "            return {\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"object_id\": o.object_id,\n",
    "                \"point_from_camera\": o.point_from_camera,\n",
    "                \"point\": o.point.tolist(),\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "            }\n",
    "        if isinstance(o, Tracking2DResult):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"object_id\": o.object_id,\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"confidence\": o.confidence\n",
    "            }\n",
    "        if isinstance(o, SegmentPoint):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"car_loc3d\": o.car_loc3d,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "                \"segment_line\": None if o.segment_line is None else o.segment_line.to_ewkb(),\n",
    "                # \"segment_line_wkb\": o.segment_line.wkb_hex,\n",
    "                \"segment_heading\": o.segment_heading,\n",
    "                \"road_polygon_info\": o.road_polygon_info,\n",
    "                \"obj_id\": o.obj_id,\n",
    "                \"type\": o.type,\n",
    "                \"next\": None if o.next is None else tuple(o.next.detection_id),\n",
    "                \"prev\": None if o.prev is None else tuple(o.prev.detection_id),\n",
    "            }\n",
    "        if isinstance(o, RoadPolygonInfo):\n",
    "            return {\n",
    "                \"id\": o.id,\n",
    "                \"polygon\": str(o.polygon),\n",
    "                # \"polygon_wkb\": o.polygon.wkb_hex,\n",
    "                \"segment_lines\": [str(l) for l in o.segment_lines],\n",
    "                \"road_type\": o.road_type,\n",
    "                \"segment_headings\": o.segment_headings,\n",
    "                \"contains_ego\": o.contains_ego,\n",
    "                \"ego_config\": o.ego_config,\n",
    "                \"fov_lines\": o.fov_lines\n",
    "            }\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.tolist()\n",
    "        if isinstance(o, np.ndarray):\n",
    "            return o.tolist()\n",
    "        return super().default(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "355b8977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/chanwutk/data/processed/full-dataset/trainval\n"
     ]
    }
   ],
   "source": [
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c1dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "    videos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'cities.pkl'), 'rb') as f:\n",
    "    cities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcb3599c-3807-4044-9636-45b2d94fe7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCHMARK_DIR = \"./outputs/ablation-performance\"\n",
    "\n",
    "\n",
    "def bm_dir(*args: \"str\"):\n",
    "    return os.path.join(BENCHMARK_DIR, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "275836d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename, run=0, ignore_error=False):\n",
    "    metadata_strongsort = {}\n",
    "    metadata_3d = {}\n",
    "    metadata_segment = {}\n",
    "    metadata_d2d = {}\n",
    "    failed_videos = []\n",
    "\n",
    "    all_metadata = {\n",
    "        'sort': metadata_strongsort,\n",
    "        'segment-trajectory': metadata_segment,\n",
    "        'detection-2d': metadata_d2d,\n",
    "    }\n",
    "\n",
    "    names = cities['boston-seaport']\n",
    "    filtered_videos = [(n, v) for n, v in videos.items() if n[6:10] in names]\n",
    "\n",
    "    for pre in all_metadata.keys():\n",
    "        p = os.path.join(BENCHMARK_DIR, f\"{pre}--{filename}_{run}\")\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p)\n",
    "        os.makedirs(p)\n",
    "\n",
    "    for i, (name, video) in tqdm(enumerate(filtered_videos), total=len(filtered_videos)):\n",
    "        try:\n",
    "            video_filename = video['filename']\n",
    "            if not video_filename.startswith('boston') or 'FRONT' not in name:\n",
    "                continue\n",
    "\n",
    "            frames = Video(\n",
    "                os.path.join(DATA_DIR, \"videos\", video[\"filename\"]),\n",
    "                [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "            )\n",
    "\n",
    "            output = pipeline.run(Payload(frames))\n",
    "\n",
    "            metadata_strongsort[name] = output[StrongSORT]\n",
    "            metadata_3d[name] = output[Tracking3D]\n",
    "            metadata_segment[name] = output[SegmentTrajectory]\n",
    "            metadata_d2d[name] = [\n",
    "                (d2ds, dids)\n",
    "                for d2ds, clss, dids\n",
    "                in output[Detection2D]\n",
    "            ]\n",
    "\n",
    "            for pre, metadata in all_metadata.items():\n",
    "                p = bm_dir(f\"{pre}--{filename}_{run}\", f\"{name}.json\")\n",
    "                with open(p, \"w\") as f:\n",
    "                    json.dump(metadata[name], f, cls=DataclassJSONEncoder, indent=1)\n",
    "        except Exception as e:\n",
    "            if ignore_error:\n",
    "                message = str(traceback.format_exc())\n",
    "                failed_videos.append((name, message))\n",
    "                print(video_filename)\n",
    "                print(e)\n",
    "                print(message)\n",
    "                print(\"------------------------------------------------------------------------------------\")\n",
    "                print()\n",
    "                print()\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with open(bm_dir(f\"failed_videos--{filename}_{run}.json\"), \"w\") as f:\n",
    "                json.dump(failed_videos, f, indent=1)\n",
    "\n",
    "            with open(bm_dir(f\"perf--{filename}_{run}.json\"), \"w\") as f:\n",
    "                performance = [\n",
    "                    {\n",
    "                        \"stage\": stage.classname(),\n",
    "                        \"benchmark\": stage.benchmark,\n",
    "                        **(\n",
    "                            {'explains': stage.explains}\n",
    "                            if hasattr(stage, 'explains')\n",
    "                            else {}\n",
    "                        )\n",
    "                    }\n",
    "                    for stage\n",
    "                    in pipeline.stages\n",
    "                ]\n",
    "                json.dump(performance, f, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98283938-b68f-4925-a5ef-eee7c6c46c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, 'intersection'))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(DecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "            df_annotations = pickle.load(f)\n",
    "        pipeline.add_filter(GroundTruthDetection(df_annotations))\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        # TODO: filter objects based on predicate\n",
    "        pipeline.add_filter(ObjectTypeFilter(['car']))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromDetection2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(FromDetection2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(StrongSORT(cache=strongsort))\n",
    "\n",
    "    # Tracking 3D\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromTracking2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(FromTracking2DAndDepth())\n",
    "\n",
    "    # Segment Trajectory\n",
    "    pipeline.add_filter(FromTracking3D())\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4adca3d-7963-4dc6-bde1-d0ce107ae959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicate = None\n",
    "\n",
    "p_noOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_inview = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objectFilter = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_de = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_opt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_optDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_gtOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_gtOptDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"noopt\": p_noOpt,\n",
    "    \"inview\": p_inview,\n",
    "    \"objectfilter\": p_objectFilter,\n",
    "    \"geo\": p_geo,\n",
    "    \"de\": p_de,\n",
    "    \"opt\": p_opt,\n",
    "    \"optde\": p_optDe,\n",
    "    \"gtopt\": p_gtOpt,\n",
    "    \"gtoptde\": p_gtOptDe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "653d48ca-7993-4c7a-b583-a864c76da0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cd4952893c4956a1f1330a70a012b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m, in \u001b[0;36mrun_benchmark\u001b[0;34m(pipeline, filename, run, ignore_error)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m frames \u001b[38;5;241m=\u001b[39m Video(\n\u001b[1;32m     30\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     31\u001b[0m     [camera_config(\u001b[38;5;241m*\u001b[39mf, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPayload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m metadata_strongsort[name] \u001b[38;5;241m=\u001b[39m output[StrongSORT]\n\u001b[1;32m     37\u001b[0m metadata_3d[name] \u001b[38;5;241m=\u001b[39m output[Tracking3D]\n",
      "File \u001b[0;32m~/Documents/apperception/optimized_ingestion/pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m---> 22\u001b[0m         payload \u001b[38;5;241m=\u001b[39m \u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[0;32m~/Documents/apperception/optimized_ingestion/payload.py:35\u001b[0m, in \u001b[0;36mPayload.filter\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mfilter\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# print(\"Stage: \", filter.classname())\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     keep, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep\n",
      "File \u001b[0;32m~/Documents/apperception/optimized_ingestion/stages/stage.py:28\u001b[0m, in \u001b[0;36mStage.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     26\u001b[0m keep_before \u001b[38;5;241m=\u001b[39m payload\u001b[38;5;241m.\u001b[39mkeep\n\u001b[1;32m     27\u001b[0m s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m e \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     30\u001b[0m keep_after \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/apperception/optimized_ingestion/cache.py:30\u001b[0m, in \u001b[0;36mcache.<locals>._fn\u001b[0;34m(stage, payload)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(stage: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _CACHE_STATUS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     videofile \u001b[38;5;241m=\u001b[39m payload\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mvideofile\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stage, Stage)\n",
      "File \u001b[0;32m~/Documents/apperception/optimized_ingestion/stages/tracking_2d/strongsort.py:61\u001b[0m, in \u001b[0;36mStrongSORT._run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(strongsort, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtracker\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(strongsort\u001b[38;5;241m.\u001b[39mtracker, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera_update\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m curr_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m         \u001b[43mstrongsort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# frame_benchmark.append(time.time())\u001b[39;00m\n\u001b[1;32m     64\u001b[0m confs \u001b[38;5;241m=\u001b[39m det[:, \u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/apperception/./submodules/yolo_tracker/trackers/strong_sort/sort/tracker.py:71\u001b[0m, in \u001b[0;36mTracker.camera_update\u001b[0;34m(self, previous_img, current_img, cache)\u001b[0m\n\u001b[1;32m     69\u001b[0m     cached_matrix \u001b[38;5;241m=\u001b[39m track\u001b[38;5;241m.\u001b[39mcamera_update(previous_img, current_img, cached_matrix)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/apperception/./submodules/yolo_tracker/trackers/strong_sort/sort/track.py:227\u001b[0m, in \u001b[0;36mTrack.camera_update\u001b[0;34m(self, previous_frame, next_frame, cached_matrix)\u001b[0m\n\u001b[1;32m    224\u001b[0m is_cached, matrix \u001b[38;5;241m=\u001b[39m cached_matrix\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cached:\n\u001b[0;32m--> 227\u001b[0m     warp_matrix, src_aligned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mECC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warp_matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m src_aligned \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/apperception/./submodules/yolo_tracker/trackers/strong_sort/sort/track.py:193\u001b[0m, in \u001b[0;36mTrack.ECC\u001b[0;34m(self, src, dst, warp_mode, eps, max_iter, scale, align)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Run the ECC algorithm. The results are stored in warp_matrix.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     (cc, warp_matrix) \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindTransformECC\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarp_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarp_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecc transform failed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = 'opt'\n",
    "for i in range(3):\n",
    "    run_benchmark(pipelines[test](None), test, run=i, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a04b-e888-417c-967a-0399f1c8c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subprocess.Popen('shutdown -h now', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cb408-b9cc-4bda-a6d4-14f62fbcba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'deopt'\n",
    "for i in range(3):\n",
    "    run_benchmark(pipelines[test](None), test, run=i, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24904082-1760-4219-94f2-8ca7a6f9aff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
