{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569e4726-2856-4e5f-a220-e3bef1c110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "import socket\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "process = subprocess.Popen('docker container start mobilitydb', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcaf7b9-8b3f-4f2f-ad00-08b197795820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dev\n"
     ]
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "test = hostname.split(\"-\")[-1]\n",
    "print(\"test\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chanwutk/code/apperception\n"
     ]
    }
   ],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        else:\n",
    "            # Other type (?)\n",
    "            return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_notebook():\n",
    "    %cd ..\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb4d993-d0a4-49d5-8b4d-1b3a62f66da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilitydb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.video import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863b7bd6-7bc4-4658-bb06-043ba955aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stages\n",
    "from optimized_ingestion.stages.in_view import InView\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_2d.ground_truth import GroundTruthDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee9880e-27d0-47f3-a3dd-36b70d199d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_road import FromDetection2DAndRoad\n",
    "from optimized_ingestion.stages.detection_3d.from_detection_2d_and_depth import FromDetection2DAndDepth\n",
    "\n",
    "from optimized_ingestion.stages.depth_estimation import DepthEstimation\n",
    "\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.detection_estimation.segment_mapping import RoadPolygonInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4bddca-a1ae-4806-be85-8cf397d01ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94373d1d-10de-4183-b688-b6ddbeb09d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_2d.tracking_2d import Tracking2D, Tracking2DResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71f2b1-2585-45fa-b179-bfa73c856b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6737b34b-d928-45aa-940e-b23a7a6e5eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_road import FromTracking2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.from_tracking_2d_and_depth import FromTracking2DAndDepth\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "\n",
    "from optimized_ingestion.stages.segment_trajectory import SegmentTrajectory\n",
    "from optimized_ingestion.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "from optimized_ingestion.stages.segment_trajectory.from_tracking_3d import FromTracking3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59907886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229308b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440a39c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataclassJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, Tracking3DResult):\n",
    "            return {\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"object_id\": o.object_id,\n",
    "                \"point_from_camera\": o.point_from_camera,\n",
    "                \"point\": o.point.tolist(),\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "            }\n",
    "        if isinstance(o, Tracking2DResult):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"object_id\": o.object_id,\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"confidence\": o.confidence\n",
    "            }\n",
    "        if isinstance(o, SegmentPoint):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"car_loc3d\": o.car_loc3d,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "                \"segment_line\": None if o.segment_line is None else o.segment_line.to_ewkb(),\n",
    "                # \"segment_line_wkb\": o.segment_line.wkb_hex,\n",
    "                \"segment_heading\": o.segment_heading,\n",
    "                \"road_polygon_info\": o.road_polygon_info,\n",
    "                \"obj_id\": o.obj_id,\n",
    "                \"type\": o.type,\n",
    "                \"next\": None if o.next is None else tuple(o.next.detection_id),\n",
    "                \"prev\": None if o.prev is None else tuple(o.prev.detection_id),\n",
    "            }\n",
    "        if isinstance(o, RoadPolygonInfo):\n",
    "            return {\n",
    "                \"id\": o.id,\n",
    "                \"polygon\": str(o.polygon),\n",
    "                # \"polygon_wkb\": o.polygon.wkb_hex,\n",
    "                \"segment_lines\": [str(l) for l in o.segment_lines],\n",
    "                \"road_type\": o.road_type,\n",
    "                \"segment_headings\": o.segment_headings,\n",
    "                \"contains_ego\": o.contains_ego,\n",
    "                \"ego_config\": o.ego_config,\n",
    "                \"fov_lines\": o.fov_lines\n",
    "            }\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.tolist()\n",
    "        if isinstance(o, np.ndarray):\n",
    "            return o.tolist()\n",
    "        return super().default(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "355b8977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/chanwutk/data/processed/full-dataset/trainval\n"
     ]
    }
   ],
   "source": [
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c1dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "    videos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'cities.pkl'), 'rb') as f:\n",
    "    cities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275836d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename, ignore_error=False):\n",
    "    metadata_strongsort = {}\n",
    "    metadata_3d = {}\n",
    "    metadata_segment = {}\n",
    "    metadata_frame_id = {}\n",
    "    failed_videos = []\n",
    "\n",
    "    # names = cities['boston-seaport'][:200]\n",
    "    names = cities['boston-seaport']\n",
    "    filtered_videos = [(n, v) for n, v in videos.items() if n[6:10] in names]\n",
    "\n",
    "    for i, (name, video) in tqdm(enumerate(filtered_videos), total=len(filtered_videos)):\n",
    "        try:\n",
    "            video_filename = video['filename']\n",
    "            # print(video_filename)\n",
    "            if not video_filename.startswith('boston') or 'FRONT' not in name:\n",
    "                continue\n",
    "\n",
    "            frames = Video(\n",
    "                os.path.join(DATA_DIR, \"videos\", video[\"filename\"]),\n",
    "                [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "            )\n",
    "\n",
    "            output = pipeline.run(Payload(frames))\n",
    "            metadata_strongsort[name] = output[StrongSORT]\n",
    "            metadata_3d[name] = output[Tracking3D]\n",
    "            metadata_segment[name] = output[SegmentTrajectory]\n",
    "            # metadata_frame_id[name] = output[GetCameraConfigId]\n",
    "        except Exception as e:\n",
    "            if ignore_error:\n",
    "                message = str(traceback.format_exc())\n",
    "                failed_videos.append((name, message))\n",
    "                print(e)\n",
    "                print(message)\n",
    "                print(\"------------------------------------------------------------------------------------\")\n",
    "                print()\n",
    "                print()\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        # Save progress every video\n",
    "        with open(f\"./outputs/sort--{filename}.json\", \"w\") as f:\n",
    "            json.dump(metadata_strongsort, f, cls=DataclassJSONEncoder, indent=2)\n",
    "\n",
    "#         with open(f\"./outputs/frame-id--{filename}.json\", \"w\") as f:\n",
    "#             json.dump(metadata_frame_id, f, indent=2)\n",
    "\n",
    "#         with open(f\"./outputs/tracking-3d--{filename}.json\", \"w\") as f:\n",
    "#             json.dump(metadata_3d, f, cls=DataclassJSONEncoder, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/segment-trajectory--{filename}.json\", \"w\") as f:\n",
    "            json.dump(metadata_segment, f, cls=DataclassJSONEncoder, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/failed_videos--{filename}.json\", \"w\") as f:\n",
    "            json.dump(failed_videos, f, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/perf--{filename}.json\", \"w\") as f:\n",
    "            performance = [\n",
    "                {\n",
    "                    \"stage\": stage.classname(),\n",
    "                    \"benchmark\": stage.benchmark,\n",
    "                }\n",
    "                for stage\n",
    "                in pipeline.stages\n",
    "            ]\n",
    "            json.dump(performance, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98283938-b68f-4925-a5ef-eee7c6c46c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, 'intersection'))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(DecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "            df_annotations = pickle.load(f)\n",
    "        pipeline.add_filter(GroundTruthDetection(df_annotations))\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        # TODO: filter objects based on predicate\n",
    "        pipeline.add_filter(ObjectTypeFilter(['car']))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromDetection2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(FromDetection2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(StrongSORT(cache=strongsort))\n",
    "\n",
    "    # Tracking 3D\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromTracking2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(FromTracking2DAndDepth())\n",
    "\n",
    "    # Segment Trajectory\n",
    "    pipeline.add_filter(FromTracking3D())\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4adca3d-7963-4dc6-bde1-d0ce107ae959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicate = None\n",
    "\n",
    "p_noOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_inview = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objectFilter = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_de = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_opt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_optDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_gtOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_gtOptDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"noopt\": p_noOpt,\n",
    "    \"inview\": p_inview,\n",
    "    \"objectfilter\": p_objectFilter,\n",
    "    \"geo\": p_geo,\n",
    "    \"de\": p_de,\n",
    "    \"opt\": p_opt,\n",
    "    \"optde\": p_optDe,\n",
    "    \"gtopt\": p_gtOpt,\n",
    "    \"gtoptde\": p_gtOptDe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "653d48ca-7993-4c7a-b583-a864c76da0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76267ac21c1412692b1b2d83453b0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtopt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 24\u001b[0m, in \u001b[0;36mrun_benchmark\u001b[0;34m(pipeline, filename, ignore_error)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m frames \u001b[38;5;241m=\u001b[39m Video(\n\u001b[1;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     21\u001b[0m     [camera_config(\u001b[38;5;241m*\u001b[39mf, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPayload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m metadata_strongsort[name] \u001b[38;5;241m=\u001b[39m output[StrongSORT]\n\u001b[1;32m     26\u001b[0m metadata_3d[name] \u001b[38;5;241m=\u001b[39m output[Tracking3D]\n",
      "File \u001b[0;32m~/code/apperception/optimized_ingestion/pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m---> 22\u001b[0m         payload \u001b[38;5;241m=\u001b[39m \u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[0;32m~/code/apperception/optimized_ingestion/payload.py:35\u001b[0m, in \u001b[0;36mPayload.filter\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mfilter\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# print(\"Stage: \", filter.classname())\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     keep, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep\n",
      "File \u001b[0;32m~/code/apperception/optimized_ingestion/stages/stage.py:28\u001b[0m, in \u001b[0;36mStage.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     26\u001b[0m keep_before \u001b[38;5;241m=\u001b[39m payload\u001b[38;5;241m.\u001b[39mkeep\n\u001b[1;32m     27\u001b[0m s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m e \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     30\u001b[0m keep_after \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/code/apperception/optimized_ingestion/cache.py:30\u001b[0m, in \u001b[0;36mcache.<locals>._fn\u001b[0;34m(stage, payload)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(stage: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _CACHE_STATUS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     videofile \u001b[38;5;241m=\u001b[39m payload\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mvideofile\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stage, Stage)\n",
      "File \u001b[0;32m~/code/apperception/optimized_ingestion/stages/decode_frame/decode_frame.py:25\u001b[0m, in \u001b[0;36mDecodeFrame._run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m video\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     26\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metadata) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(payload\u001b[38;5;241m.\u001b[39mvideo)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test = 'gtopt'\n",
    "run_benchmark(pipelines[test](None), test, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a04b-e888-417c-967a-0399f1c8c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subprocess.Popen('shutdown -h now', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7c6f2-28fe-49f9-9923-b5bd198f4687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
