{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.camera_config import camera_config\n",
    "from optimized_ingestion.payload import Payload\n",
    "from optimized_ingestion.pipeline import Pipeline\n",
    "from optimized_ingestion.video import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0676a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stages\n",
    "from optimized_ingestion.stages.filter_car_facing_sideway import FilterCarFacingSideway\n",
    "\n",
    "from optimized_ingestion.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_2d.ground_truth import GroundTruthDetection\n",
    "\n",
    "from optimized_ingestion.stages.detection_3d.from_2d_and_road import From2DAndRoad as FromD2DAndRoad\n",
    "\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.detection_estimation.segment_mapping import RoadPolygonInfo\n",
    "\n",
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT\n",
    "from optimized_ingestion.stages.tracking_2d.tracking_2d import Tracking2D, Tracking2DResult\n",
    "\n",
    "from optimized_ingestion.stages.tracking_3d.from_2d_and_road import From2DAndRoad as FromT2DAndRoad\n",
    "from optimized_ingestion.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "\n",
    "from optimized_ingestion.stages.segment_trajectory import SegmentTrajectory\n",
    "from optimized_ingestion.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "from optimized_ingestion.stages.segment_trajectory.from_tracking_3d import FromTracking3D\n",
    "\n",
    "from optimized_ingestion.stages.get_camera_config_id import GetCameraConfigId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416be4c-f42d-4a60-a7eb-2862faa4253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions\n",
    "from optimized_ingestion.actions.bbox2d_overlay import bbox2d_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59907886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229308b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "\n",
    "\n",
    "class DataclassJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, Tracking3DResult):\n",
    "            return {\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"object_id\": o.object_id,\n",
    "                \"point_from_camera\": o.point_from_camera,\n",
    "                \"point\": o.point.tolist(),\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "            }\n",
    "        if isinstance(o, Tracking2DResult):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"frame_idx\": o.frame_idx,\n",
    "                \"object_id\": o.object_id,\n",
    "                \"bbox_left\": o.bbox_left,\n",
    "                \"bbox_top\": o.bbox_top,\n",
    "                \"bbox_w\": o.bbox_w,\n",
    "                \"bbox_h\": o.bbox_h,\n",
    "                \"object_type\": o.object_type,\n",
    "                \"confidence\": o.confidence\n",
    "            }\n",
    "        if isinstance(o, SegmentPoint):\n",
    "            return {\n",
    "                \"detection_id\": tuple(o.detection_id),\n",
    "                \"car_loc3d\": o.car_loc3d,\n",
    "                \"timestamp\": str(o.timestamp),\n",
    "                \"segment_line\": None if o.segment_line is None else o.segment_line.to_ewkb(),\n",
    "                # \"segment_line_wkb\": o.segment_line.wkb_hex,\n",
    "                \"segment_heading\": o.segment_heading,\n",
    "                \"road_polygon_info\": o.road_polygon_info,\n",
    "                \"obj_id\": o.obj_id,\n",
    "                \"type\": o.type,\n",
    "                \"next\": None if o.next is None else tuple(o.next.detection_id),\n",
    "                \"prev\": None if o.prev is None else tuple(o.prev.detection_id),\n",
    "            }\n",
    "        if isinstance(o, RoadPolygonInfo):\n",
    "            return {\n",
    "                \"id\": o.id,\n",
    "                \"polygon\": str(o.polygon),\n",
    "                # \"polygon_wkb\": o.polygon.wkb_hex,\n",
    "                \"segment_lines\": [str(l) for l in o.segment_lines],\n",
    "                \"road_type\": o.road_type,\n",
    "                \"segment_headings\": o.segment_headings,\n",
    "                \"contains_ego\": o.contains_ego,\n",
    "                \"ego_config\": o.ego_config,\n",
    "                \"fov_lines\": o.fov_lines\n",
    "            }\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.tolist()\n",
    "        if isinstance(o, np.ndarray):\n",
    "            return o.tolist()\n",
    "        return super().default(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "    videos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'cities.pkl'), 'rb') as f:\n",
    "    cities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275836d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename, ignore_error=False):\n",
    "    metadata_strongsort = {}\n",
    "    metadata_3d = {}\n",
    "    metadata_segment = {}\n",
    "    metadata_frame_id = {}\n",
    "    failed_videos = []\n",
    "    names = cities['boston-seaport'][:3]\n",
    "    filtered_videos = [(n, v) for n, v in videos.items() if n[6:10] in names]\n",
    "    for i, (name, video) in enumerate(filtered_videos):\n",
    "        if name[6:10] not in names:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # print(name, f'---{i} / {len(filtered_videos)}---------------------------------------------------------')\n",
    "            video_filename = video['filename']\n",
    "            # print(video_filename)\n",
    "            if not video_filename.startswith('boston') or 'FRONT' not in name:\n",
    "                continue\n",
    "\n",
    "            frames = Video(\n",
    "                os.path.join(DATA_DIR, \"videos\", video[\"filename\"]),\n",
    "                [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "            )\n",
    "\n",
    "            output = pipeline.run(Payload(frames))\n",
    "            metadata_strongsort[name] = output[StrongSORT]\n",
    "            metadata_3d[name] = output[Tracking3D]\n",
    "            metadata_segment[name] = output[SegmentTrajectory]\n",
    "            metadata_frame_id[name] = output[GetCameraConfigId]\n",
    "            # bbox2d_overlay(output, './outputs/bbox2d_overlay')\n",
    "        except Exception as e:\n",
    "            if ignore_error:\n",
    "                failed_videos.append((name, str(traceback.format_exc())))\n",
    "                print(e)\n",
    "                print('ERRORRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR')\n",
    "                print('ERRORRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR')\n",
    "                print('ERRORRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR')\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        # Save progress every video\n",
    "        with open(f\"./outputs/{filename}.json\", \"w\") as f:\n",
    "            json.dump(metadata_strongsort, f, cls=DataclassJSONEncoder, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/{filename}-frame-id.json\", \"w\") as f:\n",
    "            json.dump(metadata_frame_id, f, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/{filename}-3d.json\", \"w\") as f:\n",
    "            json.dump(metadata_3d, f, cls=DataclassJSONEncoder, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/{filename}-segment.json\", \"w\") as f:\n",
    "            json.dump(metadata_segment, f, cls=DataclassJSONEncoder, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/{filename}-failed-videos.json\", \"w\") as f:\n",
    "            json.dump(failed_videos, f, indent=2)\n",
    "\n",
    "        with open(f\"./outputs/{filename}-performance.json\", \"w\") as f:\n",
    "            performance = [\n",
    "                {\n",
    "                    \"stage\": stage.classname(),\n",
    "                    \"runtimes\": stage.runtimes,\n",
    "                }\n",
    "                for stage\n",
    "                in pipeline.stages\n",
    "            ]\n",
    "            json.dump(performance, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_filter = ['bicycle', 'motorcycle', 'car', 'truck', 'bus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c883701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline()\n",
    "# pipeline1.add_filter(ParallelDecodeFrame())\n",
    "pipeline1.add_filter(DecodeFrame())\n",
    "pipeline1.add_filter(filter=YoloDetection())\n",
    "pipeline1.add_filter(filter=ObjectTypeFilter(type_filter))\n",
    "\n",
    "pipeline1.add_filter(filter=FromD2DAndRoad())\n",
    "pipeline1.add_filter(filter=StrongSORT())\n",
    "# pipeline1.add_filter(filter=StrongSORT(cache=False))\n",
    "pipeline1.add_filter(filter=FromT2DAndRoad())\n",
    "\n",
    "pipeline1.add_filter(filter=FromTracking3D())\n",
    "pipeline1.add_filter(filter=GetCameraConfigId())\n",
    "\n",
    "run_benchmark(pipeline1, 'segment-tracking-without-de', ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1652f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline()\n",
    "# pipeline2.add_filter(ParallelDecodeFrame())\n",
    "pipeline2.add_filter(DecodeFrame())\n",
    "pipeline2.add_filter(filter=YoloDetection())\n",
    "pipeline2.add_filter(filter=ObjectTypeFilter(type_filter))\n",
    "\n",
    "pipeline2.add_filter(filter=FromD2DAndRoad())\n",
    "pipeline2.add_filter(filter=DetectionEstimation())\n",
    "pipeline2.add_filter(filter=StrongSORT())\n",
    "pipeline2.add_filter(filter=FromT2DAndRoad())\n",
    "\n",
    "pipeline2.add_filter(filter=SegmentTrajectory())\n",
    "pipeline2.add_filter(filter=GetCameraConfigId())\n",
    "\n",
    "run_benchmark(pipeline2, 'segment-tracking-with-de', ignore_error=True)\n",
    "detection_estimation = pipeline2.stages[4]\n",
    "assert isinstance(detection_estimation, DetectionEstimation)\n",
    "with open('./outputs/segment-tracking-with-de-skip-rate.json', 'w') as f:\n",
    "    json.dump(detection_estimation.skip_rates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf313c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimized_ingestion.stages.depth_estimation import DepthEstimation\n",
    "from optimized_ingestion.stages.tracking_3d.from_2d_and_depth import From2DAndDepth\n",
    "\n",
    "pipeline3 = Pipeline()\n",
    "# pipeline3.add_filter(ParallelDecodeFrame())\n",
    "pipeline3.add_filter(DecodeFrame())\n",
    "pipeline3.add_filter(filter=YoloDetection())\n",
    "# pipeline3.add_filter(filter=ObjectTypeFilter(type_filter))\n",
    "\n",
    "pipeline3.add_filter(filter=FromD2DAndRoad())\n",
    "pipeline3.add_filter(filter=StrongSORT())\n",
    "pipeline3.add_filter(filter=DepthEstimation())\n",
    "pipeline3.add_filter(filter=From2DAndDepth())\n",
    "pipeline3.add_filter(filter=GetCameraConfigId())\n",
    "\n",
    "\n",
    "run_benchmark(pipeline3, 'tracking-with-depth-estimation', ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460cf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "#     annotations = pickle.load(f)\n",
    "\n",
    "# pipeline4 = Pipeline()\n",
    "# pipeline4.add_filter(DecodeFrame())\n",
    "# pipeline4.add_filter(filter=GroundTruthDetection(annotations))\n",
    "# # pipeline4.add_filter(filter=ObjectTypeFilter(type_filter))\n",
    "\n",
    "# # pipeline4.add_filter(filter=FromD2DAndRoad())\n",
    "# # pipeline4.add_filter(filter=StrongSORT(cache=True))\n",
    "# # # pipeline4.add_filter(filter=StrongSORT(cache=False))\n",
    "# # pipeline4.add_filter(filter=FromT2DAndRoad())\n",
    "\n",
    "# # pipeline4.add_filter(filter=FromTracking3D())\n",
    "# # pipeline4.add_filter(filter=GetCameraConfigId())\n",
    "\n",
    "# run_benchmark(pipeline4, 'segment-tracking-gt-detection', ignore_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d116b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./outputs/segment-tracking-without-de-performance.json\", \"r\") as f:\n",
    "    benchmark = json.load(f)\n",
    "\n",
    "ss_cache, ss_no_cache, *_ = benchmark[4:]\n",
    "benchmark_data = [\n",
    "    {\n",
    "        'name': ssc['name'],\n",
    "        'runtime_cache': ssc['runtime'],\n",
    "        'runtime_no_cache': ssnc['runtime']\n",
    "    }\n",
    "    for ssc, ssnc\n",
    "    in zip(ss_cache['runtimes'], ss_no_cache['runtimes'])\n",
    "]\n",
    "benchmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad112eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.Chart(pd.DataFrame.from_dict(benchmark_data))\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        x='runtime_cache:Q',\n",
    "        y='runtime_no_cache:Q',\n",
    "        tooltip=['name']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6e166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a40094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
