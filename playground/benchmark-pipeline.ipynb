{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54af4058-3f77-4307-8ae7-44a0a3013632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chanwutk/code/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60391c1-d071-43cb-8c4f-009e435e67ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf02786-1593-400e-83d1-4e26485f224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimized_ingestion.pipeline import Pipeline\n",
    "import optimized_ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd33a47-74f7-4c2b-ae6a-d00ea6e6d4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o1 = objects[0]\n",
    "o2 = objects[1]\n",
    "c = camera\n",
    "\n",
    "predicate = (\n",
    "    (o1.id != o2.id) &\n",
    "    (F.like(o1.type, 'car') | F.like(o1.type, 'truck')) &\n",
    "    (F.like(o2.type, 'car') | F.like(o2.type, 'truck')) &\n",
    "    F.angle_between(F.facing_relative(c.ego, F.road_direction(c.ego)), -15, 15) &\n",
    "    (F.distance(c.ego, o1.trans@c.time) < 50) &\n",
    "    (F.view_angle(o1.trans@c.time, c.ego) < 70 / 2.0) &\n",
    "    (F.distance(c.ego, o2.trans@c.time) < 50) &\n",
    "    (F.view_angle(o2.trans@c.time, c.ego) < 70 / 2.0) &\n",
    "    F.contains_all('intersection', [o1.trans, o2.trans]@c.time) &\n",
    "    F.angle_between(F.facing_relative(o1.trans@c.time, c.ego), 40, 135) &\n",
    "    F.angle_between(F.facing_relative(o2.trans@c.time, c.ego), -135, -50) &\n",
    "    (F.min_distance(c.ego, 'intersection') < 10) &\n",
    "    F.angle_between(F.facing_relative(o1.trans@c.time, o2.trans@c.time), 100, -100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace93423-a8d2-43ee-8f7a-b56604d6ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-3-12 Python-3.10.10 torch-2.0.0+cu117 CUDA:0 (Tesla T4, 14966MiB)\n",
      "\n",
      "Using cache found in /home/chanwutk/code/apperception/weights/ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-3-12 Python-3.10.10 torch-2.0.0+cu117 CUDA:0 (Tesla T4, 14966MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from optimized_ingestion.stages.in_view import InView\n",
    "from optimized_ingestion.stages.decode_frame.decode_frame import DecodeFrame\n",
    "from optimized_ingestion.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from optimized_ingestion.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from optimized_ingestion.stages.detection_3d.from_2d_and_road import From2DAndRoad\n",
    "from optimized_ingestion.stages.detection_3d.from_2d_and_depth import From2DAndDepth\n",
    "from optimized_ingestion.stages.depth_estimation import DepthEstimation\n",
    "from optimized_ingestion.stages.detection_estimation import DetectionEstimation\n",
    "from optimized_ingestion.stages.tracking_2d.strongsort import StrongSORT\n",
    "\n",
    "\n",
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, 'intersection'))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(DecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        pass\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        # TODO: filter objects based on predicate\n",
    "        pipeline.add_filter(ObjectTypeFilter([]))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(From2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(From2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(StrongSORT(cache=strongsort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a26382-a534-4ab8-8963-96683e3b9b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-3-12 Python-3.10.10 torch-2.0.0+cu117 CUDA:0 (Tesla T4, 14966MiB)\n",
      "\n",
      "Using cache found in /home/chanwutk/code/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-3-12 Python-3.10.10 torch-2.0.0+cu117 CUDA:0 (Tesla T4, 14966MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loggers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m p_inview \u001b[38;5;241m=\u001b[39m create_pipeline(\n\u001b[1;32m      2\u001b[0m     predicate,\n\u001b[1;32m      3\u001b[0m     in_view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     detection_estimation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m \u001b[43mloggers\u001b[49m:\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mWARN)\n\u001b[1;32m     11\u001b[0m p_objfilter \u001b[38;5;241m=\u001b[39m create_pipeline(\n\u001b[1;32m     12\u001b[0m     predicate,\n\u001b[1;32m     13\u001b[0m     in_view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     detection_estimation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loggers' is not defined"
     ]
    }
   ],
   "source": [
    "p_inview = create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objfilter = create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_opt = create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_opt_de = create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = [p_inview, p_objfilter, p_geo, p_opt, p_opt_de]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6e451-ce53-4916-9ed9-f8cf5da04dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500cef29-2e28-45ec-b17f-82a5f95289d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
