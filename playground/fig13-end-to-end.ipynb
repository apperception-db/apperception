{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c9badc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T00:15:43.617706Z",
     "iopub.status.busy": "2022-12-08T00:15:43.616466Z",
     "iopub.status.idle": "2022-12-08T00:15:48.654505Z",
     "shell.execute_reply": "2022-12-08T00:15:48.653531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/apperception/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152abe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/apperception/.installs/mambaforge/envs/apperception/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /data/apperception/apperception/weights/ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<connection object at 0x7f5a4ee32e80; dsn: 'user=docker password=xxx dbname=mobilitydb host=localhost port=25441', closed: 0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects\n",
    "from optimized_ingestion.utils.preprocess import preprocess\n",
    "database.connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ScenicWorld'\n",
    "world = empty_world(name=name)\n",
    "\n",
    "obj1 = objects[0]\n",
    "obj2 = objects[1]\n",
    "cam = camera\n",
    "\n",
    "world = world.filter(\n",
    "    (obj1.id != obj2.id) &\n",
    "#     F.like(obj1.type, 'car') &\n",
    "#     F.like(obj2.type, 'car') &\n",
    "    F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego)), -15, 15) &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 50, 135) &\n",
    "    F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
    "    (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be10787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /data/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0757-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [00:00, 1949.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:00<00:00, 4061.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  SegmentTrajectory.FromTracking3D\n",
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "Inserting trajectory\n",
      "info found [[93, 999.0, 379.0, 493.0, 171.0, -0.7853982, 'intersection', RoadPolygonInfo(id='ec17e151-b449-4bed-ad13-25197bc872fd', polygon=<shapely.geometry.polygon.Polygon object at 0x7f5711fa87c0>, segment_lines=[], road_type=None, segment_headings=[], contains_ego=None, ego_config=None, fov_lines=None), 63.41837692260742], [98, 2.0, 422.0, 413.0, 160.0, -0.7853982, 'intersection', RoadPolygonInfo(id='ec17e151-b449-4bed-ad13-25197bc872fd', polygon=<shapely.geometry.polygon.Polygon object at 0x7f5711fab2e0>, segment_lines=[], road_type=None, segment_headings=[], contains_ego=None, ego_config=None, fov_lines=None), 63.41837692260742]]\n"
     ]
    }
   ],
   "source": [
    "preprocess(world, ['scene-0757-CAM_FRONT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: get_id_time_camId_filename\n",
      "get_id_time_camId_filename \n",
      "        SELECT t0.itemId,t1.itemId, cameras.timestamp, cameras.cameraId, cameras.filename\n",
      "        FROM (SELECT * FROM item_general_trajectory) as t0\n",
      "        JOIN (SELECT * FROM item_general_trajectory) as t1 USING (cameraId)\n",
      "        JOIN Cameras USING (cameraId)\n",
      "        WHERE ((t0.itemId<>t1.itemId) AND angleBetween(facingRelative(egoHeading,roadDirection(egoTranslation,egoHeading)),-15,15) AND (ST_Distance(egoTranslation,valueAtTimestamp(t0.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t0.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (ST_Distance(egoTranslation,valueAtTimestamp(t1.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t1.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (EXISTS(SELECT 1\n",
      "            FROM SegmentPolygon\n",
      "            WHERE\n",
      "                'intersection' = Any(SegmentPolygon.segmentTypes) AND\n",
      "                ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t0.translations,timestamp)) AND ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t1.translations,timestamp))\n",
      "        )) AND angleBetween(facingRelative((valueAtTimestamp(t0.itemHeadings,timestamp))::real,egoHeading),50,135) AND angleBetween(facingRelative((valueAtTimestamp(t1.itemHeadings,timestamp))::real,egoHeading),-135,-50) AND (minDistance(egoTranslation,'intersection')<10) AND angleBetween(facingRelative((valueAtTimestamp(t0.itemHeadings,timestamp))::real,(valueAtTimestamp(t1.itemHeadings,timestamp))::real),100,-100))\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "id_time_camId_filename_base = world.get_id_time_camId_filename(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3d48ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_time_camId_filename_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "469cee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(world, ['scene-0757-CAM_FRONT'], base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf72871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_time_camId_filename = world.get_id_time_camId_filename(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20bb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
