{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9badc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T00:15:43.617706Z",
     "iopub.status.busy": "2022-12-08T00:15:43.616466Z",
     "iopub.status.idle": "2022-12-08T00:15:48.654505Z",
     "shell.execute_reply": "2022-12-08T00:15:48.653531Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152abe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects\n",
    "from optimized_ingestion.utils.preprocess import preprocess\n",
    "database.connection\n",
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "NUSCENES_RAW_DATA = \"NUSCENES_RAW_DATA\"\n",
    "if NUSCENES_RAW_DATA in os.environ:\n",
    "    RAW_DATA_DIR = os.environ[NUSCENES_RAW_DATA]\n",
    "else:\n",
    "    RAW_DATA_DIR = \"/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os.path import exists\n",
    "def construct_video(frames, size=(1600, 900), base=False, vid_name=None, vid_prefix=False):\n",
    "    unique_frames = []\n",
    "    for f in frames:\n",
    "        if f not in unique_frames:\n",
    "            unique_frames.append(f)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    vid_name = \"./outputs/fig13_\"+vid_name if vid_name else f\"./outputs/{'fig13_base' if base else 'fig13_optimized'}.mp4\"\n",
    "    display_video = cv2.VideoWriter(vid_name,fourcc, 1, size)\n",
    "    for frame in unique_frames:\n",
    "        if vid_prefix:\n",
    "            img_path = os.path.join(RAW_DATA_DIR, 'sweeps/CAM_FRONT', frame)\n",
    "            if not exists(img_path):\n",
    "                img_path = os.path.join(RAW_DATA_DIR, 'samples/CAM_FRONT', frame)\n",
    "        else:\n",
    "            img_path = os.path.join(RAW_DATA_DIR, frame)\n",
    "        img = cv2.imread(img_path)\n",
    "        display_video.write(img)\n",
    "\n",
    "    display_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ScenicWorld'\n",
    "world = empty_world(name=name)\n",
    "\n",
    "obj1 = objects[0]\n",
    "obj2 = objects[1]\n",
    "cam = camera\n",
    "\n",
    "world = world.filter(\n",
    "    (obj1.id != obj2.id) &\n",
    "    (F.like(obj1.type, 'car') | F.like(obj1.type, 'truck')) &\n",
    "    (F.like(obj2.type, 'car') | F.like(obj2.type, 'truck')) &\n",
    "    F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego)), -15, 15) &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 40, 135) &\n",
    "    F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
    "    (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20af03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(world, DATA_DIR, ['scene-0655-CAM_FRONT'], base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e90463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "investigation =[[0, 530, 480, 692, 584, 'intersection'], [1, 0, 452, 210, 647, 'intersection'], [2, 1329, 475, 1599, 612, 'intersection'], [3, 196, 430, 467, 598, 'intersection'], [4, 1105, 469, 1277, 547, 'intersection'], [5, 458, 476, 531, 550, 'intersection'], [6, 724, 480, 763, 510, 'intersection'], [7, 511, 470, 591, 532, 'intersection'], [8, 1292, 475, 1487, 579, 'intersection'], [9, 773, 473, 811, 498, 'intersection'], [10, 1055, 478, 1095, 507, 'intersection'], [11, 849, 476, 875, 500, 'intersection']]\n",
    "target = [[0, 530, 480, 692, 584, 'intersection', \n",
    "           np.array([list(zip([363.0340999493258, 1337.7113240288093, 1692.9239863364926,\n",
    "                               1790.0120384724512, 2032.4876728386516, 363.0340999493258],\n",
    "                              [863.9872080248853, 869.7245561458105, 896.1907881034633,\n",
    "                               933.9768149085215, 1035.6408551785412, 863.9872080248853]))]).reshape(-1,1,2)]]\n",
    "\n",
    "skipping_info_0655=[[1, None, None], [2, None, None], [10, 'ego_exit_segment', None], [11, None, None], [12, None, None], [13, None, None], [14, None, None], [15, None, None], [16, None, None], [17, None, None], [20, 'meet_up', ((-133, 219), (135, 499))], [21, 'car_exit_segment', ((412, 429), (504, 501))], [22, None, None], [23, None, None], [24, None, None], [25, None, None], [26, None, None], [27, None, None], [34, 'car_exit_segment', ((521, 413), (595, 485))], [35, 'ego_exit_segment', None], [37, 'car_exit_segment', ((1084, 402), (1324, 516))], [46, 'car_exit_segment', ((1105, 392), (1367, 516))], [55, 'car_exit_segment', ((962, 444), (1132, 504))], [56, 'car_exit_segment', ((1019, 430), (1191, 508))], [57, 'car_exit_segment', ((454, 448), (538, 496))], [58, 'car_exit_segment', ((-25, 343), (293, 519))], [65, 'ego_exit_segment', None], [113, None, None], [114, None, None], [115, None, None], [116, None, None], [117, None, None], [118, None, None], [119, None, None], [120, None, None], [121, None, None], [122, None, None], [132, 'ego_exit_segment', None], [133, 'car_exit_segment', ((1199, 448), (1271, 486))], [137, 'car_exit_segment', ((651, 428), (727, 490))], [138, 'car_exit_segment', ((1173, 464), (1235, 502))], [140, 'car_exit_segment', ((644, 440), (724, 500))], [141, None, None], [142, None, None], [143, None, None], [153, 'ego_exit_segment', None], [167, None, None], [168, None, None], [169, None, None], [170, None, None], [171, None, None], [172, None, None], [173, None, None], [174, None, None], [175, None, None], [182, 'ego_exit_segment', None], [183, None, None], [184, None, None], [185, None, None], [186, None, None], [187, None, None], [188, None, None], [189, None, None], [195, 'ego_exit_segment', None], [209, 'car_exit_segment', ((700, 440), (756, 486))], [211, 'car_exit_segment', ((695, 440), (753, 484))], [213, 'car_exit_segment', ((681, 426), (745, 480))], [214, None, None], [215, None, None], [216, None, None], [217, 'car_exit_segment', ((17, 456), (141, 514))], [220, 'car_exit_segment', ((-11, 461), (115, 513))], [223, 'ego_exit_segment', None], [236, 'exit_view', ((563, 405), (685, 501))]]\n",
    "\n",
    "def investigation_skipping(video_filename, skipping_info):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    vid_name = f\"./outputs/{video_filename}_skipping_investigation.mp4\"\n",
    "    display_video = cv2.VideoWriter(vid_name, fourcc, 1, (1600, 900))\n",
    "    video_path = os.path.join(DATA_DIR, \"videos\", video_filename)\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    frame_idx = 0\n",
    "    current_frame_num, current_action, current_target_bbox = skipping_info[0]\n",
    "    current_skipping_info_idx = 0\n",
    "    while(vidcap.isOpened()):\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        next_skipping_info_idx = current_skipping_info_idx + 1\n",
    "        if next_skipping_info_idx < len(skipping_info):\n",
    "            next_frame_num, next_action, next_target_bbox = skipping_info[next_skipping_info_idx]\n",
    "        if frame_idx < next_frame_num:\n",
    "            if current_action:\n",
    "                image = cv2.putText(image, current_action, (50, 50),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            if current_target_bbox:\n",
    "                x, y = current_target_bbox[0]\n",
    "                x_w, y_h = current_target_bbox[1]\n",
    "                cv2.rectangle(image, (x+(x_w-x)//2, y+(y_h-y)//2), (x_w+(x_w-x)//2, y_h+(y_h-y)//2), (0,255,0), 4)\n",
    "        if frame_idx == 55:\n",
    "            for e in target:\n",
    "                did, x, y, x_w, y_h, t, pts1 = e\n",
    "                cv2.putText(image, f'obj_{did}', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, t, (x, y_h), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.rectangle(image, (x,y), (x_w, y_h), (0,255,0), 2)\n",
    "                cv2.polylines(image, np.int32([pts1]), isClosed=True, color=(255,0,0), thickness = 2)\n",
    "            cv2.imwrite('./outputs/0655_frame_55_skipping_investigation.jpg', image)\n",
    "        display_video.write(image)\n",
    "        frame_idx += 1\n",
    "        if frame_idx == next_frame_num:\n",
    "            current_skipping_info_idx = next_skipping_info_idx\n",
    "            current_action = next_action\n",
    "            current_target_bbox = next_target_bbox\n",
    "    display_video.release()\n",
    "investigation_skipping('boston-seaport-scene-0655-CAM_FRONT.mp4', skipping_info_0655)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d62d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_query_start = time.time()\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(2)\n",
    "print(f'optimized query time: {time.time()-optimized_query_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_results = [e[4] for e in id_time_camId_filename]\n",
    "construct_video(optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be10787",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(world, DATA_DIR, ['scene-0757-CAM_FRONT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query_start = time.time()\n",
    "id_time_camId_filename_base = world.get_id_time_camId_filename(2)\n",
    "print(f'based query time: {time.time()-base_query_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_time_camId_filename_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = [e[4] for e in id_time_camId_filename_base]\n",
    "construct_video(base_results, base=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative = [f for f in base_results if f not in optimized_results]\n",
    "print(len(false_negative))\n",
    "construct_video(false_negative, vid_name=\"false_negative.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19be7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = [f for f in optimized_results if f not in base_results]\n",
    "print(len(false_positive))\n",
    "construct_video(false_positive, vid_name=\"false_positive.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d9bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f6ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
