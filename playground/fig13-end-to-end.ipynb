{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c9badc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T00:15:43.617706Z",
     "iopub.status.busy": "2022-12-08T00:15:43.616466Z",
     "iopub.status.idle": "2022-12-08T00:15:48.654505Z",
     "shell.execute_reply": "2022-12-08T00:15:48.653531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/apperception/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a17b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152abe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x7feff2dcae80; dsn: 'user=docker password=xxx dbname=mobilitydb host=localhost port=25441', closed: 0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F, import_pickle\n",
    "from apperception.predicate import camera, objects\n",
    "database.connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ScenicWorld'\n",
    "world = empty_world(name=name)\n",
    "\n",
    "obj1 = objects[0]\n",
    "obj2 = objects[1]\n",
    "cam = camera\n",
    "\n",
    "world = world.filter(\n",
    "    (obj1.id != obj2.id) &\n",
    "    F.like(obj1.type, 'car') &\n",
    "    F.like(obj2.type, 'car') &\n",
    "    F.angle_between(F.facing_relative(cam.ego, cam.roadDirection), -15, 15) &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 50, 135) &\n",
    "    F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
    "    (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be10787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/apperception/.installs/mambaforge/envs/apperception/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/apperception/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n",
      "New camera inserted successfully.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Using cache found in /data/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12196MiB)\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New camera inserted successfully.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0655-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "396it [00:00, 2362.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 396/396 [00:00<00:00, 4384.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "396\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  SegmentTrajectory.FromTracking3D\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimized_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/utils/preprocess.py:55\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(world, base)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m frames \u001b[38;5;241m=\u001b[39m Video(\n\u001b[1;32m     51\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideos/boston-seaport\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     52\u001b[0m     [camera_config(\u001b[38;5;241m*\u001b[39mf, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     53\u001b[0m     video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0m \u001b[43mprocess_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/utils/process_pipeline.py:144\u001b[0m, in \u001b[0;36mprocess_pipeline\u001b[0;34m(video_name, frames, pipeline, base)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_pipeline\u001b[39m(video_name, frames, pipeline, base):\n\u001b[0;32m--> 144\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPayload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m    145\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m base:\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m---> 22\u001b[0m         payload \u001b[38;5;241m=\u001b[39m \u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/payload.py:45\u001b[0m, in \u001b[0;36mPayload.filter\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mfilter\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mclassname())\n\u001b[0;32m---> 45\u001b[0m     keep, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(keep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keep))\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metadata \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mget(metadata)))\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/stages/stage.py:25\u001b[0m, in \u001b[0;36mStage.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple[bitarray | None, Dict[str, List[T]] | None]\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m     s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     e \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntimes\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mvideofile,\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m: e \u001b[38;5;241m-\u001b[39m s\n\u001b[1;32m     31\u001b[0m     })\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/stages/segment_trajectory/from_tracking_3d.py:87\u001b[0m, in \u001b[0;36mFromTracking3D._run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     78\u001b[0m     shapely_polygon \u001b[38;5;241m=\u001b[39m shapely\u001b[38;5;241m.\u001b[39mwkb\u001b[38;5;241m.\u001b[39mloads(polygon\u001b[38;5;241m.\u001b[39mto_ewkb(), \u001b[38;5;28mhex\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shapely_polygon, shapely\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mPolygon)\n\u001b[1;32m     80\u001b[0m     segment_point \u001b[38;5;241m=\u001b[39m SegmentPoint(\n\u001b[1;32m     81\u001b[0m         did,\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(det\u001b[38;5;241m.\u001b[39mpoint\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[1;32m     83\u001b[0m         det\u001b[38;5;241m.\u001b[39mtimestamp,\n\u001b[1;32m     84\u001b[0m         segmentline,\n\u001b[1;32m     85\u001b[0m         segmentheading,\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# A place-holder for Polygon that only contain polygon id and polygon\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         \u001b[43mRoadPolygonInfo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpolygonid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshapely_polygon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     97\u001b[0m         oid,\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Detection that cannot be mapped to any segment\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     segment_point \u001b[38;5;241m=\u001b[39m SegmentPoint(\n\u001b[1;32m    104\u001b[0m         did,\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(det\u001b[38;5;241m.\u001b[39mpoint\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m<string>:11\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, id, polygon, segment_lines, road_type, segment_headings, contains_ego, ego_config, fov_lines)\u001b[0m\n",
      "File \u001b[0;32m/data/apperception/apperception/optimized_ingestion/stages/detection_estimation/segment_mapping.py:147\u001b[0m, in \u001b[0;36mRoadPolygonInfo.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m     ends\u001b[38;5;241m.\u001b[39madd(end)\n\u001b[1;32m    141\u001b[0m starts: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist[Tuple[float, float]]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    142\u001b[0m     start\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m start\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m start_segment_map\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ends\n\u001b[1;32m    146\u001b[0m ]\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(starts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(starts)\n\u001b[1;32m    149\u001b[0m sorted_lines: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist[shapely.geometry.LineString]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    150\u001b[0m sorted_headings: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist[float]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAssertionError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from optimized_ingestion.utils.preprocess import preprocess\n",
    "preprocess(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_time_camId_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cee14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72871a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
