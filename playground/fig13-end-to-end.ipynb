{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c9badc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T00:15:43.617706Z",
     "iopub.status.busy": "2022-12-08T00:15:43.616466Z",
     "iopub.status.idle": "2022-12-08T00:15:48.654505Z",
     "shell.execute_reply": "2022-12-08T00:15:48.653531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/apperception/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152abe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/apperception/.installs/mambaforge/envs/apperception/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Using cache found in /data/apperception/apperception/weights/ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects\n",
    "from optimized_ingestion.utils.preprocess import preprocess\n",
    "database.connection\n",
    "from optimized_ingestion.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922e90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "NUSCENES_RAW_DATA = \"NUSCENES_RAW_DATA\"\n",
    "if NUSCENES_RAW_DATA in os.environ:\n",
    "    RAW_DATA_DIR = os.environ[NUSCENES_RAW_DATA]\n",
    "else:\n",
    "    RAW_DATA_DIR = \"/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574d9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def construct_video(frames, size=(1600, 900), base=False, vid_name=None):\n",
    "    unique_frames = []\n",
    "    for f in frames:\n",
    "        if f not in unique_frames:\n",
    "            unique_frames.append(f)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    vid_name = \"./outputs/fig13_\"+vid_name if vid_name else f\"./outputs/{'fig13_base' if base else 'fig13_optimized'}.avi\"\n",
    "    display_video = cv2.VideoWriter(vid_name,fourcc, 1, size)\n",
    "    for frame in unique_frames:\n",
    "        img_path = os.path.join(RAW_DATA_DIR, frame)\n",
    "        img = cv2.imread(img_path)\n",
    "        display_video.write(img)\n",
    "\n",
    "    display_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ScenicWorld'\n",
    "world = empty_world(name=name)\n",
    "\n",
    "obj1 = objects[0]\n",
    "obj2 = objects[1]\n",
    "cam = camera\n",
    "\n",
    "world = world.filter(\n",
    "    (obj1.id != obj2.id) &\n",
    "    (F.like(obj1.type, 'car') | F.like(obj1.type, 'truck')) &\n",
    "    (F.like(obj2.type, 'car') | F.like(obj2.type, 'truck')) &\n",
    "    F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego)), -15, 15) &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 50, 180) &\n",
    "    F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
    "    (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be10787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Using cache found in /data/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0757-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:03<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:02<00:00, 98.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [00:00, 3121.81it/s]\n",
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/apperception/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:13<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:00<00:00, 7167.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  SegmentTrajectory.FromTracking3D\n",
      "None\n",
      "237\n",
      "  filtered frames: 100.0%\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "obj_id 1\n",
      "obj_id 5\n",
      "obj_id 10\n",
      "obj_id 11\n",
      "obj_id 14\n",
      "obj_id 19\n",
      "obj_id 23\n",
      "obj_id 25\n",
      "obj_id 26\n",
      "obj_id 37\n",
      "obj_id 43\n",
      "obj_id 44\n",
      "obj_id 47\n",
      "obj_id 55\n",
      "obj_id 60\n",
      "obj_id 61\n",
      "obj_id 66\n",
      "obj_id 73\n",
      "obj_id 74\n",
      "obj_id 75\n",
      "obj_id 82\n",
      "obj_id 85\n",
      "obj_id 93\n",
      "obj_id 95\n",
      "obj_id 98\n",
      "obj_id 101\n",
      "obj_id 104\n",
      "obj_id 105\n",
      "obj_id 109\n",
      "obj_id 114\n",
      "obj_id 116\n",
      "obj_id 119\n",
      "obj_id 120\n",
      "obj_id 121\n",
      "obj_id 107\n",
      "obj_id 125\n",
      "obj_id 126\n",
      "obj_id 131\n",
      "obj_id 144\n",
      "obj_id 147\n",
      "obj_id 150\n",
      "obj_id 159\n",
      "obj_id 161\n",
      "obj_id 166\n",
      "obj_id 169\n",
      "obj_id 170\n",
      "obj_id 174\n",
      "obj_id 177\n",
      "obj_id 181\n",
      "obj_id 182\n",
      "Time taken to insert trajectories: 0.2822730541229248\n",
      "info found [[116, 316.0, 455.0, 296.0, 95.0], [161, 316.0, 454.0, 302.0, 94.0]]\n",
      "total preprocess time 29.35728645324707\n"
     ]
    }
   ],
   "source": [
    "preprocess(world, DATA_DIR, ['scene-0757-CAM_FRONT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff5d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: get_id_time_camId_filename\n",
      "get_id_time_camId_filename \n",
      "        SELECT t0.itemId,t1.itemId, cameras.timestamp, cameras.cameraId, cameras.filename\n",
      "        FROM (SELECT * FROM item_general_trajectory) as t0\n",
      "        JOIN (SELECT * FROM item_general_trajectory) as t1 USING (cameraId)\n",
      "        JOIN Cameras USING (cameraId)\n",
      "        WHERE ((t0.itemId<>t1.itemId) AND (t0.objectType LIKE 'car' OR t0.objectType LIKE 'truck') AND (t1.objectType LIKE 'car' OR t1.objectType LIKE 'truck') AND angleBetween(facingRelative(egoHeading,roadDirection(egoTranslation,egoHeading)),-15,15) AND (ST_Distance(egoTranslation,valueAtTimestamp(t0.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t0.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (ST_Distance(egoTranslation,valueAtTimestamp(t1.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t1.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (EXISTS(SELECT 1\n",
      "            FROM SegmentPolygon\n",
      "            WHERE\n",
      "                'intersection' = Any(SegmentPolygon.segmentTypes) AND\n",
      "                ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t0.translations,timestamp)) AND ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t1.translations,timestamp))\n",
      "        )) AND angleBetween(facingRelative((headingAtTimestamp(t0.itemHeadings, timestamp))::real,egoHeading),50,180) AND angleBetween(facingRelative((headingAtTimestamp(t1.itemHeadings, timestamp))::real,egoHeading),-135,-50) AND (minDistance(egoTranslation,'intersection')<10) AND angleBetween(facingRelative((headingAtTimestamp(t0.itemHeadings, timestamp))::real,(headingAtTimestamp(t1.itemHeadings, timestamp))::real),100,-100))\n",
      "        \n",
      "done execute node\n",
      "Result length: 46\n",
      "based query time: 121.64299488067627\n"
     ]
    }
   ],
   "source": [
    "base_query_start = time.time()\n",
    "id_time_camId_filename_base = world.get_id_time_camId_filename(2)\n",
    "print(f'based query time: {time.time()-base_query_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1523b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scene-0757-CAM_FRONT_obj_44',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 12, 262404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657112262404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_44',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 14, 362404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657114362404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_74',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 14, 612404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657114612404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_85',\n",
       "  'scene-0757-CAM_FRONT_obj_61',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 16, 262404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657116262404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_85',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 17, 162404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117162404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_85',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 17, 362404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117362404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_93',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 17, 362404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117362404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_93',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 17, 612404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117612404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_85',\n",
       "  'scene-0757-CAM_FRONT_obj_23',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 17, 662404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117662404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_23',\n",
       "  'scene-0757-CAM_FRONT_obj_98',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 18, 112404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_93',\n",
       "  'scene-0757-CAM_FRONT_obj_98',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 18, 112404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657118112404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_120',\n",
       "  'scene-0757-CAM_FRONT_obj_144',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 22, 412404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122412404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_144',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 22, 412404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657122412404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 512404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123512404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 512404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123512404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 612404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123612404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 612404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123612404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 662404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123662404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 662404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123662404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 762404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123762404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 862404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123862404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 862404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123862404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 912404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123912404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 23, 912404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657123912404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 12404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124012404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 112404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124112404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 112404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124112404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 162404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124162404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 162404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124162404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 262404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124262404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 262404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124262404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 362404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124362404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 362404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124362404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 412404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124412404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 512404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_131',\n",
       "  'scene-0757-CAM_FRONT_obj_107',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 512404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 512404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_107',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 512404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124512404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 612404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124612404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 862404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124862404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 912404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124912404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_107',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 24, 912404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657124912404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 25, 12404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125012404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 25, 112404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125112404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 25, 162404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125162404.jpg'),\n",
       " ('scene-0757-CAM_FRONT_obj_161',\n",
       "  'scene-0757-CAM_FRONT_obj_116',\n",
       "  datetime.datetime(2018, 8, 30, 12, 25, 25, 262404, tzinfo=datetime.timezone.utc),\n",
       "  'scene-0757-CAM_FRONT',\n",
       "  'sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125262404.jpg')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_time_camId_filename_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642b3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = [e[4] for e in id_time_camId_filename_base]\n",
    "construct_video(base_results, base=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391948ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Using cache found in /data/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0757-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  InView\n",
      "237\n",
      "None\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:03<00:00, 23.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:02<00:00, 100.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.ObjectTypeFilter\n",
      "types: ['car', 'truck', 'car', 'truck']\n",
      "type_indices_to_keep: {2, 7}\n",
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [00:00, 3432.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n",
      "ego_speed:  1.3581198756421884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 236/236 [00:06<00:00, 34.94it/s]\n",
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of skipped 9\n",
      "{None: 228}\n",
      "total_run_time 6.757089853286743\n",
      "total_detection_time 6.532000780105591\n",
      "total_generate_sample_plan_time 0.15547561645507812\n",
      "237\n",
      "237\n",
      "  filtered frames: 96.20253164556962%\n",
      "......KK..KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "Successfully loaded pretrained weights from \"/data/apperception/apperception/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:08<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 96.20253164556962%\n",
      "......KK..KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:00<00:00, 9971.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 96.20253164556962%\n",
      "......KK..KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Stage:  SegmentTrajectory.FromTracking3D\n",
      "None\n",
      "237\n",
      "  filtered frames: 96.20253164556962%\n",
      "......KK..KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "obj_id 7\n",
      "obj_id 8\n",
      "obj_id 9\n",
      "obj_id 15\n",
      "obj_id 20\n",
      "obj_id 22\n",
      "obj_id 25\n",
      "obj_id 29\n",
      "obj_id 32\n",
      "obj_id 35\n",
      "obj_id 37\n",
      "obj_id 39\n",
      "obj_id 44\n",
      "obj_id 46\n",
      "obj_id 47\n",
      "obj_id 50\n",
      "obj_id 51\n",
      "obj_id 52\n",
      "obj_id 54\n",
      "obj_id 61\n",
      "obj_id 67\n",
      "obj_id 69\n",
      "obj_id 73\n",
      "obj_id 77\n",
      "Time taken to insert trajectories: 0.12765073776245117\n",
      "info found []\n",
      "total preprocess time 29.303135633468628\n"
     ]
    }
   ],
   "source": [
    "preprocess(world, DATA_DIR, ['scene-0757-CAM_FRONT'], base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10b4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: get_id_time_camId_filename\n",
      "get_id_time_camId_filename \n",
      "        SELECT t0.itemId,t1.itemId, cameras.timestamp, cameras.cameraId, cameras.filename\n",
      "        FROM (SELECT * FROM item_general_trajectory) as t0\n",
      "        JOIN (SELECT * FROM item_general_trajectory) as t1 USING (cameraId)\n",
      "        JOIN Cameras USING (cameraId)\n",
      "        WHERE ((t0.itemId<>t1.itemId) AND (t0.objectType LIKE 'car' OR t0.objectType LIKE 'truck') AND (t1.objectType LIKE 'car' OR t1.objectType LIKE 'truck') AND angleBetween(facingRelative(egoHeading,roadDirection(egoTranslation,egoHeading)),-15,15) AND (ST_Distance(egoTranslation,valueAtTimestamp(t0.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t0.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (ST_Distance(egoTranslation,valueAtTimestamp(t1.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t1.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (EXISTS(SELECT 1\n",
      "            FROM SegmentPolygon\n",
      "            WHERE\n",
      "                'intersection' = Any(SegmentPolygon.segmentTypes) AND\n",
      "                ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t0.translations,timestamp)) AND ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t1.translations,timestamp))\n",
      "        )) AND angleBetween(facingRelative((headingAtTimestamp(t0.itemHeadings, timestamp))::real,egoHeading),50,180) AND angleBetween(facingRelative((headingAtTimestamp(t1.itemHeadings, timestamp))::real,egoHeading),-135,-50) AND (minDistance(egoTranslation,'intersection')<10) AND angleBetween(facingRelative((headingAtTimestamp(t0.itemHeadings, timestamp))::real,(headingAtTimestamp(t1.itemHeadings, timestamp))::real),100,-100))\n",
      "        \n",
      "done execute node\n",
      "Result length: 45\n",
      "optimized query time: 13.5182523727417\n"
     ]
    }
   ],
   "source": [
    "optimized_query_start = time.time()\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(2)\n",
    "print(f'optimized query time: {time.time()-optimized_query_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7db7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_results = [e[4] for e in id_time_camId_filename]\n",
    "construct_video(optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee79569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "false_negative = [f for f in base_results if f not in optimized_results]\n",
    "print(len(false_negative))\n",
    "construct_video(false_negative, vid_name=\"false_negative.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19be7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "false_positive = [f for f in optimized_results if f not in base_results]\n",
    "print(len(false_positive))\n",
    "construct_video(false_positive, vid_name=\"false_positive.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa88fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [e for e in id_time_camId_filename if e[4] in false_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2166f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation = [[116, 316.0, 455.0, 296.0, 95.0], [161, 316.0, 454.0, 302.0, 94.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d112e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Mini/sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125362404.jpg')\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(im)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "for obj in investigation:\n",
    "    obj_id = obj[0]\n",
    "    x,y,w,h = obj[1:5]\n",
    "    plt.text(x, y+15, 'obj'+str(obj_id))\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d9bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f6ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
