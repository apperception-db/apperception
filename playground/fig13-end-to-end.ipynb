{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c9badc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T00:15:43.617706Z",
     "iopub.status.busy": "2022-12-08T00:15:43.616466Z",
     "iopub.status.idle": "2022-12-08T00:15:48.654505Z",
     "shell.execute_reply": "2022-12-08T00:15:48.653531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/apperception/apperception\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152abe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/apperception/.installs/mambaforge/envs/apperception/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Using cache found in /data/apperception/apperception/weights/ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from apperception.database import database\n",
    "from apperception.world import empty_world\n",
    "from apperception.utils import F\n",
    "from apperception.predicate import camera, objects\n",
    "from optimized_ingestion.utils.preprocess import preprocess\n",
    "database.connection\n",
    "from optimized_ingestion.cache import disable_cache\n",
    "# disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922e90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "if NUSCENES_PROCESSED_DATA in os.environ:\n",
    "    DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "else:\n",
    "    DATA_DIR = \"/work/apperception/data/nuScenes/full-dataset-v1.0/Mini\"\n",
    "NUSCENES_RAW_DATA = \"NUSCENES_RAW_DATA\"\n",
    "if NUSCENES_RAW_DATA in os.environ:\n",
    "    RAW_DATA_DIR = os.environ[NUSCENES_RAW_DATA]\n",
    "else:\n",
    "    RAW_DATA_DIR = \"/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574d9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def construct_video(frames, size=(1600, 900), base=False, vid_name=None):\n",
    "    unique_frames = []\n",
    "    for f in frames:\n",
    "        if f not in unique_frames:\n",
    "            unique_frames.append(f)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    vid_name = \"./outputs/fig13_\"+vid_name if vid_name else f\"./outputs/{'fig13_base' if base else 'fig13_optimized'}.avi\"\n",
    "    display_video = cv2.VideoWriter(vid_name,fourcc, 1, size)\n",
    "    for frame in unique_frames:\n",
    "        img_path = os.path.join(RAW_DATA_DIR, frame)\n",
    "        img = cv2.imread(img_path)\n",
    "        display_video.write(img)\n",
    "\n",
    "    display_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ScenicWorld'\n",
    "world = empty_world(name=name)\n",
    "\n",
    "obj1 = objects[0]\n",
    "obj2 = objects[1]\n",
    "cam = camera\n",
    "\n",
    "world = world.filter(\n",
    "    (obj1.id != obj2.id) &\n",
    "    (F.like(obj1.type, 'car') | F.like(obj1.type, 'truck')) &\n",
    "    (F.like(obj2.type, 'car') | F.like(obj2.type, 'truck')) &\n",
    "    F.angle_between(F.facing_relative(cam.ego, F.road_direction(cam.ego)), -15, 15) &\n",
    "    (F.distance(cam.ego, obj1.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    (F.distance(cam.ego, obj2.trans@cam.time) < 50) &\n",
    "    (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "    F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 50, 180) &\n",
    "    F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.ego), -135, -50) &\n",
    "    (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "    F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be10787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(world, DATA_DIR, ['scene-0757-CAM_FRONT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff5d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_query_start = time.time()\n",
    "# id_time_camId_filename_base = world.get_id_time_camId_filename(2)\n",
    "# print(f'based query time: {time.time()-base_query_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1523b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_time_camId_filename_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642b3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_results = [e[4] for e in id_time_camId_filename_base]\n",
    "# construct_video(base_results, base=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391948ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-23 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Using cache found in /data/apperception/weights/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-30 Python-3.10.8 torch-1.13.0+cu117 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0757-CAM_FRONT --------------------------------------------------------------------------------\n",
      "Stage:  InView\n",
      "237\n",
      "None\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DecodeFrame.ParallelDecodeFrame\n",
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection2D.YoloDetection\n",
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  Detection3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [00:00, 3202.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 97.46835443037975%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "Stage:  DetectionEstimation\n",
      "ego_speed:  1.3581198756421884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 236/236 [00:17<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of skipped 7\n",
      "{None: 78, 'ego_exit_segment': 3, 'car_exit_segment': 22, 'meet_up': 127}\n",
      "total_run_time 17.157092571258545\n",
      "total_detection_time 12.889576196670532\n",
      "total_generate_sample_plan_time 4.12225866317749\n",
      "237\n",
      "237\n",
      "  filtered frames: 97.0464135021097%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Stage:  Tracking2D.StrongSORT\n",
      "None\n",
      "237\n",
      "  filtered frames: 97.0464135021097%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Stage:  Tracking3D.From2DAndRoad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237/237 [00:00<00:00, 7625.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "237\n",
      "  filtered frames: 97.0464135021097%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Stage:  SegmentTrajectory.FromTracking3D\n",
      "None\n",
      "237\n",
      "  filtered frames: 97.0464135021097%\n",
      "......KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n",
      "KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK.\n",
      "Time taken to insert trajectories: 0.1581733226776123\n",
      "info found []\n",
      "total preprocess time 25.348026752471924\n"
     ]
    }
   ],
   "source": [
    "preprocess(world, DATA_DIR, ['scene-0757-CAM_FRONT'], base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10b4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: filter\n",
      "execute: get_id_time_camId_filename\n",
      "get_id_time_camId_filename \n",
      "        SELECT t0.itemId,t1.itemId, cameras.timestamp, cameras.cameraId, cameras.filename\n",
      "        FROM (SELECT * FROM item_general_trajectory) as t0\n",
      "        JOIN (SELECT * FROM item_general_trajectory) as t1 USING (cameraId)\n",
      "        JOIN Cameras USING (cameraId)\n",
      "        WHERE ((t0.itemId<>t1.itemId) AND (t0.objectType LIKE 'car' OR t0.objectType LIKE 'truck') AND (t1.objectType LIKE 'car' OR t1.objectType LIKE 'truck') AND angleBetween(facingRelative(egoHeading,roadDirection(egoTranslation,egoHeading)),-15,15) AND (ST_Distance(egoTranslation,valueAtTimestamp(t0.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t0.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (ST_Distance(egoTranslation,valueAtTimestamp(t1.translations,timestamp))<50) AND (viewAngle(valueAtTimestamp(t1.translations,timestamp),egoHeading,egoTranslation)<35.0) AND (EXISTS(SELECT 1\n",
      "            FROM SegmentPolygon\n",
      "            WHERE\n",
      "                'intersection' = Any(SegmentPolygon.segmentTypes) AND\n",
      "                ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t0.translations,timestamp)) AND ST_Covers(SegmentPolygon.elementPolygon, valueAtTimestamp(t1.translations,timestamp))\n",
      "        )) AND angleBetween(facingRelative((headingAtTimestamp(t0.itemHeadings, timestamp))::real,egoHeading),50,180) AND angleBetween(facingRelative((headingAtTimestamp(t1.itemHeadings, timestamp))::real,egoHeading),-135,-50) AND (minDistance(egoTranslation,'intersection')<10) AND angleBetween(facingRelative((headingAtTimestamp(t0.itemHeadings, timestamp))::real,(headingAtTimestamp(t1.itemHeadings, timestamp))::real),100,-100))\n",
      "        \n",
      "done execute node\n",
      "Result length: 64\n",
      "optimized query time: 105.41351914405823\n"
     ]
    }
   ],
   "source": [
    "optimized_query_start = time.time()\n",
    "id_time_camId_filename = world.get_id_time_camId_filename(2)\n",
    "print(f'optimized query time: {time.time()-optimized_query_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7db7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_results = [e[4] for e in id_time_camId_filename]\n",
    "construct_video(optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee79569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_negative = [f for f in base_results if f not in optimized_results]\n",
    "# print(len(false_negative))\n",
    "# construct_video(false_negative, vid_name=\"false_negative.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19be7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positive = [f for f in optimized_results if f not in base_results]\n",
    "# print(len(false_positive))\n",
    "# construct_video(false_positive, vid_name=\"false_positive.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [e for e in id_time_camId_filename if e[4] in false_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation = [[116, 316.0, 455.0, 296.0, 95.0], [161, 316.0, 454.0, 302.0, 94.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('/work/apperception/data/raw/nuScenes/full-dataset-v1.0/Mini/sweeps/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657125362404.jpg')\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(im)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "for obj in investigation:\n",
    "    obj_id = obj[0]\n",
    "    x,y,w,h = obj[1:5]\n",
    "    plt.text(x, y+15, 'obj'+str(obj_id))\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d9bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f6ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
