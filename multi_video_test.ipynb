{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"apperception\"))\n",
    "\n",
    "### IMPORTS\n",
    "import cv2\n",
    "\n",
    "from world import *\n",
    "from world_executor import *\n",
    "from video_util import *\n",
    "from metadata_util import *\n",
    "import lens\n",
    "\n",
    "import psycopg2\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "/home/yongming/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-> Loading model from  models/mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "### Let's define some attribute for constructing the world first\n",
    "name = 'traffic_scene' # world name\n",
    "units = 'metrics'      # world units\n",
    "cam1_id = 'cam1'\n",
    "cam1_video_file = \"../visual_road_video_cut/traffic-001_clip_clip.mp4\" #cam1 view\n",
    "cam2_id = 'cam2'\n",
    "cam2_video_file = \"../visual_road_video_cut/traffic-002_clip_clip.mp4\" #cam2 view"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### First we define a world\n",
    "traffic_world = World(name=name, units=units)\n",
    "\n",
    "### Use TASM if it's available on the machine\n",
    "# traffic_world = World(name=name, units=units, enable_tasm=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### Secondly we construct the camera\n",
    "cam1_len = lens.VRLens(resolution=[3840, 2160], cam_origin=(199, -239, 5.2), yaw=-52, roll=0, pitch=0, field_of_view=90)\n",
    "cam2_len = lens.VRLens(resolution=[3840, 2160], cam_origin=(210, -270, 9), yaw=128, roll=0, pitch=-30, field_of_view=90)\n",
    "fps = 30"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "focal_width 1919.9999999999998\n",
      "focal_height 1079.9999999999998\n",
      "scaling matrix is [[ 5.20833333e-04  0.00000000e+00 -1.00000000e+00]\n",
      " [ 0.00000000e+00  9.25925926e-04 -1.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "focal_width 1919.9999999999998\n",
      "focal_height 1079.9999999999998\n",
      "scaling matrix is [[ 5.20833333e-04  0.00000000e+00 -1.00000000e+00]\n",
      " [ 0.00000000e+00  9.25925926e-04 -1.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "### Ingest the camera to the world\n",
    "traffic_world = traffic_world.camera(cam_id=cam1_id, \n",
    "                               video_file=cam1_video_file, \n",
    "                               metadata_identifier=name+\"_\"+cam1_id, \n",
    "                               lens=cam1_len)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### Call execute on the world to run the detection algorithm and save the real data to the database\n",
    "cam1_recognized_world = traffic_world.recognize(cam1_id)\n",
    "cam1_recognized_world.execute()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Worlds Table created successfully........\n",
      "New world inserted successfully........\n",
      "Camera Table created successfully........\n",
      "New camera inserted successfully.........\n",
      "# of tracked items: 15\n",
      "car-1 saved successfully\n",
      "car-2 saved successfully\n",
      "person-3 saved successfully\n",
      "traffic light-4 saved successfully\n",
      "traffic light-5 saved successfully\n",
      "person-6 saved successfully\n",
      "person-7 saved successfully\n",
      "person-8 saved successfully\n",
      "person-10 saved successfully\n",
      "car-14 saved successfully\n",
      "person-18 saved successfully\n",
      "car-19 saved successfully\n",
      "person-28 saved successfully\n",
      "car-29 saved successfully\n",
      "person-31 saved successfully\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "traffic_world = traffic_world.camera(cam_id=cam2_id, \n",
    "                               video_file=cam2_video_file, \n",
    "                               metadata_identifier=name+\"_\"+cam2_id, \n",
    "                               lens=cam2_len)\n",
    "cam2_recognized_world = traffic_world.recognize(cam2_id)\n",
    "cam2_recognized_world.execute()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yongming/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of tracked items: 9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#traffic_world.get_trajectory().execute()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}