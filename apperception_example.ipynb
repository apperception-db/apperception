{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7a8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"apperception\"))\n",
    "\n",
    "### IMPORTS\n",
    "import cv2\n",
    "\n",
    "from world import *\n",
    "from world_executor import *\n",
    "from video_util import *\n",
    "from metadata_util import *\n",
    "import lens\n",
    "import point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa27562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define some attribute for constructing the world first\n",
    "name = 'traffic_scene' # world name\n",
    "units = 'metrics'      # world units\n",
    "video_file = \"./amber_videos/traffic-scene-shorter.mp4\" #example video file\n",
    "lens_attrs = {'fov': 120, \n",
    "              'cam_origin': (0, 0, 0), \n",
    "              'skew_factor': 0}\n",
    "point_attrs = {'p_id': 'p1', \n",
    "               'cam_id': 'cam1', \n",
    "               'x': 0,\n",
    "               'y': 0, \n",
    "               'z': 0,\n",
    "               'time': None, \n",
    "               'type':'pos'}\n",
    "camera_attrs = {'ratio': 0.5}\n",
    "fps = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09cd0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we define a world\n",
    "traffic_world = World(name=name, units=units)\n",
    "\n",
    "### Use TASM if it's available on the machine\n",
    "# traffic_world = World(name=name, units=units, enable_tasm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9beeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Secondly we construct the camera\n",
    "fov, res, cam_origin, skew_factor = lens_attrs['fov'], [1280, 720], lens_attrs['cam_origin'], lens_attrs['skew_factor']\n",
    "cam_lens = lens.PinholeLens(res, cam_origin, fov, skew_factor)\n",
    "\n",
    "pt_id, cam_id, x, y, z, time, pt_type = point_attrs['p_id'], point_attrs['cam_id'], point_attrs['x'], point_attrs['y'], point_attrs['z'], point_attrs['time'], point_attrs['type']\n",
    "location = point.Point(pt_id, cam_id, x, y, z, time, pt_type)\n",
    "\n",
    "ratio = camera_attrs['ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dfb4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ingest the camera to the world\n",
    "traffic_world = traffic_world.camera(cam_id=cam_id, \n",
    "                               location=location, \n",
    "                               ratio=ratio, \n",
    "                               video_file=video_file, \n",
    "                               metadata_identifier=name+\"_\"+cam_id, \n",
    "                               lens=cam_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f206df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video 1/1 (1/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byronhsu/Desktop/apperception/env/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video 1/1 (2/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (3/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (4/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (5/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (6/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (7/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (8/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (9/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (10/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (11/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (12/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (13/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (14/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (15/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (16/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (17/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (18/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (19/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (20/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (21/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (22/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (23/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (24/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (25/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (26/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (27/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (28/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (29/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (30/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (31/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (32/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (33/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (34/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (35/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (36/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (37/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (38/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (39/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (40/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (41/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (42/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (43/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (44/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (45/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (46/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (47/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (48/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (49/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (50/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (51/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (52/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (53/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (54/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (55/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (56/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (57/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (58/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (59/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (60/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (61/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (62/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (63/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (64/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (65/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (66/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (67/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (68/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (69/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (70/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (71/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (72/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (73/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (74/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (75/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (76/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (77/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (78/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (79/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (80/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (81/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (82/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (83/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (84/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (85/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (86/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (87/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video 1/1 (88/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (89/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (90/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (91/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (92/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (93/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (94/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (95/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (96/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (97/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (98/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (99/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (100/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (101/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (102/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (103/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (104/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (105/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (106/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (107/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (108/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (109/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (110/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (111/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (112/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (113/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (114/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (115/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (116/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (117/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (118/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (119/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (120/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (121/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (122/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: video 1/1 (123/123) /Users/byronhsu/Desktop/apperception/amber_videos/traffic-scene-shorter.mp4: car-1 saved successfully\n",
      "person-2 saved successfully\n",
      "traffic light-3 saved successfully\n",
      "car-4 saved successfully\n",
      "car-6 saved successfully\n",
      "person-7 saved successfully\n",
      "traffic light-8 saved successfully\n",
      "person-9 saved successfully\n",
      "person-10 saved successfully\n",
      "person-11 saved successfully\n",
      "traffic light-12 saved successfully\n",
      "person-12 saved successfully\n",
      "car-13 saved successfully\n",
      "person-15 saved successfully\n",
      "car-18 saved successfully\n",
      "traffic light-10 saved successfully\n",
      "traffic light-9 saved successfully\n",
      "person-19 saved successfully\n",
      "car-20 saved successfully\n",
      "truck-20 saved successfully\n",
      "bus-20 saved successfully\n",
      "person-24 saved successfully\n",
      "person-25 saved successfully\n",
      "traffic light-25 saved successfully\n",
      "traffic light-11 saved successfully\n"
     ]
    }
   ],
   "source": [
    "### Call execute on the world to run the detection algorithm and save the real data to the database\n",
    "recognized_world = traffic_world.recognize(cam_id)\n",
    "recognized_world.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21581e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cam1': <video_context.Camera object at 0x7fe650562c40>}\n",
      "Module(body=[Return(value=Compare(left=Attribute(value=Name(id='obj', ctx=Load()), attr='object_type', ctx=Load()), ops=[Eq()], comparators=[Constant(value='car', kind=None)]))], type_ignores=[])\n",
      "Module(body=[Return(value=Compare(left=Attribute(value=Name(id='obj', ctx=Load()), attr='location', ctx=Load()), ops=[In()], comparators=[Name(id='volume', ctx=Load())]))], type_ignores=[])\n",
      "Module(body=[Return(value=Compare(left=Call(func=Name(id='Tmin', ctx=Load()), args=[Attribute(value=Name(id='obj', ctx=Load()), attr='location', ctx=Load())], keywords=[]), ops=[GtE()], comparators=[Name(id='start', ctx=Load())]))], type_ignores=[])\n",
      "Module(body=[Return(value=Compare(left=Call(func=Name(id='Tmax', ctx=Load()), args=[Attribute(value=Name(id='obj', ctx=Load()), attr='location', ctx=Load())], keywords=[]), ops=[Lt()], comparators=[Name(id='end', ctx=Load())]))], type_ignores=[])\n",
      "SELECT distinct on(itemId) Item_General_Trajectory.itemId From Item_General_Trajectory INNER JOIN General_Bbox USING(itemId)  Where Item_General_Trajectory.objectType='car' AND overlap(General_Bbox.trajBbox, stbox 'STBOX Z((0.01082532, 2.59647246, 0),(3.01034039, 3.35985782, 2))')=true AND Tmin(General_Bbox.trajBbox)>='2021-06-08 07:10:28' AND Tmax(General_Bbox.trajBbox)<'2021-06-08 07:12:28';\n",
      "\n",
      "filtered_ids are [['car-1']\n",
      " ['car-13']\n",
      " ['car-20']\n",
      " ['car-4']]\n",
      "4\n",
      "Module(body=[Return(value=Compare(left=Attribute(value=Name(id='obj', ctx=Load()), attr='object_id', ctx=Load()), ops=[In()], comparators=[Name(id='id_array', ctx=Load())]))], type_ignores=[])\n",
      "atPeriodSet(Item_General_Trajectory.trajCentroids,'{[0001-01-01 00:00:00, 9999-12-31 23:59:59.999999)}')\n",
      "asMFJSON(atPeriodSet(Item_General_Trajectory.trajCentroids,'{[0001-01-01 00:00:00, 9999-12-31 23:59:59.999999)}'))::json->'coordinates'\n",
      "SELECT distinct on(itemId) asMFJSON(atPeriodSet(Item_General_Trajectory.trajCentroids,'{[0001-01-01 00:00:00, 9999-12-31 23:59:59.999999)}'))::json->'coordinates' From Item_General_Trajectory  Where Item_General_Trajectory.itemId IN ('car-1','car-13','car-20','car-4');\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byronhsu/Desktop/apperception/env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[Return(value=Compare(left=Attribute(value=Name(id='obj', ctx=Load()), attr='object_id', ctx=Load()), ops=[In()], comparators=[Name(id='id_array', ctx=Load())]))], type_ignores=[])\n",
      "Module(body=[Return(value=Compare(left=Call(func=Name(id='Tmin', ctx=Load()), args=[Attribute(value=Name(id='obj', ctx=Load()), attr='location', ctx=Load())], keywords=[]), ops=[GtE()], comparators=[Name(id='start', ctx=Load())]))], type_ignores=[])\n",
      "Module(body=[Return(value=Compare(left=Call(func=Name(id='Tmax', ctx=Load()), args=[Attribute(value=Name(id='obj', ctx=Load()), attr='location', ctx=Load())], keywords=[]), ops=[Lt()], comparators=[Name(id='end', ctx=Load())]))], type_ignores=[])\n",
      "Xmin(General_Bbox.trajBbox)\n",
      "Ymin(General_Bbox.trajBbox)\n",
      "Zmin(General_Bbox.trajBbox)\n",
      "Xmax(General_Bbox.trajBbox)\n",
      "Ymax(General_Bbox.trajBbox)\n",
      "Zmax(General_Bbox.trajBbox)\n",
      "Tmin(General_Bbox.trajBbox)\n",
      "SELECT Item_General_Trajectory.itemId, Xmin(General_Bbox.trajBbox), Ymin(General_Bbox.trajBbox), Zmin(General_Bbox.trajBbox), Xmax(General_Bbox.trajBbox), Ymax(General_Bbox.trajBbox), Zmax(General_Bbox.trajBbox), Tmin(General_Bbox.trajBbox) From Item_General_Trajectory INNER JOIN General_Bbox USING(itemId)  Where Item_General_Trajectory.itemId IN ('car-1','car-13','car-20','car-4') AND Tmin(General_Bbox.trajBbox)>='0001-01-01 00:00:00' AND Tmax(General_Bbox.trajBbox)<'9999-12-31 23:59:59.999999';\n",
      "\n",
      "(121, 4)\n",
      "(121, 4)\n",
      "(114, 4)\n",
      "(58, 4)\n",
      "incorrect length: 58\n",
      "output video files ./output/traffic_scene_cam1car-1.mp4,./output/traffic_scene_cam1car-4.mp4,./output/traffic_scene_cam1car-13.mp4,./output/traffic_scene_cam1car-20.mp4\n"
     ]
    }
   ],
   "source": [
    "volume = traffic_world.select_intersection_of_interest_or_use_default(cam_id=cam_id)\n",
    "filtered_world = traffic_world.predicate(lambda obj:obj.object_type == \"car\").predicate(lambda obj:obj.location in volume, {\"volume\":volume})\n",
    "filtered_world = filtered_world.interval([0,fps*4])\n",
    " \n",
    "### to get the trajectory and the video over the entire trajectory(amber case)\n",
    "filtered_ids = filtered_world.selectkey(distinct = True).execute()\n",
    "print(\"filtered_ids are\", filtered_ids)\n",
    "print(len(filtered_ids))\n",
    "if len(filtered_ids)>0:\n",
    "    id_array = [e[0] for e in filtered_ids]\n",
    "    ### Fetch the trajectory of these items\n",
    "    trajectory = traffic_world.predicate(lambda obj: obj.object_id in id_array, {\"id_array\":id_array}).get_trajectory(distinct=True).execute()\n",
    "    traffic_world.overlay_trajectory(cam_id, trajectory)\n",
    "    ### Get the videos of these items\n",
    "    entire_video = traffic_world.predicate(lambda obj: obj.object_id in id_array, {\"id_array\":id_array}).get_video()\n",
    "    entire_video.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fe294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
